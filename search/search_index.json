{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>           Ajay Marampalli      </p> <p>Welcome to my personal website! I am a passionate software engineer with a keen interest in solving complex problems and developing innovative solutions.</p> <p> </p>"},{"location":"#contact-information","title":"Contact Information","text":"<ul> <li>Phone: (+1) 773-729-7683</li> <li>Location: Chicago, IL</li> <li>Email: ajay.marampalli10@gmail.com</li> <li>LinkedIn: /in/ajaymarampalli/</li> </ul>"},{"location":"#about-me","title":"About Me","text":"<p>I have a deep love for coding and enjoy tackling challenges on platforms like LeetCode. My favorite algorithms include:</p> <ul> <li>Dynamic Programming: Efficiently solving complex problems by breaking them down into simpler subproblems.</li> <li>Graph Algorithms: Understanding and implementing algorithms for graph traversal, shortest paths, and more.</li> <li>Sorting and Searching: Optimizing data handling with various sorting and searching techniques.</li> </ul>"},{"location":"#experience","title":"Experience","text":""},{"location":"#full-stack-engineer","title":"Full Stack Engineer","text":"<p>Energy Resources Center, University of Illinois at Chicago | Chicago, IL Jan 2022 - Present</p> <ul> <li>Played a key role in developing the Solar Cost-Benefit Calculator and Seed-Selection Tool for the US-Department of Energy (DOE) in collaboration with Stantec Inc., utilized by over 50 industry organizations to assess the feasibility of solar energy projects nationwide.</li> <li>Implemented multiple web services using Java Spring Boot, and optimized database performance by crafting stored procedures, resulting in a 20% improvement overall.</li> <li>Built the UI Components of the tools using React and Redux, ensuring responsive and efficient state management while incorporating interactive and user-friendly mapping capabilities to display eco-regions across the US using EsriGis Maps.</li> <li>Deployed the API services onto AWS ECS integrated with CloudWatch alerts and automated build and deployment processes by creating pipelines using Jenkins.</li> <li>Devised and created a web tool for collecting annual reporting data using React, TypeScript, and Redux, integrated Firebase for streamlined data storage, and implemented seamless communication and data exchange using WP-JSON API endpoints.</li> <li>Technologies Used: React, TypeScript, HTML, CSS, Redux, Java Spring Boot, AWS, WordPress, Maven, Git</li> </ul>"},{"location":"#software-engineer","title":"Software Engineer","text":"<p>Cognizant Technology Solutions | Hyderabad, India June 2020 - June 2021</p> <ul> <li>Developed an Angular 12 application for a transportation booking platform, enhancing user experience through the implementation of real-time bus tracking services and automated alerts. This solution enabled users to receive real-time location updates via email and text, reducing customer support inquiries by 70%.</li> <li>Gained experience in working with Angular modules and services, alongside reactive programming using RxJS, to develop scalable and maintainable components.</li> <li>Formulated a Business Monitoring dashboard for a bank client, implementing Single-Sign-On (SSO) using Spring Security.</li> <li>Ensured optimal data handling and storage using Spring Data JPA and Hibernate, facilitating seamless communication with databases which resulted in a 15% boost in data retrieval speed, improving the overall system performance.</li> </ul>"},{"location":"#education","title":"Education","text":"<p>University of Illinois at Chicago | Master of Science in Computer Science August 2021 \u2013 May 2023</p> <ul> <li>Relevant Courses: Development of Mobile Applications, Big Data Visualization, User Interface Design, Introduction to Networking, Human-Computer Interaction, Database Systems.</li> </ul>"},{"location":"#certifications","title":"Certifications","text":"<ul> <li>AWS Certified Developer \u2013 Associate</li> <li>Key Skills: Lambda, EC2, ECS, API Gateway, IAM, Cognito, CDK, CloudFormation, DynamoDB, RDS, S3</li> </ul>"},{"location":"#projects","title":"Projects","text":""},{"location":"#flight-analytics-a-data-driven-approach-to-visualization-of-airline-operations","title":"Flight Analytics: A Data-Driven Approach to Visualization of Airline Operations","text":"<ul> <li>Spearheaded the development of a flight delay visualization solution in React, TypeScript, and Redux. Achieved a 50% improvement in user engagement and optimized the process for accessing critical flight information.</li> <li>Built a scalable back end using Express.js, handling real-time queries on flight delay information stored in AWS RDS (Postgres).</li> <li>Utilized D3.js to create visually appealing visualizations, improving the understanding of trends and correlations.</li> <li>Key Skills: React.js, Express.js, D3.js, SQL, AWS (RDS, EC2, Lambda)</li> </ul>"},{"location":"#skills","title":"Skills","text":"<ul> <li>Front-End Development: JavaScript, TypeScript, React, Angular, HTML, CSS, Redux, jQuery, Bootstrap, Figma</li> <li>Software Development: Java, Spring Boot, SQL, REST API, VS Code, Android Development, .NET, C#, Python</li> <li>Database Systems: SQL Server, MySQL, PostgreSQL, AWS RDS, MongoDB</li> <li>Development Tools &amp; Concepts: Git, Postman, Android Studio, IntelliJ, Docker, Bitbucket, Agile, Scrum</li> <li>Cloud Platforms: AWS, Heroku, Netlify, Azure DevOps</li> </ul>"},{"location":"#explore-more","title":"Explore More","text":"<p>Feel free to explore the other sections of my website:</p> <ul> <li>ASP.NET</li> <li>AWS</li> <li>AzureDev</li> <li>C#</li> <li>LeetCode</li> <li>Low Level Design</li> </ul>"},{"location":"ASP.NET/","title":"ASP.NET","text":"<p>Course Link Udemy- Mosh Hamedani</p>"},{"location":"ASP.NET/#introductions","title":"Introductions","text":"<ul> <li>entry point to the application is program.cs , which creates an app object and starts a kestrel web server. In production scenarios, IIS sits in front of multiple applications and forwards request to the kestrel server.</li> </ul>"},{"location":"ASP.NET/#dependency-injection","title":"Dependency Injection","text":"<ul> <li>In the main application of the program <code>program.cs</code>, the dependencies required for the application should be registered, <code>build.Services</code> or <code>IServiceCollection</code> is the central container of all the dependencies in the application.</li> <li>Using this approach, the classes do not have to create object instances whenever a specific dependency is required in a class</li> <li>Instead the dependencies are passed to the application, through constructor.</li> </ul> <ul> <li>Life Cycle of the DI injection</li> <li>Service Registration (add methods to the <code>IServiceCollection</code>)</li> <li>Different lifetime scopes of object<ol> <li>Singleton - a single instance is created for the entire runtime</li> <li>scoped - a new instance is created for each request or every time its needed</li> <li>transient - a new instance is created everytime a service is required ()</li> </ol> </li> <li>class Dependency declaration (a class which requires the object declares the interface type as a parameter in its constructor)</li> <li>Object Creation and Injection</li> <li>At run time, when the class requests to make an instance of the interface, the runtime looks up the registery and creates an instance based on the interface lifecycle and injects into the constructor</li> </ul>"},{"location":"ASP.NET/#middleware","title":"Middleware","text":"<ul> <li> <p>This portion of the program sits in between the client and the kestrel web server, the order is important in the middleware declaration</p> </li> <li> <p>auth &gt; routing &gt; static files &gt; logging</p> </li> </ul>"},{"location":"ASP.NET/#serversiderendering","title":"ServerSideRendering","text":"<ul> <li>In this type of approach, all requests are made from the browser are handled by the server internally, the components required for the browser are generated by the server</li> <li>MVC and Razor pages support SSR</li> </ul>"},{"location":"ASP.NET/#clientside","title":"ClientSide","text":"<ul> <li>In this type, all whole bundle is sent to the client at once, and the client handles the internal actions.</li> <li> <p>Blazor supports CSR</p> </li> <li> <p>two types of appraoches are followed in blazor pages</p> </li> <li>blazor webassembly - in this all the components are compilied into assembly and sent over to browser which renders the page using its runtime environment</li> <li>blazor server - in this approach, a <code>signalR</code> middleware is added which creates a web socket connection between the client and server and it keeps track of all changes made by user and renders appropriately</li> </ul>"},{"location":"ASP.NET/#mvc","title":"MVC","text":"<ul> <li>Model : Representation of a data object used in other classes.</li> <li>View : Layer responsible for transformation of information or data from model and present it in UI</li> <li>Contoller: Layer responsible for handling all the requests. It interacts with the <code>Model</code> to fetch data and <code>View</code> to make changes to display in the UI.</li> <li>Router : The layer which is responsible for routing the requests to the appropriate controller in the backend.</li> </ul>"},{"location":"ASP.NET/#return-types","title":"Return Types","text":"<ul> <li>ActionResult - whenever a action is invoked in a controller, some specific logic is performed and an <code>ActionResult</code> object is returned, which indicates what the server should respond to the request</li> <li>ViewResult: This is the most common type, used to render a view template (typically a Razor view) for the client.</li> <li>ContentResult: This returns plain text content directly to the client.</li> <li>EmptyResult: This indicates no specific content needs to be returned, often used for simple actions that might just perform some processing.</li> <li>RedirectResult: This redirects the user's request to a different URL.</li> <li>JsonResult: This returns data in JSON format, often used for AJAX requests in web applications.</li> <li>JavaScriptResult: This returns a JavaScript code snippet that can be executed on the client-side.</li> </ul>"},{"location":"ASP.NET/#routing","title":"Routing","text":"<ul> <li>two different methods of routing are offered in .net</li> <li>convention-based routing: In this method, inside the router class, a new map route can be created for a specific controller by passing the controller name and contional paratemers to match the route</li> <li>attribute routing: In this case, the routing is handled by the router class itself, <code>[Route]</code> attribute should be declared in the controller class</li> </ul>"},{"location":"ASP.NET/#orm","title":"ORM","text":"<ul> <li> <p>object Relational Mapper : creates objects based on the relational data from database</p> </li> <li> <p>workflow</p> </li> <li> <p>a _DBContext is created to work on the database, a _DBSet is created to create a stack of all the operations to be performed</p> </li> <li>through LINQ new queries are added to the _DBSet and executed on DB using the _DBContext</li> <li> <p>use _DBContext.SaveChanges() to process all stacks</p> </li> <li> <p>two different types of approached are followed in entity framework</p> </li> <li>Database first: In this approach , the DB models are created first using which the EF , will create the model classes and controllers</li> <li> <p>Code first: in this approach, the models and controllers are created through which the DB schema's are created. Can perform verisioning and migrations in this approach.</p> </li> <li> <p>command line tools for migration <code>use-migration</code>,<code>add-migration</code>,<code>update database</code></p> </li> </ul>"},{"location":"ASP.NET/#dto","title":"DTO","text":"<ul> <li>useful for delivering only the required data objects from a data model.</li> <li>A new data object is create which caters the specific use , this new object will be sent over the network, without disclosing the details of the main model class.</li> <li>AutoMapper can be used to create dto objects and tranform them in the controllers</li> </ul>"},{"location":"ASP.NET/#grpc","title":"gRPC","text":"<ul> <li>This is an another kind of API interface format, main functinalities</li> <li>work on performing remote procedure calls, instead of put,get,post,delete actions</li> <li>serilization and deserialization is performed by protocol buffer or protobuffers</li> <li>a contract is signed between the parties prior to connection to determine the formats</li> </ul>"},{"location":"ASP.NET/#ef-core","title":"EF Core","text":"<ul> <li>EF was initially introduced to manage the database objects and connections to the database, EF core was later introduced to support the cross platform functionality</li> </ul>"},{"location":"ASP.NET/#testing","title":"Testing","text":"<p>Automated tests are used to improve relaibility and are included in the build process or CI/CD pipeline</p> <ul> <li> <p>Unit Testing: A small chunk or a responsibility of a component is tested, this approach is used to find the error easily rather than going into the rabbit hole</p> </li> <li> <p>Integration testing: Mainly used to check if two components are properly configured to execute their tasks (connecting to database , a controller calling a service appropriately)</p> </li> <li> <p>Functional Test: Mainly used to test end to end functionality of the application, it tests the complete life cycle.</p> </li> </ul> <p>Different steps in the testing</p> <ol> <li>Action - Define the workflow of the testing proc.</li> <li>Mock - Create all the objects and variables required for performing the action.</li> <li>Assert - Post performing the action, check if the required response is noted.</li> </ol>"},{"location":"AWS/","title":"AWS - Developer Associate Certificate","text":"<p>Domains of the course Course-Link, PluralSight</p> <ol> <li>Development of aws services (32%)</li> <li>security (26%)</li> <li>deployment (24%)</li> <li>troubleshooting and optimization (18%)</li> </ol> <p>130 minutes - 65 questions</p>"},{"location":"AWS/#iam","title":"IAM","text":"<p>IAM - Identity Access Management</p> <p>main usage - to controll acess to the resources end points - users, groups , roles , policies</p> <ul> <li>roles - defines a set of conditions on resources , users or group or applications inherit these properties</li> <li>A role provides a dynamic way to provide permission of interact with the resoruces</li> <li>policies - A direct way to interact way with resources.</li> </ul> <p>A role can follow a set of policies to interact with</p> <p>E.g - creating a new policy and attaching a role to it</p> <ul> <li>policy name - <code>ReadOnlyAccessToS3Bucket</code></li> </ul> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::example-bucket\",\n                \"arn:aws:s3:::example-bucket/*\"\n            ]\n        }\n    ]\n}\n</code></pre> <ul> <li>Role Name: EC2ReadOnlyS3Role</li> </ul> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"ec2.amazonaws.com\"\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n</code></pre> <p>To check if a policy can perform a set of actions we can use</p> <ul> <li>Policy Sim</li> </ul>"},{"location":"AWS/#aws-cognito","title":"AWS Cognito","text":"<ul> <li>service to provide authz and authn features with the aws resources</li> <li><code>User Pool</code> contains information such as the JWT token issued by third party authN providers</li> <li><code>Identity Pool</code> contains information which is used to assign a new IAM role to the user and provide temporary access to the aws resources</li> <li> <p>Different policy types offered in IAM</p> </li> <li> <p>inline policy --&gt; this is a policy which can be attached to a single user or a single group and maintains a 1:1 relation (i.e only can be used by them, whenever the user is deleted the policy is deleted)</p> </li> <li>AWS managed --&gt; this is a default policy which is authored and managed by aws, it has policy .for each service</li> <li>customer managed --&gt; this type of policy is used when organization need tailoring of the aws managed policies.</li> </ul>"},{"location":"AWS/#rbac","title":"RBAC","text":"<ul> <li>Role Based Access Control, in this model a role is created with a certain policies attaced to it to satisty a job, this model is adopted by the IAM.</li> </ul>"},{"location":"AWS/#active-directory","title":"Active Directory","text":"<ul> <li> <p>Identity Provider Store(Idp)</p> </li> <li> <p>contains details about the authentication for the users</p> </li> <li>mentions the access and actions which each user can perform</li> <li> <p>can use the IAM or connect to an extrenal Active Directory which can be cannonical to Idp</p> </li> <li> <p>Identity Broker</p> </li> <li> <p>It acts as a central checkpoint for multiple Idp's</p> </li> <li>Cognito can assume this role to validate credentials from multiple third party applications</li> </ul>"},{"location":"AWS/#sts","title":"STS","text":"<ul> <li>aws provides the service to access the resource in a different aws account through sts AssumeRole policy</li> <li>a new IAM role is created in the main account which is shared with the second account to share access to the resources</li> <li><code>credential_process</code> - in aws cli this is used to define a metadata parameter which specifies an external authentication connection to be used during the auth process</li> <li> <p><code>credential_source</code> - in aws cli the credential source defines the method or source from which auth codes should be fetched , different options of auth are</p> </li> <li> <p>IAM role (sts assume-role)</p> </li> <li>SSO (configure single sign on profile)</li> <li>web identity configuration (sts assume-role-with-web-identity, provide the token with parameter web-identity-token)</li> <li> <p>export it as environmnet variables</p> </li> <li> <p>both the <code>credential_process</code> and <code>credential_source</code> are present in the ~/.aws/config folder</p> </li> <li> <p>different way to pass credentials to an aws sdk</p> </li> <li> <p>set environment variables and set the <code>credential_soruce</code> to fetch the creds</p> </li> <li>configure the ~./aws/credentials file to read the credentials</li> <li>the AWS_SDK_LOAD_CONFIG variable which points to the path of credentials folder or file</li> <li><code>aws.config.loadFromPath</code> function which reads the credentials from a json file.</li> </ul>"},{"location":"AWS/#acm","title":"ACM","text":"<ul> <li>AWS certiicate Manager, services used to create, store and renew public and private ssl/tls certificates</li> <li>acm wildcard certificates can be used to protect the subdomains, when the keys are signed by acm certificate authority(CA) they can be used everywhere in the companies public key infrastructure (PKI)</li> </ul>"},{"location":"AWS/#vpc","title":"VPC","text":"<ul> <li> <p>NACL (Network ACL)</p> </li> <li> <p>use to protect the subnets traffic</p> </li> <li>its stateless</li> </ul>"},{"location":"AWS/#ec2","title":"EC2","text":"<ul> <li>Elastic Cloud Compute</li> <li> <p>pricing types</p> </li> <li> <p>on Demand (pay per use)</p> </li> <li>Reserved (prepay and long term)</li> <li>spot (fix a max price , the instances are balanced dynamically)</li> <li>dedicated</li> </ul> <p>EBS storage types</p> <ol> <li>gp2 , gp3 - general purpose (3000 - 16000 IOPS)</li> <li>io1,io2,SAN - faster access (16000 - 64000 IOPS) , can be attached to mulitiple instances</li> <li>SAN - (256000 IOPS)</li> <li> <p>st1 (500 mbps), sc1 (250mbps) - hdd storage</p> </li> <li> <p>ec2 instance and ebs volume should be in the same availability zone in order to attach them.</p> </li> <li>general purpose ssd - virtual desktops , test and dev env, low latency iot devices</li> <li>throughput optimized - streaming data</li> <li>cold hdd - used for infrequent data</li> <li>provisioned i/o - critical sustained processing</li> <li>instance profile in ec2 are used to attach the IAM roles to the instace, a single role can be shared by multiple ec2 instances.</li> </ol>"},{"location":"AWS/#elastic-load-balancer","title":"Elastic Load Balancer","text":"<p>types</p> <ol> <li>application (http / https requests)</li> <li>network load (tcp)</li> <li> <p>gateway load balancers (used to serve third party applications such as firewalls)</p> </li> <li> <p>Main use case is to efficiently forward requests to the appropriate server</p> </li> <li>the load balancer has a private address by default , it used the x-forwarded-by property to find the ip address of end user</li> </ol> <p></p> <ul> <li>connection draining happens in elb when one of the instance is in draining stage and it reroutes the new requests to the healthy units</li> </ul>"},{"location":"AWS/#rds","title":"RDS","text":"<ul> <li>main use case: In case of Transaction data , use RDS if use case need to perform analysis on large data use RedShift</li> </ul> <p>to improve performance - Read replica snapshots of rds instances are provided to resolve disasters - Multiple rds instances are allocated in different Availability zones</p> <ul> <li> <p>two different options to perform backups</p> </li> <li> <p>automated - handled by aws , these are performed in definitive time window, can be stored across multiple time zones</p> </li> <li> <p>manual - a snapshot is created manually by the user and its stored in an s3 bucket (charged) , this snapshot would be having a different RDS endpoint compared to the parent</p> </li> <li> <p>An unencrypted RDS instance can be encrypted by making a manual snaphot and encrypting it.</p> </li> </ul> <p></p> <ul> <li>RDS proxy: its used to load balance all the incoming traffic to the rds instance , in case of any instance failures all the transactions are stored in the proxy servers and are resolved post failure resolving process.</li> </ul>"},{"location":"AWS/#elasticache","title":"ElastiCache","text":"<p>In memory storage in aws, two types are available</p> <ol> <li>memcache (used to store simple cache , session storage of website) - memcache sits in front of an RDS instance</li> <li>Redis (complex datatypes, larger applications such as online gaming)</li> </ol> <p>MemoryDB for redis is alternative to an RDS service</p>"},{"location":"AWS/#caching-strategies","title":"Caching Strategies","text":"<ul> <li> <p>different caching strategies in cache</p> </li> <li> <p>write - through --&gt; add data to cache first before writing to the database</p> </li> <li>read-through --&gt; first queries the cache before making a request to database, then updating the cache</li> <li>lazy loading --&gt; load items into the cache only when the items are required to be loaded into cache</li> <li>adding ttl --&gt; put a new ttl record to each item , this would reduce the cluttering of the cache and frequent update of the cache.</li> </ul>"},{"location":"AWS/#parameter-store","title":"Parameter Store","text":"<p>System manager service provides the parameter store to encrypt sensitive data and pass on to other resources</p>"},{"location":"AWS/#secrets-manager","title":"Secrets Manager","text":"<ul> <li>AWS secret manager is used to store all the database passwords , api keys . etc.</li> <li>rotation of the keys can be enables in secrets manager which is handled by an lambda function</li> <li>use programmatic way to retrive keys from the manager</li> <li>it uses a key from aws kms to encrypt and it can be replicated in other zones</li> </ul>"},{"location":"AWS/#ec2-image-builder","title":"EC2 Image Builder","text":"<ul> <li>EC2 instances can be used to test and build images</li> </ul>"},{"location":"AWS/#s3","title":"S3","text":"<p>Simple Storage Service</p> <p>Different types</p> <ol> <li>Standard (general purpose)</li> <li>standard - infrequent access (store backup files)</li> <li>glacier and glacier archive (large archive data)</li> <li>Intelligent Tiering (auto shift between storage types based on access frequency)</li> </ol> <p>Encryption types</p> <ol> <li>SSE-S3 (managed by s3 , not by kms - default)</li> <li>SSE-KMS (managed by kms)</li> <li>SSE-C (managed by customer)</li> <li>DSSE-KMS (dual encryption managed by kms)</li> </ol> <p>By default CORS is disabled between two s3 buckets , edit the properties and allow the host to enable CORS</p> <ul> <li> <p>in the lifecycle policy of the s3 , the following components are decided</p> </li> <li> <p>days after which the storage class should be changed</p> </li> <li>days after which the object should be removed from the storage service</li> </ul>"},{"location":"AWS/#cloudfront","title":"CloudFront","text":"<p>CDN network provided by aws</p> <ol> <li>Edge Location (cache location with definitve ttl)</li> <li> <p>CloudFront origin (origin of files (s3,ec2,elb,r53))</p> </li> <li> <p>Can assign a resource to be restricted by use of signed URL or signed cookies.</p> </li> </ol> <p>additional topics - AWS WAF (firewall) --&gt; mainly used to restrict all the incoming traffic to the origin</p> <ul> <li>A new origin access identity is required whenever we need to restrict access to the s3 buckets</li> </ul>"},{"location":"AWS/#allowed-methods","title":"Allowed Methods","text":"<ol> <li>GET, HEAD (resource_headers) (read-only)</li> <li>GET, HEAD, OPTIONS (request_to_know_allowed_methods) (read-only)</li> <li>GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE (read-only and write)</li> </ol>"},{"location":"AWS/#oac","title":"OAC","text":"<ul> <li>OAC controls access to the origin source in cloudFront</li> <li>this acts as a special identity</li> </ul>"},{"location":"AWS/#athena","title":"Athena","text":"<p>Service used to run SQL queries on data stored in s3 buckets</p> <p>usecases - log analysis, generating reports based on s3 data, click data analysis</p> <ul> <li>need to create a new s3 bucket before analysis to store all the results of the queries.</li> </ul> <p></p>"},{"location":"AWS/#serverless-architectures","title":"ServerLess Architectures","text":"<p>diff types of serverless arch</p> <ol> <li>lambda</li> <li>sqs</li> <li>sns</li> <li>api gateway</li> <li>dynamodb</li> <li>s3</li> </ol> <p></p>"},{"location":"AWS/#lamda","title":"lamda","text":"<ul> <li>serverless arch to run applications and microservices , the run time environment is handled by aws</li> <li>priced based on number of requests and memory consumption of the program</li> <li> <p>different triggers to invove a lamda function</p> </li> <li> <p>change in s3 bucket, dynamo table (any changes to resources)</p> </li> <li> <p>user requests (api gateway to invoke requests)</p> </li> <li> <p>increasing the memory of a lambda function automatically add CPU to the instance.</p> </li> <li>error handling in lambda functions can be handled by usage of dead letter queues which send the error logs using the sns service.</li> <li>lambda provides <code>alias</code> option to maintain different versions of the function, each alias has a unique ARN</li> <li>an alias cannot point to another alias, alias routing configuration can be used for sending a specific portion of the incoming traffic to a different version of the function</li> <li> <p>lambda functions using c#,java,python</p> </li> <li> <p>handler definition in python file_name.handler_function_name</p> </li> <li>in Java, the main function implements the interface <code>RequestHandler</code>, the handler function is defined as <code>MainClass::MainFunction</code></li> <li>in c#, the handler is defined as NameSpace::MainClass.FunctionName</li> </ul>"},{"location":"AWS/#api-gateway","title":"API Gateway","text":"<ul> <li>service which sits in front of all RestFul API sockets and handles incoming requests.</li> <li>All requests made to API gateway are logged in cloudWatch</li> <li>API gateway allows importing of the openAPI profile and also allows SOAP protocol by transforming XML into JSON formats</li> <li>API gateway also allows mock integration endpoints for testing, use case when a front end dev team finsihes their code and wants to test but theres no available back end , they can create mock tests to test out the routes</li> <li> <p>fields in the mock test</p> </li> <li> <p>status code</p> </li> <li> <p>body message</p> </li> <li> <p>API Gateway also provides option of caching , in this option all the responses are cached with a ttl of 300 seconds , any new request made to gateway uses the cache</p> </li> <li> <p>API gateway also allows throttling of the request.</p> </li> <li> <p>by default it allows 10,000 requests per second</p> </li> <li>if we get more no of requests than the limit , the requests are throttled to the next second without resulting in an 429 server overload response code.</li> </ul>"},{"location":"AWS/#version-control","title":"version control","text":"<ul> <li>lambda offers version control to manage different stage od SDLC , $LATEST sign indicates the default version. We can also create aliases in the functions to route traffic between two different versions of the code.</li> <li>lambda function can join a vpc and connect or create elastic resources in that particular vpc, need to add additional policies to acheive this.</li> </ul>"},{"location":"AWS/#step-functions","title":"step functions","text":"<ul> <li>service to orchestrate several serverless functions, the step function consists of a state machine which handles all the tasks in it.</li> <li> <p>different types of executions</p> </li> <li> <p>series tasks</p> </li> <li>parallel tasks</li> <li>series + parallel</li> <li>branching (conditional statements)</li> </ul>"},{"location":"AWS/#data-storage-in-lambda-functions","title":"Data storage in lambda functions","text":"<p>By default lambda functions are stateless, different options to provide storage to lambda functions</p> <ol> <li>/tmp (accessible from 512mb to 10gb, works in the same environment and can be shared by all functions using the runtime)</li> <li>layers (used to manage all the libraries required for the runtime (50mb ))</li> <li>EFS (File system which can be mounted at runtime , it should be in the same vpc as the lambda function, allows dynamic read and writes)</li> <li>DynamoDB (files or value directly stored to DB)</li> <li>S3 (store files in s3)</li> </ol>"},{"location":"AWS/#dynamodb","title":"DynamoDB","text":"<ul> <li>NoSQL database servie provide by aws, it does not have any schema structure , data is stored in tables , each row is an item and each column of the table is an attribute , the data is stored in json format</li> <li> <p>two types of keys can be used to indicate the primary key</p> </li> <li> <p>partition key</p> </li> <li> <p>partition key + sort key (when a same user has multiple records , a student taking multiple course, in this case user_id+course_id is the PK)</p> </li> <li> <p>access to the DDB is controlled through IAM roles, access can be blocked by adding conditinal statements in policy</p> </li> </ul> <p></p> <ul> <li>in this example policy , the condition states only matching records with <code>user_id</code> should be displayed or queried as response.</li> <li>a local secondary index can also be used to query results along with a single partition key , a local secondary index must be created at the creation time</li> <li>a global secondary index on other hand can be paired up with multiple partion keys spread across table and can be created at any time.</li> <li><code>Query</code> is used to scan items in the table based on a partition key along with sort key</li> <li><code>Scan</code> is used to scan all the items in the table , does not depend on the primary key or secondary key to scan the items.</li> <li>dynamo tables are different in different regions <code>us-east-1</code> and <code>us-west-1</code> would be different.</li> </ul>"},{"location":"AWS/#read-and-write-capacities","title":"Read and write capacities","text":"<ul> <li>dynamo db provides Read and write capacity units as metrics</li> <li>each <code>READ</code> unit can read 4kb per second data in eventual consistency and 2KB/sec in stong consistency.</li> <li>each <code>WRITE</code> unit can write 1kb/sec</li> </ul>"},{"location":"AWS/#dax","title":"DAX","text":"<ul> <li>dynamo db offers in memory cache which sits infront of the db</li> <li>workflow --&gt; when ever a user queries , it first checks the DAX if its a cache hit , return res, else query db</li> <li>usefull in case of eventual read consistency and heavy read intensive applciations , black friday sales</li> </ul>"},{"location":"AWS/#ttl","title":"TTL","text":"<ul> <li>dynambo db offers the service to auto remove objects from the table based on a defined ttl.</li> <li>the attribute used to set ttl must be in <code>epoch-time</code> format</li> </ul>"},{"location":"AWS/#dynamodb-streams","title":"DynamoDB Streams","text":"<ul> <li>its a service which stores time - ordered sequence data in table</li> <li>it stores the data for 24 hours</li> <li>it has a different api than the dynamo db , its usefull as a trigger for lambda functions.</li> <li>all the records are cleaned after 24 hours</li> <li> <p>usecase</p> </li> <li> <p>when ever a payment record is stored in the db stream , a lambda event is triggered</p> </li> <li>the lambda event sends a sns notification and adds the item to sqs queue which is processed and a reciet is genereated</li> </ul>"},{"location":"AWS/#provisionedthroughputexception","title":"ProvisionedThroughPutException","text":"<ul> <li>when the request exceed the read and write units quota .this exception is thrown</li> <li>to avoid this a <code>exponential backoff</code> pattern is followed, (e.g first try 50ms ,second - 100ms , third -200)</li> </ul>"},{"location":"AWS/#kms","title":"KMS","text":"<ul> <li>AWS key management service, it can be inherited by other storage services to encrypt / decrypt incoming and outgoing data</li> <li>it follows envolope encryption method , where a master key encrypts a data key which in turn is used to encrypt the main data files</li> <li> <p>useful commands in kms</p> </li> <li> <p>encrypt , decrypt</p> </li> <li>rotate key (periodically update the customer master key)</li> <li> <p>generate data key (used to generate a new key , which in turn can be used to encrypt and decrypt other data contents)</p> </li> <li> <p>GenerateDataKeyAPI is used in envolope encryption process</p> </li> <li> </li> </ul>"},{"location":"AWS/#envolope-encryption-process-is-used-to-avoid-the-transfer-of-big-data-files-into-kms-server-instead-it-would-just-transfer-just-the-data-key-over-the-network","title":"envolope encryption process is used to avoid the transfer of big data files into kms server , instead it would just transfer just the data key over the network.","text":""},{"location":"AWS/#sqs","title":"SQS","text":"<ul> <li>usecase -&gt; its a pull based queue service sitting between the receiving end and the output receiving end. API calls are made to poll the events from queue</li> <li>every item has a visibility timeout (30sec), if the event is not processed within the time limits, its pushed back onto the queue to reprocess.</li> <li>default retention period of sqs is 4 days and each item can be &lt;=250kb</li> </ul> <p>two types of queue are presnet</p> <ol> <li>standard (default, allows duplicated and can be unordered)</li> <li> <p>FIFO (ordered queue , rate limit at 300 TPS)</p> </li> <li> <p>Delays can be introduced into the SQS to properly allow the functioning of async operations. default is 0 , max is 900 seconds</p> </li> <li> <p>if file size is &gt;256kb , can use s3 to store the data, in order to perform this the components needed are</p> </li> <li> <p>SQS Extended client for java</p> </li> <li>aws sdk java</li> </ol> <p></p>"},{"location":"AWS/#sns","title":"SNS","text":"<ul> <li>simple notification service , used a pub/sub model to deliver notifications</li> <li>a topic is created and all the consumers subscribe to that topic</li> <li>can be used to trigger lambda functions</li> </ul>"},{"location":"AWS/#ses","title":"SES","text":"<ul> <li>simple email service , its similar to SNS but only for emails , supports both incoming and outgoing mails , mails are stored in an s3 bucket.</li> <li>used for marketing , can be used as a trigger to lambda function</li> </ul>"},{"location":"AWS/#kinesis","title":"Kinesis","text":"<ul> <li> <p>service to provide real time data analyis services , three different types</p> </li> <li> <p>kinesis streams</p> </li> <li>kinesis data firehose</li> <li>data analytics</li> </ul> <p></p>"},{"location":"AWS/#streams","title":"streams","text":"<ul> <li>mainly used for data stream analysis or video analysis</li> <li>the whole input stream is divided into multiple shards which define the rate limit of the stream</li> <li>can connect to lambda for processing and store in s3, or emr or redshift</li> </ul>"},{"location":"AWS/#data-firehose","title":"data firehose","text":"<ul> <li>similar to streams but has no shards or no retention</li> <li>directly stores data onto the storage units</li> </ul>"},{"location":"AWS/#data-analytics","title":"data analytics","text":"<ul> <li>sits in between the kinesis stream and the storage units</li> <li>can run on demands sql queries related to BI and store the results in storage units</li> </ul>"},{"location":"AWS/#consumers","title":"consumers","text":"<ul> <li>The kinesis provides a Client library which handles the connections between the consumers and the shards</li> <li>its a one:many relation , one consumer can process multiple shards.</li> <li>whenever a reshard occurs the client library handles the load balancing of the consumers.</li> </ul>"},{"location":"AWS/#elastic-bean-stack","title":"Elastic Bean Stack","text":"<ul> <li>PaaS service , which handles all the infrastructer and deploys the applications</li> <li>supports docker container or recommended servers</li> </ul>"},{"location":"AWS/#deployment-options","title":"deployment options","text":"<ul> <li>for this use case consider all the instances running v1 and need to update to v2</li> </ul> <ol> <li>All at once:    In this case , all the existing instances are deployed at once , the system is offline during the deployment phase , suitable for testing</li> <li>rolling:    In this case , the instances are divided into batches and each batch is updated concurrently , suitable for less load servers</li> <li>rolling with additional batch :    In this case , a additional batch of instances of batch size is initialized , and the batches are deployed by concurrently , no down time of the servers</li> <li>immutable:    In this case, new instance for each existing instance is initialized before deployment, after the complete deployment the intances are swapped , no down time, preferrable for production servers</li> </ol>"},{"location":"AWS/#traffic-splitting","title":"traffic splitting","text":"<ul> <li>In case of immutatble deployment option, a portion of traffic is routed to the new version for a test period, post test pass checks, the slots are swapped.</li> </ul>"},{"location":"AWS/#advanced-ebs","title":"Advanced EBS","text":""},{"location":"AWS/#script-files","title":"Script Files","text":"<ul> <li>In pre amazon linux 2 environments, all the configurations such as packages to install, shell commands, creating users, enabling services,configuring load balanncers are present in the .config file</li> <li>the .config file should be located in the .ebconfig folder at the root dir</li> </ul> <ul> <li> <p>In latest versions, the same functionalities are divided into different sections offering modularity</p> </li> <li> <p>BuildFile</p> </li> <li> <p>used to run commands that run for a short time and exit</p> </li> <li> <p>format --&gt; :<code>&lt;command&gt;</code> <li> <p>ProcFile</p> </li> <li> <p>used for running long commands post start of instance   </p> </li> <p>3.PlatformHooks</p> <ul> <li>this files are used to run scripts after the environment is set up in the EBS. Different scripts can be run at different stages of the application runtime.</li> </ul> <p></p>"},{"location":"AWS/#rds-connections","title":"RDS Connections","text":"<ul> <li>If an RDS instance is included during the build process of the EBS instance, whenever we terminate the instace the RDS will be terminated and lost.</li> <li>To avoid this we can create the RDS instance seperately and include both EBS and RDS inside a security group and pass the database connection details as environment variables.</li> </ul>"},{"location":"AWS/#cicd","title":"CI/CD","text":"<ul> <li>aws provides option of maintaining an git repository through codeRepostiory service</li> </ul>"},{"location":"AWS/#codedeploy","title":"codeDeploy","text":"<ul> <li> <p>provided options for code deployment</p> </li> <li> <p>in-place deployment (replace each instance, will be having reduced performance)</p> </li> <li> <p>blue/green deployment (new instances are issued and new verision is deployed in the green instance, onSuccess the traffic is routed to the new version and the slots are swapped)</p> </li> <li> <p>All the main aspects of the deployment life cycle and configuration files should be present in the <code>appspec.yml</code> file</p> </li> <li>example of appsec.yml file</li> </ul> <p></p> <ul> <li> <p>The phases of the deployment life cycle</p> </li> <li> <p>beforeBlockTraffic (tasks before de-regestering from load balancer)</p> </li> <li>blockTraffic (task to de-register from load balancer)</li> <li>afterBlockTraffic (tasks post de-registering from load balancer)</li> <li>applicationStop (tasks to stop the application)</li> <li>DownloadBundle (fetch resources from the repo.)</li> <li>BeforeInstall (backing up current version)</li> <li>Install (copy files to the dest.)</li> <li>postInstall (clean up scripts, set permissions)</li> <li>ApplicationStart</li> <li>ValidateStart</li> </ul> <p></p>"},{"location":"AWS/#codepipeline","title":"CodePipeline","text":"<ul> <li>All the stages of the deployments can be included into a pipeline</li> <li>It used triggers of cloudWatch to look for changes and initiate pipeline</li> </ul>"},{"location":"AWS/#ecs","title":"ECS","text":"<ul> <li>Elastic Container Service - orchestration service</li> <li>service to run containers on ec2 instances, each container has its own virtual env, which are run on docker containers</li> <li> <p>Two different options are provided</p> </li> <li> <p>Running on ec2 instances (option to manage the underlying arch,)</p> </li> <li> <p>AWS Fargate (serverless containers, aws manages the ec2 instances)</p> </li> <li> <p>All the images meants for ECS are stored in Elastic Container Registry</p> </li> </ul>"},{"location":"AWS/#cloudformation","title":"CloudFormation","text":"<ul> <li>service used to allocate resources based on a template</li> <li>used to allocate many resource at a single task , it creates a stack and run's all the queries in the json file</li> <li>all the required instances are defined in the <code>resources</code> section</li> <li>includes import and export features, to include the features of one template into another and chain the stacks</li> <li> <p>in the cloudFormation.yaml file</p> </li> <li> <p>cfn-init is used to retrieve metadata, install packages, create files and start services</p> </li> <li> <p>cfn-signal is used to indicate the completion of a process in the stack</p> </li> <li> <p>deletion</p> </li> </ul>"},{"location":"AWS/#severless-application-model","title":"Severless Application Model","text":"<ul> <li>this service is used mainly to create serverless application instances based on the cloudFormation template</li> <li>uses the functions <code>package</code> and <code>deploy</code> for its operations</li> <li>The sam cli can be used to test before deployment of the resources</li> <li> <p>use case testing a lambda function before deployment</p> </li> <li> <p>use <code>sam local start-lambda</code></p> </li> <li>this would create a docker container to simulate the environment along with mocking if the service requires access to s3 or dynamodb</li> <li>creates a local endpoint (localhost://3000)</li> <li>invoke the function using <code>sam local invoke</code></li> <li>whenever a request arrives at the local end point , the cli routes it to the appropriate docker container and executes it</li> </ul>"},{"location":"AWS/#cdk","title":"CDK","text":"<ul> <li>service which is used to allocate and deploy resources based on a code.</li> <li> <p>the components of the cdk include</p> </li> <li> <p>App context (main object)</p> </li> <li>Stack (container which is used to define resources)</li> <li> <p>constructs (individual items inside stack which define the resources)</p> </li> <li> <p>The CDK code is compiled into a cloudFormation template post which it's pushed onto the cloudFormation stack.</p> </li> </ul> <p></p>"},{"location":"AWS/#cloudwatch","title":"cloudWatch","text":"<ul> <li>service to monitor the aws services</li> <li>can be attached to any instance and fetch information at a defined regular intervals</li> <li>can install a cloudWatch agent in ec2 instances to collect operating system level information</li> <li>can create alarms and triggers use the metrics</li> </ul>"},{"location":"AWS/#codeguru","title":"CodeGuru","text":"<ul> <li>service to provide a profiler for application running in aws services or on-premises</li> <li> <p>A profiler consits of</p> </li> <li> <p>agent - which is installed on application and sends its runtime state to the profiler</p> </li> <li>console - provides data viz of the performance</li> <li> <p>api - manage all the profiling groups</p> </li> <li> <p>this service can be attached to an repository to perform code analyis and provide recommendations</p> </li> </ul>"},{"location":"AWS/#aws-directlink-privatelink","title":"AWS DirectLink , PrivateLink","text":"<ul> <li> <p>DirectLink</p> </li> <li> <p>dedicated infrastrcuter provided between the aws resources and the on-prem servers, avoid network traffic congestion</p> </li> <li> <p>useful for tranferring large datasets, hybrid cloud archs,cost-effective data transfers</p> </li> <li> <p>PrivateLink</p> </li> <li> <p>this service is used to create a secure tunnel between the aws resources of other accounts, this avoid connection to the public internet</p> </li> <li>useful for secure access and maintaining data privacy</li> </ul>"},{"location":"AWS/#aws-cli","title":"AWS CLI","text":"<ul> <li> <p>the order of presedence in fetching the credentials</p> </li> <li> <p>runtime (terminal or sdk runtime)</p> </li> <li>environment variables</li> <li>./aws/credentials</li> <li>./aws/config</li> <li>ecs containers</li> <li>ec2 instance profiles</li> </ul>"},{"location":"AWS/#mock-test-important-topics","title":"Mock Test Important Topics","text":""},{"location":"AWS/#cloudwatch-agent-vs-athena-queries-on-s3-storage","title":"CloudWatch Agent vs. Athena Queries on S3 Storage","text":"<ul> <li>CloudWatch Agents: Used for monitoring resources.</li> <li>Athena Queries: Used for log analysis, business intelligence, and making reports.</li> </ul>"},{"location":"AWS/#reserved-concurrency-vs-provisioned-concurrency","title":"Reserved Concurrency vs. Provisioned Concurrency","text":"<ul> <li>Reserved Concurrency: Indicates the maximum instances of the Lambda function that can be invoked.</li> <li>Provisioned Concurrency: Indicates the number of instances that are always available to reduce wake-up time.</li> </ul>"},{"location":"AWS/#when-to-use-system-parameter-store-vs-secrets-manager","title":"When to Use System Parameter Store vs. Secrets Manager","text":"<ul> <li>Use System Parameter Store for non-sensitive data and configuration values.</li> <li>Use Secrets Manager for managing sensitive information like database credentials, API keys, etc.</li> </ul>"},{"location":"AWS/#cloudwatch-metrics-costs","title":"CloudWatch Metrics Costs","text":"<ul> <li>Metrics that incur costs include custom metrics, detailed monitoring for EC2 instances, and additional metrics for certain AWS services.</li> </ul>"},{"location":"AWS/#lambda-function-alias","title":"Lambda Function Alias","text":"<ul> <li>Used as a pointer to the version of the function available for deployment.</li> </ul>"},{"location":"AWS/#strongly-consistent-vs-eventually-consistent","title":"Strongly Consistent vs. Eventually Consistent","text":"<ul> <li>Strongly Consistent: Ensures immediate consistency across all copies.</li> <li>Eventually Consistent: Ensures consistency over time, not immediately.</li> </ul>"},{"location":"AWS/#mfa-authentication-using-cli","title":"MFA Authentication Using CLI","text":"<ul> <li>Use <code>sts get-session-token</code> to receive temporary credentials valid for 1 hour.</li> </ul>"},{"location":"AWS/#appspecyaml-file","title":"Appspec.yaml File","text":"<ul> <li>Used in CodeDeploy to configure security and permissions.</li> </ul>"},{"location":"AWS/#eb-cli-commands","title":"EB CLI Commands","text":"<ul> <li>Commands include <code>-r</code> (region), <code>-ip</code> (instance profile), <code>-c</code> (subdomain), <code>-db</code> (relational database), <code>-db.i</code> (specify instance type), <code>-es</code> (enable spot instances), <code>-it</code> (list of EC2 instances required during deployment).</li> </ul>"},{"location":"AWS/#phi-and-pii-data-types","title":"PHI and PII Data Types","text":"<ul> <li>PHI: Protected Health Information.</li> <li>PII: Personally Identifiable Information.</li> </ul>"},{"location":"AWS/#aws-swf","title":"AWS SWF","text":"<ul> <li>Service orchestration similar to Step Functions but used for large-scale workflows, capable of running workflows for months.</li> </ul>"},{"location":"AWS/#amazon-macie","title":"Amazon Macie","text":"<ul> <li>Service used to detect confidential information (PHI and PII data types) in S3 buckets using classification algorithms.</li> </ul>"},{"location":"AWS/#aws-privatelink","title":"AWS PrivateLink","text":"<ul> <li>Allows resources inside a VPC to connect to services privately without exposing data to the public internet.</li> </ul>"},{"location":"AWS/#aws-identity-center","title":"AWS Identity Center","text":"<ul> <li>Provides identity provider (IdP) and service provider (SP) services to the workforce.</li> </ul>"},{"location":"AWS/#event-source-mapping-lambda-functions","title":"Event Source Mapping (Lambda Functions)","text":"<ul> <li>Invocation of a function based on an SQS event.</li> </ul>"},{"location":"AWS/#aws-ad-services","title":"AWS AD Services","text":"<ul> <li>Fully managed Microsoft AD on AWS Cloud, provides an adaptor to bridge on-premise AD and AWS resources.</li> </ul>"},{"location":"AWS/#aws-snowball-edge","title":"AWS Snowball Edge","text":"<ul> <li>Used for data transfer and edge computing.</li> </ul>"},{"location":"AWS/#iam-identity-based-policies-vs-iam-resource-based-policies","title":"IAM Identity-Based Policies vs. IAM Resource-Based Policies","text":"<ul> <li>Identity-Based Policies: Attached to IAM users, roles, or groups to define what actions an identity can perform.</li> <li>Resource-Based Policies: Attached directly to resources, defining who can access them.</li> </ul>"},{"location":"AWS/#waf-use-cases","title":"WAF Use Cases","text":"<ul> <li>Protection against SQL injection, cross-site scripting, DDoS attacks, IP filtering, and restriction to specific URIs.</li> </ul>"},{"location":"AWS/#cloudtrail-vs-cloudwatch","title":"CloudTrail vs. CloudWatch","text":"<ul> <li>CloudTrail: Logs, API analytics, and security investigations.</li> <li>CloudWatch: Performance monitoring, application-level monitoring.</li> </ul>"},{"location":"AWS/#s3-security-best-practices","title":"S3 Security Best Practices","text":"<ul> <li>Use encryption, access control, and logging for securing S3 data.</li> </ul>"},{"location":"AWS/#ec2-agent","title":"EC2 Agent","text":"<ul> <li>Similar to CloudWatch agent, focusing on management of EC2 instances.</li> </ul>"},{"location":"AWS/#using-codedeploy-to-launch-instances-in-microsoft-azure","title":"Using CodeDeploy to Launch Instances in Microsoft Azure","text":"<ul> <li>Install a CodeDeploy agent on the VM in another cloud provider to make it detectable in the CodeDeploy dashboard.</li> </ul>"},{"location":"AWS/#availability-of-kms-across-different-regions","title":"Availability of KMS Across Different Regions","text":"<ul> <li>KMS is region-specific and keys cannot be transferred using AWS Direct Connect.</li> </ul>"},{"location":"AWS/#sts-options-for-getting-tokens-and-changing-token-validity-time","title":"STS Options for Getting Tokens and Changing Token Validity Time","text":"<ul> <li>Options include <code>AssumeRole</code>, <code>AssumeRoleWithSAML</code>, <code>AssumeRoleWithWebIdentity</code>.</li> </ul>"},{"location":"AWS/#key-policy-in-kms","title":"Key Policy in KMS","text":"<ul> <li>Each KMS key has a policy attached to it, defining the identities who can use the key.</li> </ul>"},{"location":"AWS/#default-retention-period-of-cloudwatch","title":"Default Retention Period of CloudWatch","text":"<ul> <li>2 weeks (14 days).</li> </ul>"},{"location":"AWS/#aws-ssm-agent-and-amazon-quicksight","title":"AWS SSM Agent and Amazon QuickSight","text":"<ul> <li>SSM Agent: Installed on EC2, sends details about patches, inventory, and configurations to the System Manager.</li> <li>Amazon QuickSight: BI service for data visualization.</li> </ul>"},{"location":"AWS/#log-locations-of-different-services-in-ec2-instance","title":"Log Locations of Different Services in EC2 Instance","text":"<ul> <li><code>app/access.log</code>: Info about the CodeDeploy agent.</li> <li><code>/var/log/messages</code>: Directory containing all logs.</li> <li><code>/etc/awslogs/awslogs.conf</code>: Info about the CloudWatch agent.</li> </ul>"},{"location":"AWS/#specifying-resources-required-in-ebs-deployment","title":"Specifying Resources Required in EBS Deployment","text":"<ul> <li>Use configuration files and CLI commands to specify resources.</li> </ul>"},{"location":"AWS/#when-to-use-aws-pricing-api","title":"When to Use AWS Pricing API","text":"<ul> <li>For complex architectures, to fetch all price values in JSON format.</li> </ul>"},{"location":"AWS/#filters-in-dynamodb","title":"Filters in DynamoDB","text":"<ul> <li>Annotations can be used for filter expressions. <code>GetTraceSummaries</code> API is used for grouping annotations.</li> </ul>"},{"location":"AWS/#debugging-lambda-functions","title":"Debugging Lambda Functions","text":"<ul> <li>Use CloudWatch logs and X-Ray for debugging.</li> </ul>"},{"location":"AWS/#secondary-indexes-in-dynamodb","title":"Secondary Indexes in DynamoDB","text":"<ul> <li>Used to query data more efficiently.</li> </ul>"},{"location":"AWS/#key-grants-in-aws-kms-and-providing-temporary-access-to-kms-keys","title":"Key Grants in AWS KMS and Providing Temporary Access to KMS Keys","text":"<ul> <li>Key grants provide temporary access to KMS keys.</li> </ul>"},{"location":"AWS/#approving-every-stage-in-code-deployment-pipeline-before-deployment","title":"Approving Every Stage in Code Deployment Pipeline Before Deployment","text":"<ul> <li>Use manual approval actions in CodePipeline.</li> </ul>"},{"location":"AWS/#lambda-power-tuning","title":"Lambda Power Tuning","text":"<ul> <li>Tool to run several concurrent versions of Lambda functions at different memory configurations.</li> </ul>"},{"location":"AWS/#cloudwatch-emf","title":"CloudWatch EMF","text":"<ul> <li>Embedded Metric Format used to publish logs to CloudWatch in a custom format.</li> </ul>"},{"location":"AWS/#jwt-structure","title":"JWT Structure","text":"<ul> <li>Consists of three sections: Header, Payload, and Signature.</li> </ul>"},{"location":"AWS/#aws-x-ray","title":"AWS X-Ray","text":"<ul> <li>Used to find specific services with errors and high latency. The X-Ray daemon sends data to the API for analytics.</li> </ul>"},{"location":"AWS/#instance-type-incompatibility-with-elastic-beanstalk","title":"Instance Type Incompatibility with Elastic Beanstalk","text":"<ul> <li>Capacity reserved instances are incompatible with Elastic Beanstalk as they handle instance creation dynamically.</li> </ul>"},{"location":"AWS/#aws-sdk-client-for-s3","title":"AWS SDK Client for S3","text":"<ul> <li>Can be used for client-side encryption before passing data to S3.</li> </ul>"},{"location":"AWS/#when-to-use-codepipeline-vs-cloudformation","title":"When to Use CodePipeline vs. CloudFormation","text":"<ul> <li>CodePipeline: For automated code delivery.</li> <li>CloudFormation: For automated provisioning.</li> </ul>"},{"location":"AWS/#websocket-api-in-api-gateway","title":"WebSocket API in API Gateway","text":"<ul> <li>Enables long-time connections with low latency.</li> </ul>"},{"location":"AWS/#aws-transfer-family-and-global-accelerator","title":"AWS Transfer Family and Global Accelerator","text":"<ul> <li>AWS Transfer Family: For setting up SFTP, FTP servers.</li> <li>Global Accelerator: Improves traffic performance using AWS network infrastructure, reducing latency.</li> </ul>"},{"location":"AWS/#aws-database-migration-service","title":"AWS Database Migration Service","text":"<ul> <li>Moves on-premises databases to AWS, supports AWS-to-AWS migrations, and converts between different database services (e.g., MySQL to PostgreSQL).</li> </ul>"},{"location":"AWS/#unauthorized-or-anonymous-access-in-aws-cognito","title":"Unauthorized or Anonymous Access in AWS Cognito","text":"<ul> <li>Create a <code>guest_role</code> for identity pools to define resources accessible by guest users.</li> </ul>"},{"location":"AWS/#amazon-rekognition-and-amazon-comprehend","title":"Amazon Rekognition and Amazon Comprehend","text":"<ul> <li>Amazon Rekognition: Image and video analysis, object and scene detection, facial analysis, OCR, content moderation.</li> <li>Amazon Comprehend: Natural language processing, sentiment analysis, entity recognition, topic modeling, key phrase extraction, language detection.</li> </ul>"},{"location":"AWS/#aws-appconfig-aws-msk-aws-appsync","title":"AWS AppConfig, AWS MSK, AWS AppSync","text":"<ul> <li>AWS AppConfig: Manages application configurations, controls feature rollouts.</li> <li>AWS MSK: Managed streaming Kafka service for microservices and event-driven architectures.</li> <li>AWS AppSync: Service to build data-driven apps with real-time updates and offline capabilities.</li> </ul>"},{"location":"AWS/#additional-resources","title":"Additional Resources","text":""},{"location":"AzureDev/","title":"Azure Developer Associate","text":"<p><code>Credits</code> - Microsoft Learning</p>"},{"location":"AzureDev/#azure-fundamentals","title":"Azure Fundamentals","text":""},{"location":"AzureDev/#shared-responsibility-model","title":"shared responsibility model","text":"<p>In this model, the responsibilites are shared between the cloud provider and the client, for instance in case of cloud SQL server, the provider is responsible for setting up the instances whereas the client is responsible for data ingestion and providing access.</p> <p>Different Cloud Service types</p> <pre><code>1. Infrastructure as a Service (IAAS) - client is most responsible - Lift and shift\n2. Platform as a Service (PAAS) - middle ground - Development Kits\n3. Software as a Service (SAAS) - cloud provider is most responsible - Email Service\n</code></pre> <p></p>"},{"location":"AzureDev/#vertical-scaling","title":"Vertical Scaling","text":"<p>The ability to add more compute power, in case of app development adding more cpu power is vertical scaling</p>"},{"location":"AzureDev/#horizontal-scaling","title":"Horizontal scaling","text":"<p>The ability to add more machines or containers to support the demand(either auto or manual)</p>"},{"location":"AzureDev/#az204-azure-app-service","title":"AZ:204 - Azure App service","text":""},{"location":"AzureDev/#azure-app-service","title":"Azure App service","text":"<pre><code>HTTP-based service for hosting web application , REST API's and back ends. Runs on both linux and windows environments.\n</code></pre> <ul> <li> <p>Components of the App service</p> </li> <li> <p>Operating System (Windows, Linux)</p> </li> <li>Region (West US, East US, etc.)</li> <li>Number of VM instances</li> <li>Size of VM instances (Small, Medium, Large)</li> <li>Pricing tier (Free, Shared, Basic, Standard, Premium, PremiumV2 PremiumV3, Isolated, IsolatedV2)</li> <li> <p>Deployment</p> </li> <li> <p>Azure DevOps Services: You can push your code to Azure DevOps Services, build your code in the cloud, run the tests, generate a release from the code, and finally, push your code to an Azure Web App.</p> </li> <li>GitHub: connect production branch to directly make changes to App service.</li> <li>Bitbucket: With its similarities to GitHub, you can configure an automated deployment with Bitbucket.</li> </ul> <p>Manual:</p> <ul> <li>CLI: webapp up is a feature of the az command-line interface that packages your app and deploys it. Unlike other deployment methods, az webapp up can create a new App Service web app for you if you haven't already created one.</li> <li>Zip deploy: Use curl or a similar HTTP utility to send a ZIP of your application files to App Service.</li> <li>FTP/S: FTP or FTPS is a traditional way of pushing your code to many hosting environments, including App Service.</li> </ul> <p>We can use deployment swaps method to save time , in this method we deploy to staging and swap the production build.</p>"},{"location":"AzureDev/#security","title":"Security","text":""},{"location":"AzureDev/#azure-app-service-authentication-providers","title":"Azure App service Authentication providers","text":"Provider Sign-in endpoint How-To guidance Microsoft identity platform /.auth/login/aad App Service Microsoft identity platform login Facebook /.auth/login/facebook App Service Facebook login Google /.auth/login/google App Service Google login Twitter /.auth/login/twitter App Service Twitter login Any OpenID Connect provider /.auth/login/providername App Service OpenID Connect login GitHub /.auth/login/github App Service GitHub login"},{"location":"AzureDev/#how-it-works","title":"how it works","text":"<p>Both the authetication and Authorization modules run in same sandbox, before the http request hit the App service they are processed.services provided by this module are</p> <ul> <li>validate, store and refresh OAuth tokens provided by identity providers</li> <li>Manage the authenticated sessions</li> <li>inject identity information into http headers</li> </ul>"},{"location":"AzureDev/#authentication-flow","title":"Authentication Flow","text":"Step Without provider SDK With provider SDK Sign user in Redirects client to /.auth/login/provider. Client code signs user in directly with provider's SDK and receives an authentication token. For information, see the provider's documentation. Post-authentication Provider redirects client to /.auth/login/provider/callback. Client code posts token from provider to /.auth/login/provider for validation. Establish authenticated session App Service adds authenticated cookie to response. App Service returns its own authentication token to client code. Serve authenticated content Client includes authentication cookie in subsequent requests (automatically handled by browser). Client code presents authentication token in X-ZUMO-AUTH header (automatically handled by Mobile Apps client SDKs)."},{"location":"AzureDev/#two-options-are-provided-for-authentication","title":"Two options are provided for authentication:","text":"<ul> <li>without provider sdk: The browser app provides the auth login page to the user, the server code manages the sign in process thus making it server-directed flow</li> <li>with provider sdk: The client application signs into the provider manually and submits the token to the App server, this is client-directed flow and mainly used in browser-less apps, RestAPI's, Azure functions</li> </ul>"},{"location":"AzureDev/#authorization-modes","title":"Authorization Modes","text":"<ul> <li>unauthenticated --&gt; The App Server allows unautheticated traffic to App server, can add a step to inject http headers.</li> <li>authenticated --&gt; The App server rejects all the unauth traffic, a redirect is issued to <code>.\\auth\\login\\&lt;provider&gt;</code></li> </ul>"},{"location":"AzureDev/#token-store","title":"Token Store","text":"<p>App Service provides in-built token store at the init of the application, when authetication is enabled with any provider a default token store is provided.</p>"},{"location":"AzureDev/#networking","title":"Networking","text":"<p>In Standard plans , all the Apps in the service run under the same worker node, similarly all the outbound addresses for the application are shared. All the possible IP's are listed under the <code>possibleOutboundIPAddresses</code> property.</p> <p>in azure shell</p> <pre><code>az webapp show \\\n    --resource-group &lt;group_name&gt; \\\n    --name &lt;app_name&gt; \\\n    --query outboundIpAddresses \\\n    --output tsv\n</code></pre>"},{"location":"AzureDev/#application-settings","title":"Application Settings","text":"<p>All the environmental variables of the application are controller through appSettings Configuaration file, this files will be used for connecting to Azure MySQL servers in production env. , the contents of web.config and appsettings.json by default are used for development env.</p>"},{"location":"AzureDev/#security-certificates","title":"Security Certificates","text":"<p>A certificate is shared between app services in the same resourceGroup and region combination.</p> Option Description Create a free App Service managed certificate A private certificate that's free of charge and easy to use if you just need to secure your custom domain in App Service. Purchase an App Service certificate A private certificate that's managed by Azure. It combines the simplicity of automated certificate management and the flexibility of renewal and export options. Import a certificate from Key Vault Useful if you use Azure Key Vault to manage your certificates. Upload a private certificate If you already have a private certificate from a third-party provider, you can upload it. Upload a public certificate Public certificates aren't used to secure custom domains, but you can load them into your code if you need them to access remote resources. <p>All the certifcates purchased through azure are stored in <code>azure keyValut</code></p>"},{"location":"AzureDev/#metrics-for-autoscale","title":"Metrics for AutoScale","text":"<p>Autoscaling by metric requires that you define one or more autoscale rules. An autoscale rule specifies a metric to monitor, and how autoscaling should respond when this metric crosses a defined threshold. The metrics you can monitor for a web app are:</p> <ul> <li>CPU Percentage. This metric is an indication of the CPU utilization across all instances. A high value shows that instances are becoming CPU-bound, which could cause delays in processing client requests.</li> <li>Memory Percentage. This metric captures the memory occupancy of the application across all instances. A high value indicates that free memory could be running low, and could cause one or more instances to fail.</li> <li>Disk Queue Length. This metric is a measure of the number of outstanding I/O requests across all instances. A high value means that disk contention could be occurring.</li> <li>Http Queue Length. This metric shows how many client requests are waiting for processing by the web app. If this number is large, client requests might fail with HTTP 408 (Timeout) errors.</li> <li>Data In. This metric is the number of bytes received across all instances.</li> <li>Data Out. This metric is the number of bytes sent by all instances.</li> </ul> <p>A duration is defined for capturing the Autoscale metrics , the whole duration is divided into equal time grains.</p>"},{"location":"AzureDev/#slot-swapping","title":"slot swapping","text":"<p>The following is carried out during swap</p> <ul> <li>All the settings of the target(production build) are copied into source slot</li> <li>HTTP requests are sent to all instances in the source , if a response is recived the slot is considered warmed up.</li> <li>Once All the instances are warmed up, the route configurations are swapped to route the traffic to new slot</li> </ul>"},{"location":"AzureDev/#routing","title":"Routing","text":"<p>To get user feedback for the new features, a portion of the production traffic can be routed to the new staging slot randomly. The user is pointed to the staging slot until the end of client session. A cookie <code>x-ms-routing-name=staging</code> indicates the same.</p> <ul> <li>Azure WebJob contents --&gt; these are the background workers which process specific tasks on http requests or message queues</li> <li>Azure webjob schedulers --&gt; these are background workers which trigger on a scheduled basis mainly used for data synchronization.</li> </ul>"},{"location":"AzureDev/#azure-functions","title":"Azure Functions","text":"<p>Azure functions are similar to WebJobs of the App Service , but have more flexible triggers and standalone properties. It is also similar to Azure Logic Apps in terms of functionality but has a different development approach, Logic Apps are design driven where as Functions are code-first architecture.</p> <p><code>functionAppScaleLimit</code> is used to fix the scale Limit for the Azure Function lies in range(0-max(200))</p> <p>A function contains two components code and config.json file, A function can have only one trigger.</p>"},{"location":"AzureDev/#function-app","title":"Function App","text":"<p>A Function App is a holder for all the functions, all the items share same deployment method and runtime.</p> <p>Data required for the functions is passed as parameters and the function returns the output. No services are connected in this way.</p> <p><code>dataType</code> property is used to define the binding type, it's required in interpretted languages, in compiled languages the type is inferred from runtime.</p> <p>useCase --&gt; whenever a message is added to Azure Queue , add a table row to Azure table Storage.</p> <pre><code>{\n  \"bindings\": [\n    {\n      \"type\": \"queueTrigger\",\n      \"direction\": \"in\",\n      \"name\": \"order\",\n      \"queueName\": \"myqueue-items\",\n      \"connection\": \"MY_STORAGE_ACCT_APP_SETTING\"\n    },\n    {\n      \"type\": \"table\",\n      \"direction\": \"out\",\n      \"name\": \"$return\",\n      \"tableName\": \"outTable\",\n      \"connection\": \"MY_TABLE_STORAGE_ACCT_APP_SETTING\"\n    }\n  ]\n}\n</code></pre> <ul> <li><code>type</code> --&gt; trigger type</li> <li><code>direction</code> --&gt; data binding direction (in,out)</li> <li><code>name</code> --&gt; data parameter</li> <li><code>queueName</code> --&gt; name of queue column (name of the trigger)</li> <li><code>connection</code> --&gt; connection String</li> </ul> <p>The Functions can also be triggered using class libraries , in this case the function.json file is not required.</p> <p>e.g</p> <pre><code>public static class QueueTriggerTableOutput\n{\n    [FunctionName(\"QueueTriggerTableOutput\")]\n    [return: Table(\"outTable\", Connection = \"MY_TABLE_STORAGE_ACCT_APP_SETTING\")]\n    public static Person Run(\n        [QueueTrigger(\"myqueue-items\", Connection = \"MY_STORAGE_ACCT_APP_SETTING\")]JObject order,\n        ILogger log)\n    {\n        return new Person() {\n                PartitionKey = \"Orders\",\n                RowKey = Guid.NewGuid().ToString(),\n                Name = order[\"Name\"].ToString(),\n                MobileNumber = order[\"MobileNumber\"].ToString() };\n    }\n}\n\npublic class Person\n{\n    public string PartitionKey { get; set; }\n    public string RowKey { get; set; }\n    public string Name { get; set; }\n    public string MobileNumber { get; set; }\n}\n</code></pre> <p>All the required parameters are passed in the class as annotations.</p> <ul> <li>HTTP Triggers</li> </ul>"},{"location":"AzureDev/#azure-blob-storage","title":"Azure Blob Storage","text":"<p>Three types of resources</p> <ul> <li>Storage Account - endpoint of the azure storage blob e.g mystorageaccount</li> </ul> <p><code>http://mystorageaccount.blob.core.windows.net</code></p> <ul> <li>container -&gt; organizes a set of blobs , a storage account can have unlimited containers</li> </ul> <p><code>https://myaccount.blob.core.windows.net/mycontainer</code></p> <ul> <li>blobs</li> <li>block blobs - text and binary</li> <li>append blobs - logs</li> <li>page blobs - images for vm</li> </ul> <p><code>https://myaccount.blob.core.windows.net/mycontainer/myvirtualdirectory/myblob</code></p>"},{"location":"AzureDev/#security_1","title":"Security","text":"<p>All files stored in azure storage are by default encrypted with 256 bit AES. A user can choose manual encryption by adding a key in microsoft valut</p> <ul> <li>customer managed key - A specific key is used to encrypt all the incoming data</li> <li>customer provided key - A key is provided in the request to read or write data in azure storage</li> </ul>"},{"location":"AzureDev/#blob-lifecycle-policies","title":"blob lifecycle policies","text":"<p>Any rule in a policy contains a filter set and a action set, filter set defines a set of data blobs and action set defines a particular action to be performed on the filtered set</p>"},{"location":"AzureDev/#rehydrate-blob","title":"Rehydrate blob","text":"<p>Once a blob is in archive tier its considered as an offline resource, to make it alive , two options</p> <ul> <li>copy the contents of the blob to a new cool or hot tier blob</li> <li>set the existing blob to new tier</li> </ul>"},{"location":"AzureDev/#azure-storage-client","title":"Azure Storage Client","text":"<p>Azure storage provides classes for .NET to interact with the storage</p> Class Description BlobServiceClient Represents the storage account, and provides operations to retrieve and configure account properties, and to work with blob containers in the storage account. BlobContainerClient Represents a specific blob container, and provides operations to work with the container and the blobs within. BlobClient Represents a specific blob, and provides general operations to work with the blob, including operations to upload, download, delete, and create snapshots. AppendBlobClient Represents an append blob, and provides operations specific to append blobs, such as appending log data. BlockBlobClient Represents a block blob, and provides operations specific to block blobs, such as staging and then committing blocks of data. <ul> <li>exercise to create blob storage using asp.net sdk client</li> </ul> <p>/az-204/azblob/program.cs</p> <ol> <li>create a new dotnet console app</li> <li>add the azure sdk dependency</li> <li>create a storage account , set up a container in it</li> <li>use the BlobContainer class to update contents to it</li> <li>clean up</li> </ol>"},{"location":"AzureDev/#http-header-for-blobs","title":"HTTP header for blobs","text":"<p>The standard HTTP headers supported on blobs include:</p> <ol> <li>ETag</li> <li>Last-Modified</li> <li>Content-Length</li> <li>Content-Type</li> <li>Content-MD5</li> <li>Content-Encoding</li> <li>Content-Language</li> <li>Cache-Control</li> <li>Origin</li> <li>Range</li> </ol>"},{"location":"AzureDev/#azure-cosmos-db","title":"Azure COSMOS DB","text":"<p>Azure cosmos DB is a NOSQL database which offers multi-master replication across all regions</p> <p>hierarchy</p> <p>DB account --&gt; Databases --&gt; container --&gt; DB Items</p> <p></p> <p>Cosmos DB supports stored procedures in interpretted languages (JS), all the procedures are time bound, during the creation of procedures a boolean return is expected indicating the status of the procedure</p> <p>cosmos DB also offeres</p> <ul> <li>pre triggers --&gt; these are initiated before making changes in the DB , used for formatting data, data validation</li> <li>post triggers --&gt; these are initiated after making a change in DB , used for logging or sending an email</li> </ul> <p>all the triggers are part of an single transaction, i.e if an trigger even fails the whole transaction is rolled back to initial state</p> <p>A change feed is offered for a container in cosmos db , azure .net sdk or java sdk can be used to interact with it.</p> <p>four steps in changed feed processor</p> <ol> <li>connect to the container on which feed is required</li> <li>A lease instance is issued to store the feed temporarily</li> <li>A compute instance is initiated can be a app service or VM or physical</li> <li>bussiness logic associated with change feed</li> </ol>"},{"location":"AzureDev/#azure-container-registry","title":"Azure Container Registry","text":"<p>Azure Container Registry (ACR) hosts all the services for a smooth CI/CD pipelines.</p> <p>different tasks to build and maintain container images</p> <ul> <li>Quick task : build a single image and push to ACR</li> <li>Trigger Update: Source code trigger, Image update</li> <li>Multi updates: upgrades at container level , helm upgrades</li> </ul>"},{"location":"AzureDev/#dockerfile","title":"DockerFile","text":"<p>A Dockerfile is a script that contains a series of instructions that are used to build a Docker image. Dockerfiles typically include the following information:</p> <ul> <li>The base or parent image we use to create the new image</li> <li>Commands to update the base OS and install other software</li> <li>Build artifacts to include, such as a developed application</li> <li>Services to expose, such a storage and network configuration</li> <li>Command to run when the container is launched</li> </ul>"},{"location":"AzureDev/#azure-container-instances","title":"Azure Container Instances","text":"<p>It's a serveless container service in azure, main difference from the ACR is the ability to run container without managing the underlying images, useful for microservices , batch process and it provides various start and stop policies</p> <p>Top level resource in ACI is <code>container-group</code> , it hosts multiple container under same host machine , all the containers share same life-cycle, resources and network connections</p> <p></p> <p>This example container group:</p> <ul> <li>Is scheduled on a single host machine.</li> <li>Is assigned a DNS name label.</li> <li>Exposes a single public IP address, with one exposed port.</li> <li>Consists of two containers. One container listens on port 80, while the other listens on port 5000.</li> <li>Includes two Azure file shares as volume mounts, and each container mounts one of the shares locally.</li> </ul> <p>multi container usecases</p> <ol> <li>a container to host web application , a container to retrive and store logs</li> <li>a container to host front-end , a container to run back-end services</li> </ol>"},{"location":"AzureDev/#container-restart-policy","title":"container restart policy","text":"Restart policy Description Always Containers in the container group are always restarted. This is the default setting applied when no restart policy is specified at container creation. Never Containers in the container group are never restarted. The containers run at most once. OnFailure Containers in the container group are restarted only when the process executed in the container fails (when it terminates with a nonzero exit code). The containers are run at least once."},{"location":"AzureDev/#azure-container-apps","title":"Azure container Apps","text":"<p>This service runs on top of Azure Kubernetes service, mainly used for</p> <ul> <li>deploying api endpoints</li> <li>running background services</li> <li>running microservices</li> <li>handling event-driven services</li> </ul> <p>All container Apps are serviced inside an Container Environment which shares the same virtual network resources and logging storage.</p> <p>Azure container Apps cannot run priviliged apps , no root access is provided to containers and it can run only linux/amd64 based images</p>"},{"location":"AzureDev/#authorization-and-authentication","title":"Authorization and Authentication","text":"<p>Azure containers provide both authN and authZ services when <code>allowInsecure</code> is disabled and require authetication is enabled in the configuration settings.</p> <p>In this Arch , both the authN and authZ run as sidecar containers running parallely.</p> <p></p> <p>services provided by the middleware</p> <ul> <li>authN and authZ operations for selectede identity provider</li> <li>maintain session</li> <li>inject http headers with identity information</li> </ul>"},{"location":"AzureDev/#revisions-and-secrets","title":"revisions and secrets","text":"<ul> <li>revisions : The version management is acheived through revisions, any specific container can have a current revision and can make updates to the current using an revision policy.</li> </ul> <p>All the available revisions can be listed at</p> <p><code>az containerapp revision list</code></p> <ul> <li>secrets : Secrets in container apps are declared at environment level, a change in secret doesn't creat or modify an exisiting revision. secrets are declared using the <code>--secret</code> variable during the init of the container and accessed using <code>secretref:</code></li> </ul>"},{"location":"AzureDev/#dapr-integration","title":"DAPR integration","text":"<p>Dapr --&gt; Distributed Application Runtime</p> <ul> <li>it provides and acts as a medium to allow connections between containers to allow pub/sub messages and service to service call initiations</li> <li>Azure provides dapr and manages updates to it.</li> </ul> <p>Services provided</p> <ol> <li>service to service invocation - this allows discovery of the services andn service to service calls along with authN</li> <li>state management - containers are stateless apps , this provides state for transactions and CRUD opxns</li> <li>pub/sub - communication between containers through a middleware container</li> <li>bindings - triggers to initiate services</li> <li>actors - single thread workers which can be called or invoked through messages</li> <li>observability - used to monitor containers</li> <li>secrets - used to store secrets at dapr environment</li> </ol> <p></p> <p>Dapr runs as side car containers in the container environment to provide services.</p>"},{"location":"AzureDev/#microsoft-identity-platform","title":"Microsoft Identity Platform","text":"<p>Identify platform provides sdk and other options to let users sign in and use API's</p> <p>allows</p> <ul> <li>microsoft entra accounts</li> <li>personal</li> <li>social</li> </ul> <p>when regstering an application to Entra ID , need to mention whether its used by single tenant or group</p> <ul> <li>home tenant : home tenant of an application create an application object</li> <li>others: all other tenants of the application use service objects which are blueprints of the main application object class</li> </ul>"},{"location":"AzureDev/#authorization","title":"Authorization","text":"<ul> <li>Oauth 2.0 : This service allows a third party app to use the application using mrst identity platform</li> <li>access to individual resources is provided by defining a scope, scopes are attached at the end of the resource URI   e.g , accessing calender from the graph API   <code>https://graph.microsoft.com/Calender.Read</code></li> <li>graph --&gt; service provider , Calender.Read --&gt; scope</li> <li> <p>permission types</p> </li> <li> <p>delegate - user or app requests for access</p> </li> <li> <p>app only - consent provided by admin for daemon processes</p> </li> <li> <p>consent types</p> </li> <li> <p>static - provided by admin prior to accessing the app</p> </li> <li>dynamic - request access at run time</li> <li>admin - high previlage access</li> </ul>"},{"location":"AzureDev/#msal","title":"MSAL","text":"<p>the Microsoft Authorization Library offers services to authenticate users using Azure AD and provide access to secured web API's</p> <p>Uses</p> <ul> <li>fetch tokens on behalf of application or an user</li> <li>handles a token cache repository , which auto issues tokens post ttl</li> <li>specify the audience to the application</li> </ul> <p>Different types of authentication</p> Flow Description Authorization code Native and web apps securely obtain tokens in the name of the user Client credentials Service applications run without user interaction On-behalf-of The application calls a service/web API, which in turns calls Microsoft Graph Implicit Used in browser-based applications Device code Enables sign-in to a device by using another device that has a browser Integrated Windows Windows computers silently acquire an access token when they're domain joined Interactive Mobile and desktops applications call Microsoft Graph in the name of a user Username/password The application signs in a user by using their username and password <p>Two different types of application clients are provided in azure</p> <ol> <li>public client - the devices not trusted to store secrets and easy to access, they use web api's to fetch the secrets</li> <li>confidential client - the devices which are trusted and hard to access , all the web api run on these servers.</li> </ol> <p>with MSAL.NET , we can use <code>publicCLientApplicationBuilder</code>, <code>confidentialClientApplicationBuilder</code> methods to create these clients</p> <p>Before the init process of the application , need to register the application in the azure identity, post that fetch the following from the portal</p> <ol> <li>client id --&gt; id of the application</li> <li>identity provider URL</li> <li>tenant ID --&gt; used if the application group tenant application (organization)</li> <li>appication secrets</li> <li>redirectURI - the url to which user should be redirected along with tokens</li> </ol>"},{"location":"AzureDev/#initiating-clients","title":"Initiating Clients","text":"<ul> <li>public client :</li> </ul> <pre><code>IPublicClientApplication app = PublicClientApplicationBuilder.Create(clientId).Build();\n</code></pre> <ul> <li>confidentital client:</li> </ul> <p>need to specify the redirect URI where the app server is running</p> <pre><code>string redirectUri = \"https://myapp.azurewebsites.net\";\nIConfidentialClientApplication app = ConfidentialClientApplicationBuilder.Create(clientId)\n    .WithClientSecret(clientSecret)\n    .WithRedirectUri(redirectUri )\n    .Build();\n</code></pre>"},{"location":"AzureDev/#access-modifiers","title":"Access Modifiers","text":"<p>Access modifiers for public clients</p> Modifier Description .WithAuthority() Sets the application default authority to a Microsoft Entra authority, with the possibility of choosing the Azure Cloud, the audience, the tenant (tenant ID or domain name), or providing directly the authority URI. .WithTenantId(string tenantId) Overrides the tenant ID, or the tenant description. .WithClientId(string) Overrides the client ID. .WithRedirectUri(string redirectUri) Overrides the default redirect URI. This is useful for scenarios requiring a broker. .WithComponent(string) Sets the name of the library using MSAL.NET (for telemetry reasons). .WithDebugLoggingCallback() If called, the application calls Debug.Write simply enabling debugging traces. .WithLogging() If called, the application calls a callback with debugging traces. .WithTelemetry(TelemetryCallback telemetryCallback) Sets the delegate used to send telemetry. <p>Access modifiers for confidential clients</p> Modifier Description .WithCertificate(X509Certificate2 certificate) Sets the certificate identifying the application with Microsoft Entra ID. .WithClientSecret(string clientSecret) Sets the client secret (app password) identifying the application with Microsoft Entra ID."},{"location":"AzureDev/#shared-access","title":"Shared Access","text":"<p>A shared access signature (SAS) is a URI that grants restricted access rights to Azure Storage resources. You can provide a shared access signature to clients that you want to grant delegate access to certain storage account resources.</p> <p>Three types of shared access</p> <ol> <li>User SAS - SAS secured with Entra ID credentials , used for blob storage</li> <li>Service SAS - secured with storage account key , used to access blob storage, queue storage, files</li> <li>Account SAS - used to delegate access to resources dependent on storage</li> </ol> <p>When you use a SAS to access data stored in Azure Storage, you need two components. The first is a URI to the resource you want to access. The second part is a SAS token that you've created to authorize access to that resource.</p> <p>In a single URI, such as <code>https://medicalrecords.blob.core.windows.net/patient-images/patient-116139-nq8z7f.jpg?sp=r&amp;st=2020-01-20T11:42:32Z&amp;se=2020-01-20T19:42:32Z&amp;spr=https&amp;sv=2019-02-02&amp;sr=b&amp;sig=SrW1HZ5Nb6MbRzTbXCaPm%2BJiSEn15tC91Y4umMPwVZs%3D</code>,</p> <p>you can separate the URI from the SAS token as follows:</p> <p>URI: <code>https://medicalrecords.blob.core.windows.net/patient-images/patient-116139-nq8z7f.jpg?</code></p> <p>SAS token: <code>sp=r&amp;st=2020-01-20T11:42:32Z&amp;se=2020-01-20T19:42:32Z&amp;spr=https&amp;sv=2019-02-02&amp;sr=b&amp;sig=SrW1HZ5Nb6MbRzTbXCaPm%2BJiSEn15tC91Y4umMPwVZs%3D</code></p> Component Description sp=r Controls the access rights. The values can be a for add, c for create, d for delete, l for list, r for read, or w for write. This example is read only. The example sp=acdlrw grants all the available rights. st=2020-01-20T11:42:32Z The date and time when access starts. se=2020-01-20T19:42:32Z The date and time when access ends. This example grants eight hours of access. sv=2019-02-02 The version of the storage API to use. sr=b The kind of storage being accessed. In this example, b is for blob. sig=SrW1HZ5Nb6MbRzTbXCaPm%2BJiSEn15tC91Y4umMPwVZs%3D The cryptographic signature. <p></p> <p>Use case</p> <ul> <li>A client wants to read/write information to a storage account of another user/owner.</li> <li>In order to facilitate this an SAS is required</li> <li>A front end proxy server is established to validate the files if required and get an SAS</li> <li>Post acquring the SAS , the files are sent to the storage account</li> </ul> <p>An extra level of security can be acheived by adding the storage access policy to a container to check on the server side before accessing the file</p> <ul> <li>creating a storage access policy throuh azure-cli</li> </ul> <pre><code>az storage container policy create --name &lt;stored access policy identifier&gt; --container-name &lt;container name&gt; --start &lt;start time UTC datetime&gt; --expiry &lt;expiry time UTC datetime&gt; --permissions &lt;(a)dd, (c)reate, (d)elete, (l)ist, (r)ead, or (w)rite&gt; --account-key &lt;storage account key&gt; --account-name &lt;storage account name&gt;\n</code></pre>"},{"location":"AzureDev/#microsoft-graph","title":"Microsoft Graph","text":"<p>Microsoft graph API provides sdk and rest endpoints to access the data stored in azure services.</p> <p></p> <p>It consists of three components</p> <ul> <li>Graph Connectors: Used to deliver all the incoming data into the Azure Storage , all the popular services have connectors (Drive,Salesforce,Box)</li> <li>Data Connect: used to deliver all the data from the graph to the azure internal tools for development</li> <li>Rest Endpoint: The graph library provides the endpoint <code>https://graph.microsoft.com/</code> to provide endpoint to API and SDK's.</li> </ul> <ul> <li>url pattern to fetch records</li> </ul> <p><code>{HTTP method} https://graph.microsoft.com/{version}/{resource}?{query-parameters}</code></p> <ol> <li>HTTP method - the operation that would be performed (GET,PUT,POST,PATCH,DELETE)</li> <li>version - version of the graph API used</li> <li>resource - indicating the id of the resource (me/Email)</li> <li> <p>query-paremeters - includes a set of query options to be performed ($skip, $sort, $top)</p> </li> <li> <p>Pattern of the Response</p> </li> <li> <p>Status Code</p> </li> <li>Response</li> <li>nextLink - used when response is long.</li> </ol>"},{"location":"AzureDev/#azure-key-vault","title":"Azure key vault","text":"<p>Azure key value is used to store sensitive information such as API Keys, app secrets, certificates and cryptographic keys</p> <ul> <li>useful in maintaining keys if an application has multiple versions</li> <li>authN is provided by Entra ID and authZ is provided by role bases Acess or key valut policies</li> </ul> <ul> <li> <p>managed identity</p> </li> <li> <p>system managed: In this type of approach , whenever we need access from key valut system auto manages it.</p> </li> </ul> <p>process included</p> <ul> <li>ARM creates a identity for the resources in the Entra ID and assigns to the resoruce for the whole lifecycle</li> <li> <p>whenever a resource requires authN, azure auto manages it</p> </li> <li> <p>user managed: In this type of approach the user has to manually register the service in the entra ID.</p> </li> <li> <p>Whenever authN is required a request has to be sent to <code>vault.azure.net\\token</code></p> </li> </ul>"},{"location":"AzureDev/#azure-api-management","title":"Azure API Management","text":"<p>Api Management is composed of three components</p> <ul> <li> <p>API gateway</p> </li> <li> <p>Accept incoming calls and route to backend</p> </li> <li>Request and response transformations</li> <li>rate limit</li> <li> <p>caching and logs</p> </li> <li> <p>Management plane</p> </li> <li> <p>manage users</p> </li> <li>transformation on request</li> <li> <p>define api schema</p> </li> <li> <p>Developer portal</p> </li> <li> <p>Documentation</p> </li> <li>create and manage keys</li> </ul> <p>available policies in gateway are <code>inbound</code>,<code>outbound</code>,<code>onError</code></p> <p>e.g adding headers to incoming request</p> <pre><code>&lt;policies&gt;\n    &lt;inbound&gt;\n        &lt;base /&gt;\n        &lt;set-header name=\"x-request-context-data\" exists-action=\"override\"&gt;\n            &lt;value&gt;@(context.User.Id)&lt;/value&gt;\n            &lt;value&gt;@(context.Deployment.Region)&lt;/value&gt;\n      &lt;/set-header&gt;\n    &lt;/inbound&gt;\n&lt;/policies&gt;\n</code></pre>"},{"location":"AzureDev/#advanced-policies","title":"Advanced policies","text":"<ol> <li>control flow - Apply policy statements based on conditional boolean expressions</li> <li>forward request - this policy forwards the request to specified context.forwardRef , if not mentioned the outbound policy would be executed</li> </ol> <pre><code>&lt;forward-request timeout=\"time in seconds\" follow-redirects=\"true | false\"/&gt;\n</code></pre> <ol> <li>limit concurency - this policy limits incoming requests, return an HTTP 429 - Too many requests status code</li> </ol> <pre><code>&lt;limit-concurrency key=\"expression\" max-count=\"number\"&gt;\n        &lt;!\u2014 nested policy statements --&gt;\n&lt;/limit-concurrency&gt;\n</code></pre> <ol> <li>log to event hub - send particular request for event analysis</li> <li>mock response - used for test purposes</li> <li>Retry - execute a set of child policies until retry condition is false or time is exhausted</li> </ol> <pre><code>&lt;retry\n    condition=\"boolean expression or literal\"\n    count=\"number of retry attempts\"\n    interval=\"retry interval in seconds\"\n    max-interval=\"maximum retry interval in seconds\"\n    delta=\"retry interval delta in seconds\"\n    first-fast-retry=\"boolean expression or literal\"&gt;\n        &lt;!-- One or more child policies. No restrictions --&gt;\n&lt;/retry&gt;\n</code></pre>"},{"location":"AzureDev/#scope-for-apis","title":"scope for API's","text":"<ul> <li>all : includes all the api endpoints with a single subscription key</li> <li>a single api - specific to an API endpoint</li> <li>product - specific to a group of products</li> </ul> <p>default header name - <code>Ocp-Apim-Subscription-Key</code></p> <pre><code>curl --header \"Ocp-Apim-Subscription-Key: &lt;key string&gt;\" https://&lt;apim gateway&gt;.azure-api.net/api/path\n</code></pre> <p>default query parameter - <code>subscription-Key</code></p> <pre><code>curl https://&lt;apim gateway&gt;.azure-api.net/api/path?subscription-key=&lt;key string&gt;\n</code></pre>"},{"location":"AzureDev/#api-security-tls","title":"API security TLS","text":"<p>Other way to authenticate is to set inbound rules to check</p> <ol> <li>Certificate Authority</li> <li>Thumbprint</li> <li>Subject</li> <li>Expiry date</li> </ol> <p>useful to authenticate azure functions</p> <p>e.g checking thumbprint in inbound rule policies</p> <pre><code>&lt;choose&gt;\n    &lt;when condition=\"@(context.Request.Certificate == null || context.Request.Certificate.Thumbprint != \"desired-thumbprint\")\" &gt;\n        &lt;return-response&gt;\n            &lt;set-status code=\"403\" reason=\"Invalid client certificate\" /&gt;\n        &lt;/return-response&gt;\n    &lt;/when&gt;\n&lt;/choose&gt;\n</code></pre>"},{"location":"AzureDev/#azure-event-grid","title":"Azure Event Grid","text":"<p>Main use - Acts as an event handler and publisher to action taking subscribers</p> <ul> <li>Events - What happened.</li> <li>Event sources - Where the event took place.</li> <li>Topics - The endpoint where publishers send events.</li> <li>Event subscriptions - The endpoint or built-in mechanism to route events, sometimes to more than one handler. Subscriptions are also used by handlers to intelligently filter incoming events.</li> <li>Event handlers - The app or service reacting to the event.</li> </ul> <p>Event grid support two types of event schemes</p> <ul> <li>Event Grid Event Scheme -&gt; designed for setting up the azure event grid system.</li> <li>Cloud Event Scheme --&gt; used to define the data scheme for systems beyond azure event grid</li> </ul> <p>Dead letter events - after exhausting all the retry attemps or post the time to live (TTL) mentioned in the policy the azure event grid stores an dead letter event in the system.</p> <p>webhooks are used to receive events from azure event grid, post setting up the system access should be provided to the end point to receive POST requests</p> <p>e.g Azure functions with event grid trigger</p>"},{"location":"AzureDev/#filters","title":"Filters","text":"<p>only a specific set of events can be filterd out from the event grid pool and passed to the webhook endpoint, different types of filters</p> <ol> <li>Event type - success or failure</li> <li>Subject begins with or ends with (filter a specific type of files )</li> <li> <p>Advance filters - use the following fields</p> </li> <li> <p>operator type - The type of comparison.</p> </li> <li>key - The field in the event data that you're using for filtering. It can be a number, boolean, or string.</li> <li>value or values - The value or values to compare to the key.</li> </ol> <pre><code>\"filter\": {\n  \"advancedFilters\": [\n    {\n      \"operatorType\": \"NumberGreaterThanOrEquals\",\n      \"key\": \"Data.Key1\",\n      \"value\": 5\n    },\n    {\n      \"operatorType\": \"StringContains\",\n      \"key\": \"Subject\",\n      \"values\": [\"container1\", \"container2\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"AzureDev/#azure-event-hub","title":"Azure Event Hub","text":"<p>Event Hub is used to receive and process millions of events per second. It serves a front door to any event pipeline and acts as event ingestor.</p> <p>Auth --&gt; Microsoft Entra ID or SAS</p> <ul> <li>usecase scenario</li> </ul> <p>As an example scenario, consider a home security company that monitors 100,000 homes. Every minute, it gets data from various sensors such as a motion detector, door/window open sensor, glass break detector, and so on, installed in each home. The company provides a web site for residents to monitor the activity of their home in near real time.</p> <p>Each sensor pushes data to an event hub. The event hub is configured with 16 partitions. On the consuming end, you need a mechanism that can read these events, consolidate them, and dump the aggregate to a storage blob, which is then projected to a user-friendly web page.</p>"},{"location":"AzureDev/#architecture-of-event-hub","title":"Architecture of Event Hub","text":"<ul> <li>Event producers (POST Requests): source of data (logs, telemetry, mobile app data,etc..)</li> <li>protocol : either HTTPS or Kafka 1.0 protocol(streaming platforms) or Advanced Message Queue protocl (IoT messaging queues)</li> <li>Azure event hubs: Main container to facilitate data, the total number of partitions should be defined at initialization, data is assigned at the end of each partition on any post event.</li> <li>consumer group: The main consumers of the event hubs , each consumer is connected to an partion and receives events in a continuos stream.</li> <li>Event Receivers (GET Requests): The Endpoint which receives events from IoT devices , this receivers mainly use AMQ protocol.</li> </ul> <p>All the captured data is stored in Apache Avro format.</p> <p>location of an example file can be</p> <pre><code>https://mystorageaccount.blob.core.windows.net/mycontainer/mynamespace/myeventhub/0/2017/12/08/03/03/17.avro\n</code></pre> <p>naming convention used</p> <pre><code>{Namespace}/{EventHub}/{PartitionId}/{Year}/{Month}/{Day}/{Hour}/{Minute}/{Second}\n</code></pre>"},{"location":"AzureDev/#azure-message-queues","title":"Azure Message Queues","text":"<p>Two types of queues are supported</p> <ul> <li>Service Bus Queue : main part of the azure messaging infc., supports pub/sub and other models. Useful for parallel queuing.</li> <li>Storage queue : queue built in the main infrastructe of the azure storage.useful for long queues (supports upto 80gb)</li> </ul> <p>The Queue used for stream uses FIFO, these are load leveling nodes as client and publisher might have different stream rates</p> <p>Two modes of subscriptions are available for consumers</p> <ul> <li>Receive and delete : the consumer sends a request for message, the service bus processes the request and marks it as consumed , in case of downtime or restarts the request is lost.</li> <li>peek and lock : In this mode , once a request is received from the consumer , the service bus locks the next request and processes the current. This makes it fault tolerant , in case of any issues the lock is removed either by abandoing or a ttl.</li> </ul>"},{"location":"AzureDev/#different-types-of-message-routings","title":"Different types of message routings","text":"<ul> <li>Simple Request/reply: The producer pushes a message to the queue with the field <code>ReplyTo</code> , all the consumers send their status to the address</li> <li>Multicast request/reply: The producer pushes a message to the queue and multi consumers send their status to the <code>ReplyTo</code> field.</li> <li>Multiplexing - A <code>sessionID</code> field is assigned to the message and all consumers listen on the active session.</li> <li>Multiplexing Request/reply: Multiple Producers share a <code>SessionID</code> and all the consumers respons to <code>ReplyToSessionID</code> address.</li> </ul> <p>Azure logic Apps maintain the routing in the service bus.</p>"},{"location":"AzureDev/#exercise","title":"Exercise","text":""},{"location":"AzureDev/#azure-cache-for-redis","title":"Azure Cache for Redis","text":"<p>Used for the following scenarios</p> <ul> <li>Data cache : A chunk of frequenty used data from source is stored in cache and frequently updated</li> <li>Static content : store contents of the static websites</li> <li>session storage : alternative to cookies to improve performance</li> <li>Distributed transactions: Useful to maintain the atomicity of transactions, it keeps a log of transactions and rolls back in case of failure.</li> </ul> <p>command format for redis</p> <pre><code>COMMAND parameter1 parameter2 parameter3\n</code></pre> Command Description ping Ping the server. Returns \"PONG\". set [key] [value] Sets a key/value in the cache. Returns \"OK\" on success. get [key] Gets a value from the cache. exists [key] Returns '1' if the key exists in the cache, '0' if it doesn't. type [key] Returns the type associated to the value for the given key. incr [key] Increment the given value associated with key by '1'. The value must be an integer or double value. This returns the new value. incrby [key] [amount] Increment the given value associated with key by the specified amount. The value must be an integer or double value. This returns the new value. del [key] Deletes the value associated with the key. flushdb Delete all keys and values in the database. ------"},{"location":"AzureDev/#storage-on-cdns","title":"storage on CDN's","text":"<p>azure offers several POP (point of presence) edge servers spread across serveral geo locations</p> <p>main features</p> <ol> <li>site load time accelaration</li> <li>https configurations</li> <li>file compressions</li> <li>geo filtering</li> <li>diagnostic logs</li> </ol>"},{"location":"AzureDev/#content-updating","title":"Content updating","text":"<p>In normal workflow, whenever a file is uploaded to the cdn, its considered as fresh until the ttl expired, post that server fetches a new file and updates the ttl.</p> <p>In alternative, it can force purge and load files onto CDN through cli to improve the experience.</p> <pre><code>az cdn endpoint purge \\\n    --content-paths '/css/*' '/js/app.js' \\\n    --name ContosoEndpoint \\\n    --profile-name DemoProfile \\\n    --resource-group ExampleGroup\n</code></pre> <pre><code>az cdn endpoint load \\\n    --content-paths '/img/*' '/js/module.js' \\\n    --name ContosoEndpoint \\\n    --profile-name DemoProfile \\\n    --resource-group ExampleGroup\n</code></pre>"},{"location":"AzureDev/#exam-topics","title":"Exam Topics","text":"<ul> <li>Develop Azure compute solutions (25-30%)</li> <li>Develop Azure storage (15-20%)</li> <li>Implement Azure Security (20-25%)</li> <li>Monitor, troubleshoot, and optimize Azure solutions (15-20%)</li> <li>Connect to and consume Azure services and third-party services (15-20%)</li> </ul>"},{"location":"AzureDev/#practice-questions","title":"Practice Questions","text":"<ul> <li>az webapp deploy --clean true --&gt; target folder is cleaned before deployment</li> <li>az webapp deploy --restart true --&gt; restart the service after deployment , default service of the zip deployment</li> <li>ARR (Application Request Routing ) affinity parameter is used to always route to the proper App service instance</li> <li>fan-out/fan-in pattern of the azure functinos enables parallel processing</li> <li> <p>timer trigger notations:</p> </li> <li> <p>detailed error logs of azure web app service is used to check for 400 errors</p> </li> <li>In production, the version must be pinned. The only way to achieve that is by using a tag that follows the convention {major}.{minor}.{patch}.</li> <li>az eventhubs eventhub update adds partitions to an existing event hub.</li> <li>az eventhubs eventhub consumer-group update updates the event hub consumer group.</li> <li>EventProcessorClient balances the load between multiple instances of a program in newer .NET versions (version 5.0). EventHubConsumerClient balances the load between multiple instances of a program in Python and JavaScript. EventProcessorHost balances the load between multiple instances of a program in earlier .NET versions. The EventHubProducerClient class is used to send events to an event hub.</li> <li>The Rotate operation will generate a new version of the key based on the key policy. The Rotation Policy operation updates the rotation policy of a key vault key. The Purge Deleted Key operation is applicable for soft-delete enabled vaults or HSMs. The Set Attributes operation changes specified attributes of a stored key.</li> <li>This item tests the candidate\u2019s knowledge of implementing solutions that use Azure Service Bus. A SqlFilter holds a SQL-like conditional expression that is evaluated in the broker against the arriving message\u2019s user-defined properties and system properties. The TrueFilter and FalseFilter either cause all arriving messages (true) or none of the arriving messages (false) to be selected for the subscription. A CorrelationFilter holds a set of conditions that are matched against one or more of an arriving message's user and system properties. Size Filter and Content are not valid options for Service Bus topic filtering.</li> </ul>"},{"location":"C%23/","title":"C# Documentation","text":"<p><code>Credits</code> - Derek Banas</p>"},{"location":"C%23/#table-of-contents","title":"Table of contents","text":"Concept Primary Usages Namespaces Oraganize code base Classes"},{"location":"C%23/#namespaces","title":"NameSpaces","text":"<p>A group of Classes, Interfaces, Enums, Structs organized together. Used to organize and maintain the codebase</p> <pre><code>namespace MyNamespace {\n    class MyClass {\n        // Class definition\n    }\n\n    interface MyInterface {\n        // Interface definition\n    }\n\n    // Other types can be declared here\n\n    // Using directive\n    using MyNamespace;\n    MyClass myObj = new MyClass();\n}\n</code></pre>"},{"location":"LeetCode/","title":"LeetCode Solutions","text":""},{"location":"LeetCode/#algorithms","title":"Algorithms","text":""},{"location":"LeetCode/#bellman-ford","title":"Bellman - Ford","text":""},{"location":"LeetCode/#intervals","title":"Intervals","text":""},{"location":"LeetCode/#1851-minimum-interval-to-include-each-query","title":"1851. Minimum Interval to Include Each Query","text":"<pre><code>class Solution {\n    public int[] minInterval(int[][] intervals, int[] queries) {\n        /*\n            edge cases:\n                1. if just one elem exists in the intervals, return the size of the container, if the querie exists in the range of the interval\n            algo:\n                1. sort the intervals and queries to avoid iterating over more elements\n                2. init a minheap to store the matching intervals for each query\n                3. iterate over the intervals to check for match, and offer to minheap\n                4. after iterating, poll from the minheap and pick the least value\n                5. assing it to the originalindex in the res\n            t.c - O(nlogn + qlogn) - iterate over the intervals, and iterate over each interval\n            s.c - O(queriesIndex) + O(res) + O(minHeap)\n\n        */\n        int n = intervals.length;\n        int qlen = queries.length;\n        int[][] queriesIndex = new int[qlen][2];\n        int[] res = new int[qlen];\n\n        //map the queriesIndex to maintain the original order\n        for(int ind=0;ind&lt;qlen;ind++){\n            queriesIndex[ind] = new int[]{queries[ind],ind};\n        }\n\n        //sort the arrays based on the starting index in asc order\n        Arrays.sort(intervals,(a,b)-&gt;a[0]-b[0]);\n\n        //sort the queries in asc order\n        Arrays.sort(queriesIndex,(a,b)-&gt;a[0]-b[0]);\n\n        //maintain a minHeap (pq) to return the least interval size container for each querie\n        PriorityQueue&lt;int[]&gt; mh = new PriorityQueue&lt;&gt;((a, b) -&gt; (a[1] - a[0] + 1) - (b[1] - b[0] + 1));\n\n        //process each query\n        int index = 0;\n        for(int[] q:queriesIndex){\n            int query = q[0];\n            int originalInd = q[1];\n            while(index&lt;n &amp;&amp; intervals[index][0]&lt;=query){\n                //found interval with a match offer to min heap\n                mh.offer(intervals[index]);\n                index++;\n            }\n\n            //poll from the min heap and assign the min value to the res[originalIndex]\n            while(!mh.isEmpty() &amp;&amp; mh.peek()[1]&lt;query){\n                //poll\n                mh.poll();\n            }\n\n            res[originalInd] = mh.isEmpty()?-1:(mh.peek()[1]-mh.peek()[0])+1;\n        }\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#435-non-overlapping-intervals","title":"435. Non-overlapping Intervals","text":"<pre><code>class Solution {\n    public int eraseOverlapIntervals(int[][] intervals) {\n        /*\n            edge cases:\n                1. If there\u2019s only one interval, return 0 since no overlaps are possible.\n                2. In the case [a1, b1], [a2, b2] if b1 == a2, do not count it as an overlap.\n\n            algo:\n                1. Sort the intervals based on their end time to facilitate minimizing removals.\n                2. Iterate through the sorted intervals and count overlaps by comparing the start of the current interval with the end of the previous non-overlapping interval.\n                3. Return the number of intervals removed to eliminate all overlaps.\n\n            t.c - o(nlogn) due to sorting.\n            s.c - o(logn) for the stack space used by sorting.\n        */\n\n        if (intervals.length &lt;= 1) {\n            return 0;\n        }\n\n        // Sort intervals by their end time in ascending order\n        Arrays.sort(intervals, (a, b) -&gt; a[1] - b[1]);\n\n        int res = 0;  // To count the number of removed intervals\n        int prevEnd = intervals[0][1];\n\n        for (int i = 1; i &lt; intervals.length; i++) {\n            // If current interval starts before the end of the previous non-overlapping interval, it's an overlap\n            if (intervals[i][0] &lt; prevEnd) {\n                res++;\n            } else {\n                // Update prevEnd to the end time of the current interval if there's no overlap\n                prevEnd = intervals[i][1];\n            }\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#56-merge-intervals","title":"56. Merge Intervals","text":"<pre><code>class Solution {\n    public int[][] merge(int[][] intervals) {\n        /*\n            algo:\n                1. sort the intervals to avoid mixup and missing ranges\n                2. if the intervals match merge\n                return;\n            t.c - o(nlogn)\n            s.c - o(n)\n        */\n\n        List&lt;int[]&gt; res = new ArrayList&lt;&gt;();\n        Arrays.sort(intervals,(a,b)-&gt;a[0]-b[0]);\n\n        res.add(intervals[0]);\n\n        for(int ind=1;ind&lt;intervals.length;ind++){\n            //get the last element from the arraylist and check with the curr\n            int[] last = res.get(res.size()-1);\n            if(last[1]&gt;=intervals[ind][0]){\n                // [1,3] [2,6] --&gt; merge and update the last\n                last[1] = Math.max(last[1],intervals[ind][1]);\n            }\n            else{\n                // ranges do not match add to res\n                res.add(intervals[ind]);\n            }\n        }\n\n        return res.toArray(int[][]::new);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#57-insert-interval","title":"57. Insert Interval","text":"<pre><code>class Solution {\n    public int[][] insert(int[][] intervals, int[] newInterval) {\n\n        /*\n            algo:\n                three cases\n                1. if the interval is less than newInterval; skip\n                2. merge: if the interval lies in the range, update the newInterval\n                3. if the interval is greater than newInterval; skip\n            t.c - o(n)\n            s.c - o(n)\n        */\n\n        List&lt;int[]&gt; res = new ArrayList&lt;&gt;();\n        int n = intervals.length;\n        int ind = 0;\n\n        //case 1 [1,2] --&gt; [4,8] (greater)\n        while(ind&lt;n &amp;&amp; (newInterval[0]&gt;intervals[ind][1])){\n            res.add(intervals[ind]);\n            ind++;\n        }\n\n        //case 2 [3,5] --&gt; [4,8] (merge)\n        while(ind&lt;n &amp;&amp; (newInterval[1]&gt;=intervals[ind][0])){\n            //update the newInterval\n            newInterval[0] = Math.min(intervals[ind][0],newInterval[0]);\n            newInterval[1] = Math.max(intervals[ind][1],newInterval[1]);\n            ind++;\n        }\n\n        //after merge add it to res\n        res.add(newInterval);\n\n        //case 3 , add the rest of the elements greater than newInterval [6,9] [2,5]\n        while(ind&lt;n){\n            res.add(intervals[ind]);\n            ind++;\n        }\n\n        return res.toArray(int[][]::new);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#dp","title":"DP","text":""},{"location":"LeetCode/#5-longest-palindromic-substring","title":"5. Longest Palindromic Substring","text":"<pre><code>class Solution {\n\n    /*\n        brute force -&gt; check all the possible strings and return the largest combinations from those strings\n        t.c -&gt; O(n^2) to check pairs , O(n) to check if string is palindrome : total : O(n^3)\n        s.c -&gt; O(validPalindromes) , considering StringBuilder Objects\n\n        algo:\n        1. to check in one pass , have to consider a element as a center and check left and right boundaries\n        2. in case of odd , consider single element as center , in case of even consider z and z+1 (two chars)\n        3. return the longest substring\n    */\n\n    private String res = \"\";\n\n    public void util(String s, int l, int r) {\n        while (l &gt;= 0 &amp;&amp; r &lt; s.length() &amp;&amp; s.charAt(l) == s.charAt(r)) {\n            int palindromeLen = r - l + 1;\n            if (palindromeLen &gt; res.length()) {\n                res = s.substring(l, r + 1);\n            }\n            l--;\n            r++;\n        }\n    }\n\n    public String longestPalindrome(String s) {\n        int n = s.length();\n        if (n == 0) {\n            return \"\";\n        }\n\n        for (int z = 0; z &lt; n; z++) {\n            // check for odd length palindromes , considering z as center and checking boundaries\n            util(s, z, z);\n            // check for even length palindromes , considering 2 elements as center\n            util(s, z, z + 1);\n        }\n\n        return res;\n    }\n}\n</code></pre> <p><code>Manacher Approach - O(n)</code></p>"},{"location":"LeetCode/#70-climbing-stairs","title":"70. Climbing Stairs","text":"<pre><code>class Solution {\n    /*\n        b.f --&gt; generate all the paths and calculate the total sum (backtracking) t.c - O(2^n)\n        t.c - O(n)\n        s.c - O(n)\n        approach:\n        1. we need 1 step at n and n-1 index\n        2. for (n-2) to 0 , each index have sum of n-1 and n-2 as steps required\n        3. return dp[n]\n    */\n\n    public int climbStairs(int n) {\n        int[] dp = new int[n+1];\n        dp[0] = 1;\n        dp[1] = 1;\n\n        for(int z = 2; z&lt;n+1;z++){\n            dp[z] = dp[z-1] + dp[z-2];\n        }\n        return dp[n];\n    }\n}\n</code></pre>"},{"location":"LeetCode/#91-decode-ways","title":"91. Decode Ways","text":"<p><code>brute-force: back-tracking</code></p> <pre><code>class Solution {\n\n    private List&lt;List&lt;Character&gt;&gt; res = new ArrayList&lt;&gt;();\n\n    public void bt(int index, List&lt;Character&gt; subset, String s) {\n        if (index == s.length()) {\n            res.add(new ArrayList&lt;&gt;(subset));\n            return;\n        }\n\n        // Single-digit case\n        int digit = s.charAt(index) - '0';\n        if (digit &gt;= 1 &amp;&amp; digit &lt;= 9) {\n            subset.add((char) (digit + 'A' - 1));\n            bt(index + 1, subset, s);\n            subset.remove(subset.size() - 1);\n        }\n\n        // Two-digit case\n        if (index + 1 &lt; s.length()) {\n            int twoDigits = Integer.parseInt(s.substring(index, index + 2));\n            if (twoDigits &gt;= 10 &amp;&amp; twoDigits &lt;= 26) {\n                subset.add((char) (twoDigits + 'A' - 1));\n                bt(index + 2, subset, s);\n                subset.remove(subset.size() - 1);\n            }\n        }\n    }\n\n    public int numDecodings(String s) {\n        // Check if index 0 is 0, return 0\n        if (s.charAt(0) == '0') {\n            return 0;\n        }\n        bt(0, new ArrayList&lt;&gt;(), s);\n\n        for (var el : res) {\n            System.out.println(el);\n        }\n        return res.size();\n    }\n}\n</code></pre> <p><code>DP approach</code></p> <pre><code>public class Solution {\n    /*\n        t.c - O(n)\n        s.c - O(n)\n        approach:\n        1. for each char in the string , we can either form a single digit combination or two digit combination\n        2. start from(2,n) check for single and two digit , if in range(1-9) and (10-26) , add to dp\n        3. return dp[n]\n    */\n    public int numDecodings(String s) {\n        int n = s.length();\n\n        if (n == 0) {\n            return 0;\n        }\n\n        int[] dp = new int[n + 1];\n        dp[0] = 1; // Base case: Empty string can be decoded in one way (no characters).\n        dp[1] = s.charAt(0) == '0' ? 0 : 1; // First character can be decoded only if it's not '0'.\n\n        for (int i = 2; i &lt;= n; i++) {\n            int oneDigit = Integer.parseInt(s.substring(i - 1, i));\n            int twoDigits = Integer.parseInt(s.substring(i - 2, i));\n\n            if (oneDigit &gt;= 1 &amp;&amp; oneDigit &lt;= 9) {\n                dp[i] += dp[i - 1];\n            }\n\n            if (twoDigits &gt;= 10 &amp;&amp; twoDigits &lt;= 26) {\n                dp[i] += dp[i - 2];\n            }\n        }\n\n        return dp[n];\n    }\n}\n</code></pre>"},{"location":"LeetCode/#139-word-break","title":"139. Word Break","text":"<p><code>brute-force: recursion</code></p> <pre><code>class Solution {\n    public boolean wordBreak(String s, List&lt;String&gt; wordDict) {\n        /*\n            brute - force(recursive approach)\n            1. base case when the word is found in dictionary return true;\n            2. start from (1,n) , if the substring is found in dictionary (found the first match )\n            3. pass the rest of the string recursively , if all recursive calls return true\n            4. return\n        */\n\n\n        int n = s.length();\n\n        // Base case: if the string is in the dictionary, return true\n        if (wordDict.contains(s)) {\n            return true;\n        }\n\n        for (int z = 1; z &lt; n; z++) {\n            String ss = s.substring(0, z);\n            // find the first part, pass on the second part recursively\n            if (wordDict.contains(ss)) {\n                String suf = s.substring(z);\n                if (wordBreak(suf, wordDict)) {\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n}\n</code></pre> <p><code>dp approach</code></p> <pre><code>class Solution {\n    public boolean wordBreak(String s, List&lt;String&gt; wordDict) {\n        /*\n            dp approach (bottom-up)\n            1. base case dp[len(word)] as true, start from n-1 to 0\n            2. if any substring is found in wordDict , set dp[index] as true\n            3. to check the final string can be split or not , set dp[0] as dp[0+len(matchedWord)]\n\n            leetcode , [leet,code]\n            dp[8] = true\n            dp[7] = dp[6] = dp[5] = false\n            dp[4] = true (found code)\n            dp[3] = dp[2] = dp[1] = false\n            dp[0] = dp[0+4] 4 --&gt; len(matchedWord) i.e leet\n        */\n        int n = s.length();\n        boolean[] dp = new boolean[n+1];\n        dp[n] = true;\n\n        for (int z = n - 1; z &gt;= 0; z--) {\n            for (String word : wordDict) {\n                int end = z + word.length();\n                if (end &lt;= n &amp;&amp; s.substring(z, end).equals(word)) {\n                    dp[z] = dp[end] || dp[z];\n                }\n            }\n        }\n\n        return dp[0];\n    }\n}\n</code></pre>"},{"location":"LeetCode/#152-maximum-product-subarray","title":"152. Maximum Product Subarray","text":"<p><code>brute-force</code></p> <pre><code>class Solution {\n    public int maxProduct(int[] nums) {\n        /*\n            brute force\n            1. O(n**2), init the product of every number as i\n            2. multiply until n-1\n            3. return max\n\n        */\n        int n = nums.length;\n        int maxProduct = Integer.MIN_VALUE;\n\n        for (int i = 0; i &lt; n; i++) {\n            int product = 1;\n            for (int j = i; j &lt; n; j++) {\n                product *= nums[j];\n                maxProduct = Math.max(maxProduct, product);\n            }\n        }\n\n        return maxProduct;\n    }\n}\n</code></pre> <p><code>using prefix and suffix sum</code></p> <pre><code>class Solution {\n    public int maxProduct(int[] nums) {\n        /*\n            approach - 2 (using suffix and prefix)\n            1. start with 1 for pre and suff , mulitply z (0 to n-1)\n            2. if digit is 0 , make the pre and suff back to 1 (will not be considered as sub-array)\n            3. return the max\n        */\n\n        int n = nums.length;\n        int maxProduct = nums[0]; // Initialize maxProduct with the first element\n        int pre = 1;\n        int suff = 1;\n\n        for (int i = 0; i &lt; n; i++) {\n            pre *= nums[i];\n            suff *= nums[n - i - 1];\n\n            // Update maxProduct with the maximum of maxProduct, pre, and suff\n            maxProduct = Math.max(maxProduct, Math.max(pre, suff));\n\n            // Reset pre and suff if they become 0\n            if (pre == 0) {\n                pre = 1;\n            }\n            if (suff == 0) {\n                suff = 1;\n            }\n        }\n\n        return maxProduct;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#198-house-robber","title":"198. House Robber","text":"<pre><code>class Solution {\n    /*\n        brute.f -&gt; make combinations , choosing one home or leaving it and calculate sum (back-tracking)\n        t.c - O(2^n)\n\n        approach:\n        1. first choice -&gt; select first home , second choice -&gt; select second home or first home\n        2. from third house , two choices , either select current + first or second (cannot select second as it is adjacent)\n        3. return dp[last]\n        t.c - O(n)\n        s.c - O(n)\n\n    */\n\n    public int rob(int[] nums) {\n        int n = nums.length;\n        if (n == 0) {\n            return 0;\n        } else if (n == 1) {\n            return nums[0];\n        }\n\n        int[] dp = new int[n];\n        dp[0] = nums[0];\n        dp[1] = Math.max(nums[0], nums[1]);\n\n        for (int z = 2; z &lt; n; z++) {\n            dp[z] = Math.max(nums[z] + dp[z - 2], dp[z - 1]);\n        }\n\n        return dp[n - 1];\n    }\n}\n</code></pre>"},{"location":"LeetCode/#213-house-robber-ii","title":"213. House Robber II","text":"<pre><code>class Solution {\n    /*\n        b.f -&gt; to select in circle have to avoid first and last as they are adjacent , run backtracking including first and excluding last and vice versa\n        t.c - 2 * O(2^n)\n\n        dp:\n        1. init two arrays f = nums[1:] , s = nums[0:n-1]\n        2. a helper function to find max amount to rob from a house (h.r I)\n        3. return max of helper(f),helper(s)\n\n        t.c - 2*O(n)\n        s.c - 2*O(n)\n\n    */\n    public int h(int[] nums){\n        int n = nums.length;\n        if(n==0){\n            return 0;\n        }\n        if(n==1){\n            return nums[0];\n        }\n\n        int[] dp = new int[n];\n        dp[0] = nums[0];\n        dp[1] = Math.max(dp[0], nums[1]);\n\n        for(int z = 2;z&lt;n;z++){\n            dp[z] = Math.max(nums[z]+dp[z-2], dp[z-1]); //cannot select z-1 (adjacent)\n        }\n        return dp[n-1];\n    }\n\n    public int rob(int[] nums) {\n        int n = nums.length;\n        if(n==0){\n            return 0;\n        }\n        if(n==1){\n            return nums[0];\n        }\n        int[] f = new int[n - 1];\n        int[] s = new int[n - 1];\n\n        for (int i = 0; i &lt; n - 1; i++) {\n            f[i] = nums[i];\n            s[i] = nums[i + 1];\n        }\n\n        return Math.max(h(f), h(s));\n    }\n}\n</code></pre>"},{"location":"LeetCode/#300-longest-increasing-subsequence","title":"300. Longest Increasing Subsequence","text":"<p><code>O(n^2)</code></p> <pre><code>class Solution {\n    public int lengthOfLIS(int[] nums) {\n        /*\n            Approach:\n            1. we can form a subsequence of length 1 with each element in the array , so dp[i] of each index is initialized as 1\n            2. for (0,n) -&gt; start as 1 , check from (0 to i) . if element is less than orginal , modity dp[i]\n            3. at each index update the maxLen in comparision with dp[i]\n            4.return\n        */\n\n        int n = nums.length;\n        int[] dp = new int[n];\n        int maxLen = 1; //base case\n\n        for (int i = 0; i &lt; n; i++) {\n            dp[i] = 1; // Initialize to 1 as every element is a subsequence of length 1\n\n            for (int j = 0; j &lt; i; j++) {\n                if (nums[i] &gt; nums[j]) {\n                    dp[i] = Math.max(dp[i], dp[j] + 1);\n                }\n            }\n\n            maxLen = Math.max(maxLen, dp[i]);\n        }\n        return maxLen;\n    }\n}\n</code></pre> <p><code>O(nlogn)</code> <pre><code>class Solution {\n    /*\n        approach:\n        1. idea is to calculate the length of th LIS not return the LIS , so we can modify the array\n        2. add the first elem to a temp list and set the length as 1 (base case)\n        3. for(1,n) -&gt; check if the element is greater than z-1 index , if yes add it to list , len++\n        4. else , find the index in the temporarry list where the element can be added ( lower bound (binary seach))\n        5. return\n\n        t.c - O(nlogn)\n        s.c - O(n) - arrayList to hold the elements\n    */\n\n\n    public int lengthOfLIS(int[] nums) {\n        List&lt;Integer&gt; tail = new ArrayList&lt;&gt;();\n\n        for (final int num : nums) {\n            if (tail.isEmpty() || num &gt; tail.get(tail.size() - 1)) {\n                tail.add(num);\n            } else {\n                int ind = firstGreaterEqual(tail, num);\n                tail.set(ind, num);\n            }\n        }\n\n        return tail.size();\n    }\n\n    private int firstGreaterEqual(List&lt;Integer&gt; A, int target) {\n        int l = 0;\n        int r = A.size();\n        while (l &lt; r) {\n            final int m = (l + r) / 2;\n            if (A.get(m) &gt;= target) {\n                r = m;\n            } else {\n                l = m + 1;\n            }\n        }\n        return l;\n    }\n}\n</code></pre></p>"},{"location":"LeetCode/#322-coin-change","title":"322. Coin Change","text":"<p><code>brute-force: back-tracking</code></p> <pre><code>class Solution {\n\n    private List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n\n    private void backtrack(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; current, int[] coins, int start, int remainingAmount) {\n        if (remainingAmount == 0) {\n            res.add(new ArrayList&lt;&gt;(current));\n            return;\n        }\n\n        for (int i = start; i &lt; coins.length; i++) {\n            if (remainingAmount - coins[i] &gt;= 0) {\n                current.add(coins[i]);\n                backtrack(result, current, coins, i, remainingAmount - coins[i]);\n                current.remove(current.size() - 1); // Backtrack\n            }\n        }\n    }\n\n    public int coinChange(int[] coins, int amount) {\n        backtrack(res, new ArrayList&lt;&gt;(), coins, 0, amount);\n        for(var el:res){\n            System.out.println(el);\n        }\n\n        return res.size();\n    }\n}\n</code></pre> <p><code>DP-approach</code></p> <pre><code>class Solution {\n\n    public int coinChange(int[] coins, int amount) {\n        if (amount &lt; 0 || coins.length == 0 || coins == null) {\n            return -1;\n        }\n\n        int[] dp = new int[amount + 1];\n        Arrays.fill(dp, amount + 1);\n        dp[0] = 0;\n\n        for (int coin : coins) {\n            for (int z = coin; z &lt;= amount; z++) {\n                dp[z] = Math.min(dp[z], 1 + dp[z - coin]);\n            }\n        }\n\n        return dp[amount] &lt;= amount ? dp[amount] : -1;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#416-partition-equal-subset-sum","title":"416. Partition Equal Subset Sum","text":"<p><code>brute-force</code></p> <pre><code>class Solution {\n    /*\n        brute - force:\n        1. if the sum of nums is odd , cannot parition the nums\n        2. generate all the subsets using backtracking and check if targetsum can be acheived\n        3. return\n    */\n\n    public boolean canPartition(int[] nums) {\n        int totalSum = 0;\n        for (int num : nums) {\n            totalSum += num;\n        }\n\n        if (totalSum % 2 != 0) {\n            return false; // If total sum is odd, cannot partition equally\n        }\n\n        return canPartitionRec(nums, 0, 0, totalSum / 2);\n    }\n\n    private boolean canPartitionRec(int[] nums, int index, int currentSum, int targetSum) {\n        if (currentSum == targetSum) {\n            return true;\n        }\n\n        if (index &gt;= nums.length || currentSum &gt; targetSum) {\n            return false;\n        }\n\n        // Include the current element in the subset\n        if (canPartitionRec(nums, index + 1, currentSum + nums[index], targetSum)) {\n            return true;\n        }\n\n        // Exclude the current element from the subset\n        if (canPartitionRec(nums, index + 1, currentSum, targetSum)) {\n            return true;\n        }\n\n        return false;\n    }\n}\n</code></pre> <p><code>DP using sets</code></p> <pre><code>class Solution {\n    public boolean canPartition(int[] nums) {\n        int sum = 0;\n        for (var s : nums) {\n            sum += s;\n        }\n        if (sum % 2 == 1) {\n            // base case, cannot partition the array\n            return false;\n        }\n        Set&lt;Integer&gt; set = new HashSet&lt;&gt;();\n        // base case can form a set of length 0, if no elements are included\n        set.add(0);\n        for (int z = 0; z &lt; nums.length; z++) {\n            Set&lt;Integer&gt; tempSet = new HashSet&lt;&gt;(set); // Temporary set to hold updated values\n            // iterate over the elements in the set and add nums[z]\n            for (var el : set) {\n                int ns = el + nums[z];\n                if (ns == sum / 2) {\n                    return true;\n                }\n                tempSet.add(ns);\n            }\n            set.addAll(tempSet); // Update the main set after the iteration is complete\n        }\n        return false;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#746-min-cost-climbing-stairs","title":"746. Min Cost Climbing Stairs","text":"<pre><code>class Solution {\n    public int minCostClimbingStairs(int[] cost) {\n        /*\n            b.f --&gt; generate all the list of paths and return the math with min sum (back tracking)\n            approach:\n            t.c - o(n)\n            s.c - o(n)\n            1. set the last step as 0 , first step as cost[n]\n            2. for (2,n)--&gt; dp[z] = dp[z-1] + cost[z-1] or dp[z-2] + cost[z-1]\n            3. return min of last and second last index\n\n        */\n\n\n        int n = cost.length;\n        int[] dp = new int[n+1];\n        dp[0] = 0;\n        dp[1] = cost[0];\n\n        for(int z = 2; z &lt;= n; z++) {\n            dp[z] = Math.min(dp[z-1] + cost[z-1], dp[z-2] + cost[z-1]);\n        }\n\n        return Math.min(dp[n], dp[n-1]);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#graph","title":"Graph","text":""},{"location":"LeetCode/#1334-find-the-city-with-the-smallest-number-of-neighbors-at-a-threshold-distance","title":"1334. Find the City With the Smallest Number of Neighbors at a Threshold Distance","text":"<pre><code>class Solution {\n\n    public int[][] floydWarshall(int n,int[][] edges,int distanceThreshold){\n        /*\n            1.start with the base distance arr(A) which consists of n*n distances to each node\n            2.start from node 0, use the base arr and compute a new array\n            3. for each comparision A[i,j] = min(A[i,j] , prevArr[i,current_index]+[current_index,j])\n            4. return the final array consisting of minimum distance to reach each node\n        */\n\n        int[][] dist = new int[n][n];\n\n        for (int i = 0; i &lt; n; i++) {\n            Arrays.fill(dist[i], distanceThreshold+1);\n            dist[i][i] = 0; // Distance to itself is 0\n        }\n        //make the distance array\n        for(int[] edge: edges){\n            int p1 = edge[0];\n            int p2 = edge[1];\n            int d = edge[2];\n\n            dist[p1][p2] = d;\n            dist[p2][p1] = d;\n        }\n\n\n        for(int k=0;k&lt;n;k++){\n            for(int i=0;i&lt;n;i++){\n                for(int j=0;j&lt;n;j++){\n                    dist[i][j] = Math.min(dist[i][j], (dist[i][k]+dist[k][j]));\n                }\n            }\n        }\n\n        return dist;\n    }\n\n    public int findTheCity(int n, int[][] edges, int distanceThreshold) {\n        /*\n            floyd - warshall algo (to find shortest path using all pairs , advancement of djikstras)\n            time: O(n^3)\n            space: O(n^2)\n        */\n\n        int[][] minDist = floydWarshall(n,edges,distanceThreshold);\n        int res = -1;\n\n        int minCity = n;\n\n        for(int i=0;i&lt;minDist.length;i++){\n            int cityCount = 0;\n            for(int j=0;j&lt;minDist.length;j++){\n                if(i!=j &amp;&amp; minDist[i][j]&lt;=distanceThreshold){\n                    cityCount++;\n                }\n            }\n            if(cityCount&lt;=minCity){\n                res = i;\n                minCity = cityCount;\n            }\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#2285-maximum-total-importance-of-roads","title":"2285. Maximum Total Importance of Roads","text":"<pre><code>class Solution {\n    public long maximumImportance(int n, int[][] roads) {\n        /*\n            base case: a maximum sum can be acheived if a city with more roads has higher weight attached to it. duplicates are fine as the order doesn't matter in sum calculation (2+3 = 5 or 3+2 = 5)\n\n            1. find the weights of each node in the graph and create a topological sort of the graph\n            2. run a loop on the input graph , for each edge calcuate the importance and store to res\n            3. return res\n        */\n\n\n        // Calculate the degree of each node\n        int[] degree = new int[n];\n        for (int[] road : roads) {\n            degree[road[0]]++;\n            degree[road[1]]++;\n        }\n\n        //  Sort cities by degree in descending order\n        Integer[] cities = new Integer[n];\n        for (int i = 0; i &lt; n; i++) {\n            cities[i] = i;\n        }\n        Arrays.sort(cities, (a, b) -&gt; degree[b] - degree[a]);\n\n        // Assign values to cities based on sorted order\n        int[] values = new int[n];\n        for (int i = 0; i &lt; n; i++) {\n            values[cities[i]] = n - i;\n        }\n\n        // Calculate the total importance\n        long res = 0;\n        for (int[] road : roads) {\n            res += values[road[0]] + values[road[1]];\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#127-word-ladder","title":"127. Word Ladder","text":"<pre><code>class Solution {\n    public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) {\n        /*\n            t.c -\n            to add words - word size m --&gt; o(m^2)\n            to traverse the list - o(n)\n            for bfs --&gt; o(n^2) , no.of nodes in the q\n            o(m) to traverse the word\n\n            s.c -\n            hm - O(m*n)\n\n            approach:\n            1. add beginWord to the wordList as we will be using that in count\n            2. for each word , make a new string with * replaced at each index\n            e.g hit --&gt; *it , h*t , hi*\n            3. add the word (hit) to all the possible formations\n            4. create a q with beingWord\n            5. make the formations and get all the possible neighbors from the hm , add to q\n            6. increse res at each level\n            7. return res , when endWord is found at a level\n            8.if not found , return 0\n\n        */\n\n\n        Map&lt;String, List&lt;String&gt;&gt; hm = new HashMap&lt;&gt;();\n        Set&lt;String&gt; set = new HashSet&lt;&gt;();\n        Queue&lt;String&gt; q = new LinkedList&lt;&gt;();\n        int res = 1;\n\n        if (!wordList.contains(endWord)) {\n            return 0;\n        }\n\n        wordList.add(beginWord);\n\n        for (String word : wordList) {\n            for (int i = 0; i &lt; word.length(); i++) {\n                StringBuilder sb = new StringBuilder(word);\n                sb.setCharAt(i, '*');\n                String pattern = sb.toString();\n                List&lt;String&gt; wordlist = hm.getOrDefault(pattern, new ArrayList&lt;String&gt;());\n                wordlist.add(word);\n                hm.put(pattern, wordlist);\n            }\n        }\n\n        q.offer(beginWord);\n        set.add(beginWord);\n\n        while (!q.isEmpty()) {\n            res++; // Increment res at each level\n            int size = q.size();\n            for (int i = 0; i &lt; size; i++) {\n                String w = q.poll();\n                for (int z = 0; z &lt; w.length(); z++) {\n                    StringBuilder sb = new StringBuilder(w);\n                    sb.setCharAt(z, '*');\n                    String pattern = sb.toString();\n                    List&lt;String&gt; neigh = hm.getOrDefault(pattern, new ArrayList&lt;String&gt;());\n                    for (String nei : neigh) {\n                        if (nei.equals(endWord)) {\n                            return res; // Return res when endWord is found\n                        }\n                        if (set.contains(nei)) {\n                            continue;\n                        }\n                        q.offer(nei);\n                        set.add(nei);\n                    }\n                }\n            }\n        }\n\n        return 0;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#130-surrounded-regions","title":"130. Surrounded Regions","text":"<pre><code>class Solution {\n    public void dfs(int r, int c, char[][] board) {\n        if (r &lt; 0 || c &lt; 0 || r &gt;= board.length || c &gt;= board[0].length || board[r][c] != 'O') {\n            return;\n        }\n        board[r][c] = '*';\n        dfs(r + 1, c, board);\n        dfs(r, c + 1, board);\n        dfs(r - 1, c, board);\n        dfs(r, c - 1, board);\n    }\n\n    public void solve(char[][] board) {\n        int rows = board.length;\n        int cols = board[0].length;\n\n        // Start DFS from border cells in the first and last columns\n        for (int r = 0; r &lt; rows; r++) {\n            dfs(r, 0, board);\n            dfs(r, cols - 1, board);\n        }\n\n        // Start DFS from border cells in the first and last rows\n        for (int c = 0; c &lt; cols; c++) {\n            dfs(0, c, board);\n            dfs(rows - 1, c, board);\n        }\n\n        // Convert '*' back to 'O' and 'O' to 'X'\n        for (int r = 0; r &lt; rows; r++) {\n            for (int c = 0; c &lt; cols; c++) {\n                if (board[r][c] == 'O') {\n                    board[r][c] = 'X';\n                } else if (board[r][c] == '*') {\n                    board[r][c] = 'O';\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"LeetCode/#133-clone-graph","title":"133. Clone Graph","text":"<pre><code>class Solution {\n\n    /*\n        t.c - o(n) - to iterate over the n elements\n        s.c - o(n) - to store n elements in the map\n        approach:\n        1. edge case , if the node is null , return\n        2. start with the first node , maintain a map (integer,Node) to store the elements\n        3. in the dfs func , if the node exists return else create a new node and add the children of the elems\n        4. return\n\n    */\n\n    public Node dfs(Node node){\n        if(hs.containsKey(node.val)){\n            return hs.get(node.val);\n        }\n        //create a new node\n        Node cp = new Node(node.val,new ArrayList&lt;&gt;());\n        hs.put(node.val,cp);\n        //iterate over the children\n        for(Node child: node.neighbors){\n            cp.neighbors.add(dfs(child));\n        }\n\n        return cp;\n\n    }\n\n    private HashMap&lt;Integer,Node&gt; hs = new HashMap&lt;&gt;();\n\n    public Node cloneGraph(Node node) {\n        if(node==null){\n            return null;\n        }\n\n        return dfs(node);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#200-number-of-islands","title":"200. Number of Islands","text":"<pre><code>class Solution {\n    /*\n        t.c - O(m*n) - 2 loops to check the element , dfs takes O(1)\n        s.c - O(m*n) - worst case if complete graph is an island , size of the call stack\n\n        approach:\n        1. init row and col values , check if the element is 0 or 1\n        2. if 1 --&gt; check its neighbours\n        3. if neighbours are 1 , mark them as 0 and move to find the next elem in the two nested loops\n        4. return count\n\n    */\n\n\n    private void dfs(int r, int c , char[][] grid){\n        //check boundaries\n        if(r&lt;0 || c&lt;0 || r&gt;=grid.length || c&gt;=grid[0].length || grid[r][c]=='0'){\n            return;\n        }\n        //mark as visited\n        grid[r][c]='0';\n        dfs(r+1,c,grid);\n        dfs(r-1,c,grid);\n        dfs(r,c+1,grid);\n        dfs(r,c-1,grid);\n    }\n\n    public int numIslands(char[][] grid) {\n        if(grid.length==0){\n            return 0;\n        }\n\n        int row = grid.length;\n        int col = grid[0].length;\n        int res = 0;\n\n        for(int r = 0; r&lt;row;r++){\n            for(int c = 0 ;c&lt;col;c++){\n                if(grid[r][c]=='1'){\n                    dfs(r,c,grid);\n                    res++;\n                }\n            }\n        }\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#207-course-schedule","title":"207. Course Schedule","text":"<pre><code>class Solution {\n\n    private Map&lt;Integer,List&lt;Integer&gt;&gt; hm = new HashMap&lt;&gt;();\n    private Set&lt;Integer&gt; set = new HashSet&lt;&gt;();\n\n    public boolean dfs(int course){\n        if(set.contains(course)){\n            //found cycle\n            return false;\n        }\n\n        //if an empty list is found as value for key in hm , not more pre --&gt; can finsh the course\n        if(hm.get(course).size()==0){\n            return true;\n        }\n\n        set.add(course);\n        List&lt;Integer&gt; pre = hm.get(course);\n        for(var el:pre){\n            if(!dfs(el)){\n                return false;\n            }\n        }\n        set.remove(course);\n        //mark the pre as visited\n        hm.get(course).clear();\n        return true;\n\n\n    }\n\n    public boolean canFinish(int numCourses, int[][] prerequisites) {\n        //create a hashMap to store the crs: pre pairs\n\n\n        //create empty ArrayList for each course\n        for(int z = 0 ; z&lt;numCourses;z++){\n            hm.put(z,new ArrayList&lt;&gt;());\n        }\n\n        for(int[] preList:prerequisites){\n            int crs = preList[0];\n            int pre = preList[1];\n\n            List&lt;Integer&gt; ls = hm.get(crs);\n            ls.add(pre);\n        }\n\n\n\n        //iterate through all the courses if in case its an unconnected graph\n\n        for(int x = 0 ; x&lt;numCourses;x++){\n            if(!dfs(x)){\n                return false;\n            }\n        }\n\n        return true;\n\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#210-course-schedule-ii","title":"210. Course Schedule II","text":"<pre><code>class Solution {\n\n\n    //variable instantitaion\n\n    private List&lt;Integer&gt; mid = new ArrayList&lt;&gt;();\n    private Set&lt;Integer&gt; cycle = new HashSet&lt;&gt;();\n    private Set&lt;Integer&gt; vis = new HashSet&lt;&gt;();\n    private Map&lt;Integer,List&lt;Integer&gt;&gt; hm = new HashMap&lt;&gt;();\n\n\n    public boolean dfs(int course,int[] res){\n        if(cycle.contains(course)){\n            return false;\n        }\n\n        if(vis.contains(course)){\n            //already visited no need to continue\n            return true;\n        }\n\n        cycle.add(course);\n        //do a dfs for each pre\n        List&lt;Integer&gt; pre = hm.get(course);\n        for(var el:pre){\n            if(!dfs(el,res)){\n                return false;\n            }\n        }\n        mid.add(course);\n        cycle.remove(course);\n        vis.add(course);\n        return true;\n    }\n\n    public int[] findOrder(int numCourses, int[][] prerequisites) {\n        //create an empty list for each crs\n        int[] res = new int[numCourses];\n\n        for(int z = 0 ;z&lt;numCourses;z++)\n            hm.put(z,new ArrayList&lt;&gt;());\n\n        //add prereq to the crs\n        for(int[] el : prerequisites){\n            int crs = el[0];\n            int pre = el[1];\n            List&lt;Integer&gt; ls = hm.get(crs);\n            ls.add(pre);\n        }\n\n        //run dfs for all the courses\n        for(int x = 0 ; x&lt;numCourses;x++){\n            if(!dfs(x,res)){\n                return new int[0];\n            }\n        }\n\n        //add values to res\n        for (int i = 0; i &lt; numCourses; i++) {\n            res[i] = mid.get(i); // Reversed order\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#417-pacific-atlantic-water-flow","title":"417. Pacific Atlantic Water Flow","text":"<pre><code>class Solution {\n\n    int[][] dir = { { 0, 1 }, { 0, -1 }, { 1, 0 }, { -1, 0 } };\n\n    public List&lt;List&lt;Integer&gt;&gt; pacificAtlantic(int[][] heights) {\n        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n\n        int rows = heights.length, cols = heights[0].length;\n        boolean[][] pacific = new boolean[rows][cols];\n        boolean[][] atlantic = new boolean[rows][cols];\n\n        for (int i = 0; i &lt; cols; i++) {\n            dfs(heights, 0, i, Integer.MIN_VALUE, pacific);\n            dfs(heights, rows - 1, i, Integer.MIN_VALUE, atlantic);\n        }\n\n        for (int i = 0; i &lt; rows; i++) {\n            dfs(heights, i, 0, Integer.MIN_VALUE, pacific);\n            dfs(heights, i, cols - 1, Integer.MIN_VALUE, atlantic);\n        }\n\n        for (int i = 0; i &lt; rows; i++) {\n            for (int j = 0; j &lt; cols; j++) {\n                if (pacific[i][j] &amp;&amp; atlantic[i][j]) {\n                    res.add(Arrays.asList(i, j));\n                }\n            }\n        }\n        return res;\n    }\n\n    private void dfs(\n        int[][] heights,\n        int i,\n        int j,\n        int prev,\n        boolean[][] ocean\n    ) {\n        if (i &lt; 0 || i &gt;= ocean.length || j &lt; 0 || j &gt;= ocean[0].length) return;\n        if (heights[i][j] &lt; prev || ocean[i][j]) return;\n\n        ocean[i][j] = true;\n        for (int[] d : dir) {\n            dfs(heights, i + d[0], j + d[1], heights[i][j], ocean);\n        }\n    }\n}\n</code></pre>"},{"location":"LeetCode/#684-redundant-connection","title":"684. Redundant Connection","text":"<pre><code>class Solution {\n    /*\n        t.c. - o(n) , for find and union function for n edges\n        s.c - o(n+1) - to store (n+1) elements in int[] to store parent , rank\n\n        appraoch:\n        1. union function , returns the parent of two nodes\n        2. find function , returns the parent of a node\n        3. for all the nodes in the int[][] , return the uninon function , if both have same parent found the res\n        4. return res\n\n    */\n\n    private int[] parent;\n    private int[] rank;\n\n    //function to find union\n    public boolean union(int n1,int n2){\n        int p1 = find(n1);\n        int p2 = find(n2);\n\n        if(p1==p2){\n            //found same parent edge found\n            return false;\n        }\n        if(rank[p1]&lt;rank[p2]){\n            parent[p1] = p2;\n        }\n        else if(rank[p1]&gt;rank[p2]){\n            parent[p2] = p1;\n        }\n        else{\n            parent[p1] = p2;\n            rank[p2]++;\n        }\n        return true;\n\n    }\n\n    //function to find the parent\n    public int find(int u){\n        return parent[u] == u ? u : (parent[u] = find(parent[u]));\n    }\n\n\n    public int[] findRedundantConnection(int[][] edges) {\n        int n = edges.length+1;\n        parent = new int[n];\n        rank = new int[n];\n\n        //fill the parent array\n        for(int z = 0 ; z&lt;n ; z++){\n            parent[z] = z;\n        }\n\n        for(int[] node:edges){\n            if(!union(node[0],node[1])){\n                return node;\n            }\n        }\n\n        throw new IllegalArgumentException();\n\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#695-max-area-of-island","title":"695. Max Area of Island","text":"<pre><code>class Solution {\n    /*\n        t.c - O(m*n)\n        s.c - o(m*n) -- recursive call stack\n\n        approach:\n        1. init val as 0 , start the dfs\n        2. check if inbounds (should be inside the range) , add 1 to it and return the max area\n    */\n    private int res = 0;\n    public int dfs(int r , int c, int[][] grid){\n        //check if in the bounds\n        if(r&lt;0 || c&lt;0 || r==grid.length || c==grid[0].length || grid[r][c]==0){\n            return 0;\n        }\n        //mark as vis\n        grid[r][c]=0;\n        return (1+ dfs(r+1,c,grid)+ dfs(r,c+1,grid)+ dfs(r,c-1,grid)+ dfs(r-1,c,grid));\n    }\n\n    public int maxAreaOfIsland(int[][] grid) {\n        int row = grid.length;\n        int col = grid[0].length;\n        for(int r = 0;r&lt;row;r++){\n            for(int c = 0 ; c&lt;col ; c++){\n                res = Math.max(dfs(r,c,grid),res);\n            }\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#994-rotting-oranges","title":"994. Rotting Oranges","text":"<pre><code>class Solution {\n\n    private static class Cell {\n        int row;\n        int col;\n\n        public Cell(int row, int col) {\n            this.row = row;\n            this.col = col;\n        }\n    }\n\n    public int orangesRotting(int[][] grid) {\n        Deque&lt;Cell&gt; q = new ArrayDeque&lt;&gt;();\n\n        int res = 0;\n        int freshOranges = 0;\n\n        // Count the fresh oranges and add the rotten to the queue\n        int row = grid.length;\n        int col = grid[0].length;\n\n        for (int r = 0; r &lt; row; r++) {\n            for (int c = 0; c &lt; col; c++) {\n                if (grid[r][c] == 1) {\n                    freshOranges++;\n                } else if (grid[r][c] == 2) {\n                    q.offer(new Cell(r, c));\n                }\n            }\n        }\n\n        int[][] directions = {{0, 1}, {0, -1}, {-1, 0}, {1, 0}};\n\n        // BFS on the grid\n        while (q.size() &gt; 0 &amp;&amp; freshOranges &gt; 0) {\n            int size = q.size();\n            for (int e = 0; e &lt; size; e++) {\n                Cell cell = q.poll();\n                int elRow = cell.row;\n                int elCol = cell.col;\n                for (int[] dire : directions) {\n                    int newRow = elRow + dire[0];\n                    int newCol = elCol + dire[1];\n                    if (newRow &gt;= 0 &amp;&amp; newCol &gt;= 0 &amp;&amp; newRow &lt; row &amp;&amp; newCol &lt; col &amp;&amp; grid[newRow][newCol] == 1) {\n                        // Found a fresh orange, change to rotten and add to queue\n                        grid[newRow][newCol] = 2;\n                        q.offer(new Cell(newRow, newCol));\n                        freshOranges--;\n                    }\n                }\n            }\n            res++;\n        }\n\n        return freshOranges == 0 ? res : -1;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#advanced-graphs","title":"Advanced Graphs","text":""},{"location":"LeetCode/#332-reconstruct-itinerary","title":"332. Reconstruct Itinerary","text":"<pre><code>class Solution {\n    /*\n        approach:\n\n        1. using dfs approach on the graph to find the next nodes (need to explore the present branch before backtracking on the node)\n        2. to store the neigh's of the nodes in the adj list , use a priority queue\n        3. use a stack to store the current visited node\n        4. add to stack until neighbours are null\n        5. pop from stack and add to res\n        6. return reverse of the linked list (can use addFirst to avoid reversing while poping from the stack)\n\n        t.c:\n        1. to construct adj list , O(no. of tickes * log(no.of tickets)) (with lexical sort)\n        2. stack calls O(E)\n        total -&gt; O(E.log(E))\n\n        s.c:\n        1. to store nodes in graph , O(E)\n        2. stack , O(E)\n        3. res O(E)\n        total -&gt; O(E)\n    */\n\n    private LinkedList&lt;String&gt; res = new LinkedList&lt;&gt;();\n    private Stack&lt;String&gt; st = new Stack();\n    private Map&lt;String,PriorityQueue&lt;String&gt;&gt; gr = new HashMap&lt;&gt;();\n\n    public List&lt;String&gt; findItinerary(List&lt;List&lt;String&gt;&gt; tickets) {\n        //iterate over the tickets and build the graph\n\n        for(var ticket:tickets){\n            gr.putIfAbsent(ticket.get(0),new PriorityQueue&lt;&gt;());\n            gr.get(ticket.get(0)).offer(ticket.get(1));\n        }\n\n        st.push(\"JFK\");\n        while(!st.isEmpty()){\n            String nxt = st.peek();\n            if(!gr.getOrDefault(nxt, new PriorityQueue&lt;&gt;()).isEmpty()){\n                st.push(gr.get(nxt).poll()); // gets the next list and remove the first element\n            }\n            else{\n                //reached the end of the stack , keep building the res\n                res.addFirst(st.pop());\n            }\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#743-network-delay-time","title":"743. Network Delay Time","text":"<p><code>Dijkstra's approach</code></p> <pre><code>import java.util.*;\n\nclass Solution {\n    /*\n        1. generate adj list map(int, int[node,weight]) --&gt; keep track of neigh of each node\n        2. init a dist matrix with values as int_max except for node k\n        3. maintain a queue(int[node,weight]) , init with [source,0]\n        4. until q is empty , pop a node , travese its neigh and update the dist matrix\n        5. return the max of dist mat\n    */\n    public int networkDelayTime(int[][] times, int n, int k) {\n        Map&lt;Integer, List&lt;int[]&gt;&gt; mp = new HashMap&lt;&gt;();\n        PriorityQueue&lt;int[]&gt; q = new PriorityQueue&lt;&gt;((a, b) -&gt; a[1] - b[1]);\n        int[] dist = new int[n + 1];\n        Arrays.fill(dist, Integer.MAX_VALUE);\n        int res = -1;\n\n        dist[k] = 0;\n\n        for (int[] time : times) {\n            int source = time[0];\n            int dst = time[1];\n            int w = time[2];\n\n            mp.computeIfAbsent(source, key -&gt; new ArrayList&lt;&gt;()).add(new int[]{dst, w});\n        }\n\n        q.offer(new int[]{k, 0});\n\n        while (!q.isEmpty()) {\n            int[] el = q.poll();\n            int s = el[0];\n            int weight = el[1];\n\n            if (!mp.containsKey(s)) continue;\n\n            List&lt;int[]&gt; neigh = mp.get(s);\n            for (int[] nn : neigh) {\n                int nw = nn[1] + weight;\n                if (nw &lt; dist[nn[0]]) {\n                    dist[nn[0]] = nw;\n                    q.offer(new int[]{nn[0], nw});\n                }\n            }\n        }\n\n        for (int i = 1; i &lt;= n; i++) {\n            if (dist[i] == Integer.MAX_VALUE) {\n                return -1;\n            }\n            res = Math.max(res, dist[i]);\n        }\n        return res;\n    }\n}\n</code></pre> <p><code>Bell-man-ford approach</code></p> <pre><code>import java.util.*;\n\nclass Solution {\n    public int networkDelayTime(int[][] times, int n, int k) {\n        int[] dist = new int[n + 1];\n        Arrays.fill(dist, Integer.MAX_VALUE);\n        dist[k] = 0;\n\n        // Bellman-Ford algorithm\n        for (int i = 0; i &lt; n - 1; i++) {\n            for (int[] time : times) {\n                int source = time[0];\n                int dst = time[1];\n                int weight = time[2];\n\n                if (dist[source] != Integer.MAX_VALUE &amp;&amp; dist[source] + weight &lt; dist[dst]) {\n                    dist[dst] = dist[source] + weight;\n                }\n            }\n        }\n\n        int res = -1;\n\n        for (int i = 1; i &lt;= n; i++) {\n            if (dist[i] == Integer.MAX_VALUE) {\n                return -1;\n            }\n            res = Math.max(res, dist[i]);\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#back-tracking","title":"Back Tracking","text":""},{"location":"LeetCode/#17-letter-combinations-of-a-phone-number","title":"17. Letter Combinations of a Phone Number","text":"<pre><code>class Solution {\n\n    /*\n        t.c - o(4^n) - n : no of digits\n        s.c - o(n.4^n)\n\n        approach:\n            1. make a map from digit:characters\n            2. make dfs adding to subset str and increment index\n            3. if len() matches , add to res\n            4. return\n\n    */\n\n\n    private List&lt;String&gt; res = new ArrayList&lt;&gt;();\n\n    public void dfs(int index ,String subset,String digits,Map&lt;Character,String&gt; digitToChar){\n        if(subset.length() == digits.length()){\n            res.add(subset);\n            return;\n        }\n\n        if(index &gt;= digits.length()){\n            return;\n        }\n\n        String dig = digitToChar.get(digits.charAt(index));\n        for(char c : dig.toCharArray()){\n            dfs(index+1,subset+c,digits,digitToChar);\n        }\n    }\n\n    public List&lt;String&gt; letterCombinations(String digits) {\n        /*\n        */\n\n        Map&lt;Character, String&gt; digitToChar = Map.of(\n            '2',\n            \"abc\",\n            '3',\n            \"def\",\n            '4',\n            \"ghi\",\n            '5',\n            \"jkl\",\n            '6',\n            \"mno\",\n            '7',\n            \"pqrs\",\n            '8',\n            \"tuv\",\n            '9',\n            \"wxyz\"\n        );\n\n    if(digits.length()==0){\n        return new ArrayList&lt;&gt;();\n    }\n\n    dfs(0,\"\",digits,digitToChar);\n\n    return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#39-combination-sum","title":"39. Combination Sum","text":"<pre><code>class Solution {\n\n    private List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n\n    /*\n        t.c - o(2^target)\n        s.c - o(target) - arrayList for target amount\n\n        approach:\n        1. two decision , one to include the number , target = total - val[index]\n        2. second decision , not to include the number , index++\n        3. if target == 0 , add to res\n        4. base case --&gt; if target &lt; 0 or index &gt; len(nums) , return\n        5. return res\n\n    */\n\n\n    public void dfs(int index, List&lt;Integer&gt; subset, int target, int[] candidates, int total) {\n        // Base case: if the target is reached, add the current subset to the result\n        if (target == 0) {\n            res.add(new ArrayList&lt;&gt;(subset));\n            return;\n        }\n\n        // If the target is exceeded or all elements are processed, return\n        if (target &lt; 0 || index &gt;= candidates.length) {\n            return;\n        }\n\n        // Include the current element and make the recursive call with the same index\n        subset.add(candidates[index]);\n        dfs(index, subset, target - candidates[index], candidates, total + candidates[index]);\n\n        // Exclude the current element and make the recursive call with the next index\n        subset.remove(subset.size() - 1);\n        dfs(index + 1, subset, target, candidates, total);\n    }\n\n    public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) {\n        dfs(0, new ArrayList&lt;&gt;(), target, candidates, 0);\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#40-combination-sum-ii","title":"40. Combination Sum II","text":"<pre><code>class Solution {\n\n    /*\n        t.c - o(2^n)\n        s.c - o(n.2^n) , n arrayLists for 2^n times\n\n        approach:\n        1. sort the array\n        2. init dfs , two choices to add the elem and not to add the elem\n        3. check if the current elem is same as next (or prev according to implementation)\n        4. if same skip the elem\n        5. return\n\n\n    */\n\n    private List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n\n    public void dfs(int index , List&lt;Integer&gt; subset, List&lt;List&lt;Integer&gt;&gt; res, int target , int[] nums){\n        if(target&lt;0){\n            return;\n        }\n\n        if(target==0){\n            res.add(new ArrayList&lt;&gt;(subset));\n            return;\n        }\n\n\n        for (int i = index; i &lt; nums.length; i++) {\n            if (i &gt; index &amp;&amp; nums[i] == nums[i - 1]) continue;\n            subset.add(nums[i]);\n            dfs(i+1, subset,res,target - nums[i], nums);\n            subset.remove((subset.size() - 1));\n        }\n\n    }\n\n\n    public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) {\n        Arrays.sort(candidates);\n        dfs(0,new ArrayList&lt;&gt;(), res, target,candidates);\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#46-permutations","title":"46. Permutations","text":"<pre><code>class Solution {\n\n\n    private List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n\n\n    public void backTrack(boolean[] usedValues , List&lt;Integer&gt; subset , int[] nums){\n        //base case\n        if(subset.size() == nums.length){\n            res.add(new ArrayList&lt;&gt;(subset));\n            return;\n        }\n\n        for(int z = 0 ; z&lt; nums.length; z++){\n            if(usedValues[z]){ //value already added\n                continue;\n            }\n\n            usedValues[z] = true;\n            subset.add(nums[z]);\n            backTrack(usedValues,subset,nums);\n            subset.remove(subset.size()-1);\n            usedValues[z] = false; //backtrack\n        }\n    }\n\n    public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) {\n        /*\n            t.c - O(n*n!)\n            s.c - O(n!)\n\n            approach:\n            1. use a boolean array to keep track whether a val is added or not\n            2. if not added , set to true , add to subset\n            3. backtrack setting it false for  next index\n            4. return res\n        */\n\n        backTrack(new boolean[nums.length], new ArrayList&lt;&gt;(), nums);\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#51-n-queens","title":"51. N-Queens","text":"<pre><code>class Solution {\n\n\n    public void dfs(int r , int n , boolean[] col , boolean[] posDiag , boolean[] negDiag , char[][] board ){\n        if(r==n){\n            //construct string and add to res\n            res.add(constructString(board));\n            return;\n        }\n\n        for(int c = 0 ; c&lt;n;++c){\n            //check if the c is visited , or posDiag is vis or negDiag is vis\n            if(col[c] || posDiag[r+c] || negDiag[r-c+n-1]){\n                continue;\n            }\n\n            //mark as vis\n            col[c] = true;\n            posDiag[r+c] = true; // n = 4 , r = 1 , c = 2 (3) , max of PosDiag (0,7)\n            negDiag[r-c+n-1] = true;\n            board[r][c] = 'Q';\n\n            dfs(r+1,n,col,posDiag,negDiag,board);\n\n            //remove and backtrack\n            col[c] = false;\n            posDiag[r+c] = false;\n            negDiag[r-c+n-1] = false;\n            board[r][c] = '.';\n        }\n\n    }\n\n    public List&lt;String&gt; constructString(char[][] board){\n        List&lt;String&gt; el = new ArrayList&lt;&gt;();\n        for(int r = 0 ; r&lt;board.length;r++){\n            el.add(String.valueOf(board[r]));\n        }\n        return el;\n\n    }\n\n    private List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;();\n\n    public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) {\n\n        /*\n            t.c - n.n!\n            dfs --&gt; n!\n            constructString --&gt; n (traverse through each row)\n            s.c\n            new List&lt;List&gt; to store res\n\n            approach:\n            1. init the board with '.' in n*n\n            2. keep track of visited col, positiveDiagonal , negative diagonal using boolean[]\n            3. if row==n, add to res (all rows visited)\n            4. visit each col and mark as visited , do dfs, mark unvisited for backtracking\n            5. return\n        */\n        char[][] board = new char[n][n];\n        //fill the board\n        for(int r = 0 ; r&lt;n;r++){\n            Arrays.fill(board[r],'.');\n        }\n\n        dfs(0,n,new boolean[n],new boolean[2*n-1],new boolean[2*n-1],board);\n\n        return res;\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#78-subsets","title":"78. Subsets","text":"<pre><code>class Solution {\n    /*\n        t.c - o(2^n)\n        s.c - o(n*2^n)\n\n        approach:\n        1. init res , start at index 0\n        2. at each index , 2 operations , either to add index or exclude the index\n        3. add to subset , call dfs , remove from subset , call dfs\n        4. if length reaches size of nums , add to res\n        5. return\n    */\n\n\n\n    public void dfs(int[] nums,int index,List&lt;Integer&gt; subset,List&lt;List&lt;Integer&gt;&gt; res){\n        if(index&gt;=nums.length){\n            res.add(new ArrayList&lt;&gt;(subset));\n            return;\n        }\n\n        //left tree add at index i\n        subset.add(nums[index]);\n        dfs(nums,index+1,subset,res);\n\n        //right tree not to add index i\n        subset.remove(subset.size()-1);\n        dfs(nums,index+1,subset,res);\n\n    }\n\n\n    public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) {\n        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n        dfs(nums,0,new ArrayList&lt;&gt;(),res);\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#79-word-search","title":"79. Word Search","text":"<pre><code>class Solution {\n    /*\n        t.c -&gt; o(m*n* 4^len(word))\n        s.c --&gt; (n.4^len(word)) --&gt; 4 dfs calls at each index\n\n        approach:\n        1. check the edge cases to exit the dfs\n        2. if index reaches the last index , return true\n        3. mark the el in board as visited and run dfs\n        4. modify the el back to its state to backtrack\n        5. return\n\n    */\n\n\n    public boolean dfs(int r, int c, char[][] board, String word, int index) {\n        //end cases\n        //row , column overflow\n        if (r &lt; 0 || r == board.length || c &lt; 0 || c == board[0].length) {\n            return false;\n        }\n\n        //index match\n        if (board[r][c] == word.charAt(index)) {\n            // If it is the last character of the word, return true\n            if (index == word.length() - 1) {\n                return true;\n            }\n\n            final char el = board[r][c];\n            // mark the el as visited\n            board[r][c] = '*';\n\n            // make a dfs on four directions\n            final boolean isValid = dfs(r + 1, c, board, word, index + 1) ||\n                                    dfs(r - 1, c, board, word, index + 1) ||\n                                    dfs(r, c + 1, board, word, index + 1) ||\n                                    dfs(r, c - 1, board, word, index + 1);\n\n            // replace the elem with cache\n            board[r][c] = el;\n\n            return isValid;\n        }\n\n        return false;\n    }\n\n    public boolean exist(char[][] board, String word) {\n        for (int r = 0; r &lt; board.length; r++) {\n            for (int c = 0; c &lt; board[0].length; c++) {\n                if (dfs(r, c, board, word, 0)) {\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#90-subsets-ii","title":"90. Subsets II","text":"<pre><code>class Solution {\n\n    /*\n        t.c - O(n*2^n)\n        s.c - o(n*2^n)\n\n        approach:\n        1. sort the arr , start the dfs\n        2. add at index , dfs on next non duplicate index , remove elem , backtrack\n        3. return res\n\n    */\n\n    private List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n\n\n    public void dfs(int index, List&lt;Integer&gt; subset, int[] nums){\n        res.add(new ArrayList&lt;&gt;(subset));\n\n        for (int i = index; i &lt; nums.length; i++) {\n            if (i &gt; index &amp;&amp; nums[i] == nums[i - 1]) {\n                continue; // Skip duplicates\n            }\n\n            subset.add(nums[i]);\n            dfs(i + 1, subset, nums);\n            subset.remove(subset.size() - 1);\n        }\n\n    }\n\n    public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) {\n        Arrays.sort(nums);\n        dfs(0,new ArrayList&lt;&gt;(),nums);\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#131-palindrome-partitioning","title":"131. Palindrome Partitioning","text":"<pre><code>class Solution {\n\n    private List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;();\n\n\n    public boolean isPalindrome(String s,int l,int r){\n        while(l&lt;r)\n            if(s.charAt(l++)!=s.charAt(r--))\n                return false;\n        return true;\n    }\n\n    public void dfs(String s, int index,List&lt;String&gt; subset){\n        if(index == s.length()){\n            res.add(new ArrayList&lt;&gt;(subset));\n            return;\n        }\n\n        for(int i = index ; i&lt;s.length();i++){\n            //check if palindrome from index, i\n            if(isPalindrome(s,index,i)){\n                subset.add(s.substring(index,i+1));\n                dfs(s,i+1,subset);\n                subset.remove(subset.size()-1);\n            }\n        }\n    }\n\n    public List&lt;List&lt;String&gt;&gt; partition(String s) {\n        dfs(s,0,new ArrayList&lt;&gt;());\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#trie","title":"Trie","text":""},{"location":"LeetCode/#208-implement-trie-prefix-tree","title":"208. Implement Trie (Prefix Tree)","text":"<pre><code>class TrieNode{\n    public TrieNode[] children = new TrieNode[26];\n    public boolean isEnd = false;\n}\n\nclass Trie {\n    /*\n        t.c: o(word)\n        s.c: o(word*avg(word))\n\n        approach:\n        1. init trie node class , each node consits of 26 children capacity and a boolean to check if its the end\n        2. to insert check if node exits , add it childrenm , else create a new node\n        3. to check startsWith , check if node exits ? true :false\n\n    */\n    private TrieNode root = new TrieNode();\n    //helper functions\n    public TrieNode find(String prefix) {\n        var curr = root;\n        for(char c : prefix.toCharArray()){\n            final int ind = c - 'a';\n            if(curr.children[ind]==null){\n                return null;\n            }\n            curr = curr.children[ind];\n        }\n        return curr;\n    }\n\n    public void insert(String word) {\n        TrieNode curr = root;\n        for(final char c:word.toCharArray()){\n            //find index\n            final int i = c - 'a';\n            if(curr.children[i]==null){\n                curr.children[i] = new TrieNode();\n            }\n            curr = curr.children[i];\n        }\n        curr.isEnd = true;\n    }\n\n    public boolean search(String word) {\n        var findNode = find(word);\n        return findNode!=null &amp;&amp; findNode.isEnd;\n\n    }\n\n    public boolean startsWith(String prefix) {\n        var findNode = find(prefix);\n        return findNode!=null;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#211-design-add-and-search-words-data-structure","title":"211. Design Add and Search Words Data Structure","text":"<pre><code>class TrieNode{\n    public TrieNode[] children = new TrieNode[26];\n    public boolean isEnd = false;\n}\n\nclass WordDictionary {\n    /*\n       t.c - add(o(word)) , search : o(26)\n\n       approach:\n       1. create words in the trie\n       2. to search , check if the value at index is '.'\n       3. if '.' --&gt; check if the next char exists then return true : false\n       4. if normal char , make a dfs on index+1\n       5.return\n    */\n\n    private TrieNode root = new TrieNode();\n\npublic boolean dfs(String word, TrieNode root, int ind) {\n    if (ind == word.length()) {\n        return root.isEnd;\n    }\n\n    // If not '.', do dfs on ind+1\n    if (word.charAt(ind) != '.') {\n        var nextNode = root.children[word.charAt(ind) - 'a'];\n        return nextNode == null ? false : dfs(word, nextNode, ind + 1);\n    }\n\n    // Found '.', check all 26 children\n    for (int z = 0; z &lt; 26; ++z) {\n        var nextChild = root.children[z];\n        if (nextChild != null &amp;&amp; dfs(word, nextChild, ind + 1)) {\n            return true;\n        }\n    }\n\n    // Not found\n    return false;\n}\n\n\n    public void addWord(String word) {\n        var curr = root;\n        for(final char c : word.toCharArray()){\n            final int ind = c - 'a';\n            if(curr.children[ind]==null){\n                curr.children[ind] = new TrieNode();\n            }\n            curr = curr.children[ind];\n        }\n        curr.isEnd = true;\n    }\n\n    public boolean search(String word) {\n        return dfs(word,root,0);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#212-word-search-ii","title":"212. Word Search II","text":"<pre><code>class TrieNode{\n    public TrieNode[] children = new TrieNode[26];\n    public boolean isEnd = false;\n}\n\nclass Solution {\n    /*\n        t.c -\n            addWords --&gt; o(total(words) * avg(word))\n            findWord --&gt; o(1)\n            dfs --&gt; o(row * col * 4^max(words) )\n\n        s.c -\n            addWords --&gt; o(total(words) * avg(word))\n            dfs --&gt; o(max(words))\n\n        approach:\n            1. init trienode class and add all the words\n            2. init dfs , check if its visited or exists in the trie\n            3. if exists , check if its the end , then add to string builder\n            4. else dfs in four directions\n            5. return\n\n    */\n\n\n    private TrieNode root = new TrieNode();\n    private List&lt;String&gt; res = new ArrayList&lt;&gt;();\n\n    private void addWords(TrieNode root,String[] words){\n        for(var word : words){\n            var curr = root;\n            for(final char c: word.toCharArray()){\n                final int index = c - 'a';\n                if(curr.children[index]==null){\n                    curr.children[index] = new TrieNode();\n                }\n                curr = curr.children[index];\n            }\n            curr.isEnd = true;\n        }\n    }\n\n    private boolean findWord(TrieNode root,char el){\n        int index = el - 'a';\n        return root.children[index]!=null;\n    }\n\n\n    private void dfs(int row, int col, char[][] board,TrieNode root,StringBuilder word){\n        // 1.check if the elem exists in root.children (first level) , else go to next\n        // 2. do a dfs and check if word forms and add it to res\n        char el = board[row][col];\n        if(el=='$' || !findWord(root,el)){\n            return;\n        }\n\n        root = root.children[el - 'a'];\n        word.append(el);\n        if (root.isEnd) {\n            res.add(word.toString());\n            root.isEnd = false; // Mark as visited to avoid duplicates\n        }\n\n        char temp = board[row][col];\n        board[row][col] = '$'; // Mark the cell as visited\n\n        if (row &gt; 0) dfs(row - 1, col, board, root, word);\n        if (row &lt; board.length - 1) dfs(row + 1, col, board, root, word);\n        if (col &gt; 0) dfs(row, col - 1, board, root, word);\n        if (col &lt; board[0].length - 1) dfs(row, col + 1, board, root, word);\n\n        board[row][col] = temp; // Restore the cell value for backtracking\n        word.deleteCharAt(word.length() - 1);\n    }\n\n    public List&lt;String&gt; findWords(char[][] board, String[] words) {\n        final int r = board.length;\n        final int c = board[0].length;\n        addWords(root, words);\n\n        for (int row = 0; row &lt; r; ++row) {\n            for (int col = 0; col &lt; c; ++col) {\n                dfs(row, col, board, root, new StringBuilder());\n            }\n        }\n\n        return res;\n\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#binary-tree","title":"Binary Tree","text":""},{"location":"LeetCode/#98-validate-binary-search-tree","title":"98. Validate Binary Search Tree","text":"<pre><code>class Solution {\n    /*\n        t.c - o(n)\n        s.c - o(h)\n        approach:\n        1. to validate have to check the boundaries for each iteration\n        2. init the iteration with -inf to +inf\n        3. for each iter, for left tree update right boundary to root.val\n        4. for each iter , for right tree update left boundary to root.val\n        5. if condition is not satisfied ? return false : true\n\n    */\n    public boolean dfs(TreeNode root,Integer left,Integer right){\n        if(root==null){\n            //empty tree can be a bst\n            return true;\n        }\n        if((left!=null &amp;&amp; root.val&lt;=left)||( right!=null &amp;&amp; root.val&gt;=right)){\n            // condition not satisfied for a bst\n            return false;\n        }\n\n        return ((dfs(root.left,left,root.val))&amp;&amp;(dfs(root.right,root.val,right)));\n    }\n\n\n    public boolean isValidBST(TreeNode root) {\n        return dfs(root,null,null);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#102-binary-tree-level-order-traversal","title":"102. Binary Tree Level Order Traversal","text":"<pre><code>class Solution {\n\n    /*\n        t.c - o(n)\n        s.c - o(n)\n        approach:\n            1. init a deque with root elem\n            2. if elem has left and right , append them into queue\n            3. in the range of the lenght of q , pop left and add to currlevel , if it has left and right append to q\n\n    */\n\n\n    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) {\n        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\n        if(root==null){\n            return res;\n        }\n       Deque&lt;TreeNode&gt; q = new ArrayDeque&lt;&gt;();\n        q.offer(root);\n        while(!q.isEmpty()){\n            List&lt;Integer&gt; currLevel = new ArrayList&lt;&gt;();\n            int levelSize = q.size();\n            for(int z = 0;z&lt;levelSize;z++){\n                TreeNode t = q.pollFirst();\n                currLevel.add(t.val);\n                if(t.left!=null){\n                    q.offer(t.left);\n                }\n                if(t.right!=null){\n                    q.offer(t.right);\n                }\n            }\n            res.add(currLevel);\n        }\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#105-construct-binary-tree-from-preorder-and-inorder-traversal","title":"105. Construct Binary Tree from Preorder and Inorder Traversal","text":"<pre><code>class Solution {\n    /*\n        t.c - o(n)\n        s.c - o(n) - hm to hold the index of the elements\n        approach:\n        1. two diff traversals are pre-order(root,left,right) and inorder(left,root,right)\n        2. the first index of preorder is always the root , check for the index of root in inorder\n        3. everything left to the found index , will be in the left subtree of the root\n        4. everything right to the found index , will be in the right subtree of the root\n        5. build the tree accordingly\n    */\n\n\n    public TreeNode build(int[] preorder, int preStart , int preEnd , int[] inorder , int inStart, int inEnd,   Map&lt;Integer,Integer&gt; inToIndex){\n        //base case to exit\n        if (preStart &gt; preEnd)\n            return null;\n\n        final int rootVal = preorder[preStart];\n        final int rootInIndex = inToIndex.get(rootVal);\n        final int leftSize = rootInIndex - inStart;\n\n        TreeNode root = new TreeNode(rootVal);\n        //root.left\n        //preorder --&gt; [1:mid+1] , inorder[:mid]\n\n        root.left = build(preorder, preStart + 1, preStart + leftSize, inorder, inStart,\n                        rootInIndex - 1, inToIndex);\n\n        //root.right\n        //preorder --&gt; [mid+1:] , inorder [mid+1:]\n        root.right = build(preorder, preStart + leftSize + 1, preEnd, inorder, rootInIndex + 1, inEnd,inToIndex);\n\n        return root;\n    }\n\n\n    public TreeNode buildTree(int[] preorder, int[] inorder) {\n        //hm to store the indexes\n         Map&lt;Integer, Integer&gt; inToIndex = new HashMap&lt;&gt;();\n\n        for (int i = 0; i &lt; inorder.length; ++i)\n            inToIndex.put(inorder[i], i);\n\n        return build(preorder, 0, preorder.length - 1, inorder, 0, inorder.length - 1, inToIndex);\n    }\n\n}\n</code></pre>"},{"location":"LeetCode/#110-balanced-binary-tree","title":"110. Balanced Binary Tree","text":"<pre><code>class Solution {\n    /*\n        t.c - o(n)\n        s.c - o(h)\n        approach: (bottom up to reduce to o(n), top down is o(n**2))\n            1. initially if root is null , return a new pair of (true,0)\n            2. check for left and right node , if both the trees are valid and their height diff &lt;=1\n            3. return the boolean at last\n    */\n    public Pair&lt;Boolean,Integer&gt; dfs(TreeNode root){\n        if(root==null){\n            return new Pair&lt;Boolean,Integer&gt;(true,0);\n        }\n\n        var left = dfs(root.left);\n        var right = dfs(root.right);\n\n        Boolean balanced = (left.getKey() &amp;&amp; right.getKey() &amp;&amp; Math.abs(left.getValue() - right.getValue())&lt;=1);\n\n        return new Pair&lt;Boolean,Integer&gt;(balanced, 1 + Math.max(left.getValue(),right.getValue()));\n    }\n\n    public boolean isBalanced(TreeNode root) {\n        return dfs(root).getKey();\n    }\n}\n</code></pre>"},{"location":"LeetCode/#124-binary-tree-maximum-path-sum","title":"124. Binary Tree Maximum Path Sum","text":"<pre><code>class Solution {\n    /*\n        t.c - o(n)\n        s.c - o(h)\n        approach:\n            1. two possible options for every node , either to split it or not split it\n            2. make two calculations and update the max variable\n            3. return the max variable\n\n    */\n\n    private int res = Integer.MIN_VALUE;\n\n    private int dfs(TreeNode root){\n        //base case\n        if(root==null)\n            return 0;\n\n        final int leftSum = Math.max(dfs(root.left),0);\n        final int rightSum = Math.max(dfs(root.right),0);\n        //with splitting\n        res = Math.max(res, root.val + leftSum + rightSum);\n        //without splitting (either take the left path or the right path )\n        return root.val + Math.max(leftSum,rightSum);\n\n    }\n\n    public int maxPathSum(TreeNode root) {\n        dfs(root);\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#199-binary-tree-right-side-view","title":"199. Binary Tree Right Side View","text":"<pre><code>class Solution {\n    /*\n        t.c o(n)\n        s.c o(n)\n        approach:\n            1. init empty res , if root is null return empty res\n            2. add root to queue and start bfs\n            3. in each iter, add the last elem of the level to the res\n            4. return\n    */\n\n    public List&lt;Integer&gt; rightSideView(TreeNode root) {\n        List&lt;Integer&gt; res = new ArrayList&lt;&gt;();\n        //base case\n        if(root==null){\n            return res;\n        }\n       Deque&lt;TreeNode&gt; q = new ArrayDeque&lt;&gt;();\n        q.offer(root);\n        while(!q.isEmpty()){\n            TreeNode rightNode = null;\n            int levelSize = q.size();\n            for(int z = 0;z&lt;levelSize;z++){\n                TreeNode t = q.pollFirst();\n                rightNode = t;\n                if(t.left!=null){\n                    q.offer(t.left);\n                }\n                if(t.right!=null){\n                    q.offer(t.right);\n                }\n            }\n            res.add(rightNode.val);\n        }\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#230-kth-smallest-element-in-a-bst","title":"230. Kth Smallest Element in a BST","text":"<pre><code>class Solution {\n    /*\n        t.c - o(n)\n        s.c - o(h)\n        approach:\n        1. init an array list to store the elem\n        2. do an in order traversal and store the values\n        3. return k-1\n    */\n\n    public void inOrder(TreeNode root, List&lt;Integer&gt; res){\n        if(root==null) return;\n\n        inOrder(root.left,res);\n        res.add(root.val);\n        inOrder(root.right,res);\n    }\n\n    public int kthSmallest(TreeNode root, int k) {\n        List&lt;Integer&gt; res = new ArrayList&lt;&gt;();\n        inOrder(root,res);\n        return res.get(k-1);\n    }\n}\n</code></pre> <p><code>stack</code> - approach</p> <pre><code>class Solution {\n    /*\n        t.c - o(n)\n        s.c - o(h)\n        approach:\n        1. init stack and append root\n        2. traverse until the end of the left tree\n        3. for k-1 times , pop from stack and move the root to right tree and traverse it's left tree\n        4. return top of the stack value\n    */\n\n    public int kthSmallest(TreeNode root, int k) {\n        Stack&lt;TreeNode&gt; st = new Stack&lt;&gt;();\n        TreeNode curr = root;\n\n        while(curr!=null){\n            st.push(curr);\n            curr = curr.left;\n        }\n\n        //at the end of the left\n\n        for(int z = 0 ; z&lt;k-1;z++){\n            TreeNode tmp = st.pop();\n            tmp = tmp.right;\n            while(tmp!=null){\n                st.push(tmp);\n                tmp = tmp.left;\n            }\n        }\n\n        return st.peek().val;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#235-lowest-common-ancestor-of-a-binary-search-tree","title":"235. Lowest Common Ancestor of a Binary Search Tree","text":"<pre><code>class Solution {\n    /*\n        LCA - either p,q is descent of the elem or the elem is equal to p or q (can be descendant of itself)\n        t.c - o(logn)\n        s.c - o(1)\n\n        approach:\n            1. have to return the node where both p and q are not greater or less than the TreeNode elem\n            2. start with root , check two conditions to change the curr to left or right\n            3. return the curr , when the condition satisfies\n\n    */\n\n\n    public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {\n        TreeNode curr = root;\n\n        while(curr!=null){\n            if(p.val&gt; curr.val &amp;&amp; q.val &gt; curr.val){\n                //present in the right tree\n                curr = curr.right;\n            }\n            else if(p.val &lt; curr.val &amp;&amp; q.val &lt; curr.val){\n                //present in left tree\n                curr = curr.left;\n            }\n            else{\n                return curr;\n            }\n        }\n        return null;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#297-serialize-and-deserialize-binary-tree","title":"297. Serialize and Deserialize Binary Tree","text":"<pre><code>public class Codec {\n    /*\n\n        approach:\n        1. either use dfs/bfs to create a string , seperated by delimiter\n        2. use the string and start a dfs to construct the tree\n        3. return node\n\n    */\n\n    private int index = 0;\n\n    public void serializeDFS(TreeNode root,List&lt;String&gt; res){\n        if(root==null){\n            res.add(\"N\");\n            return;\n        }\n        res.add(String.valueOf(root.val));\n        serializeDFS(root.left,res);\n        serializeDFS(root.right,res);\n    }\n\n    public TreeNode deserializeDFS(String[] tokens){\n\n        String str = tokens[this.index];\n        if(str.equals(\"N\")){\n            this.index++;\n            return null;\n        }\n\n        TreeNode nn = new TreeNode(Integer.parseInt(str));\n        this.index++;\n        nn.left = deserializeDFS(tokens);\n        nn.right = deserializeDFS(tokens);\n\n        return nn;\n    }\n\n    // Encodes a tree to a single string.\n    public String serialize(TreeNode root) {\n        List&lt;String&gt; res = new ArrayList&lt;&gt;();\n        serializeDFS(root,res);\n        return String.join(\",\",res);\n    }\n\n    // Decodes your encoded data to tree.\n    public TreeNode deserialize(String data) {\n        String[] tokens = data.split(\",\");\n        return deserializeDFS(tokens);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#1448-count-good-nodes-in-binary-tree","title":"1448. Count Good Nodes in Binary Tree","text":"<p><code>dfs</code> approach</p> <pre><code>class Solution {\n    /*\n        t.c - o(n)\n        s.c - o(h)\n        approach:\n            1. do a dfs on left and right subtree\n            2. compare if val &gt; maxVal then res++;\n            3. return res\n\n    */\n    public int dfs(TreeNode root,int maxVal){\n        if(root==null) return 0;\n\n        int res = root.val &gt;=maxVal ? 1:0;\n\n        res+= dfs(root.left,Math.max(root.val,maxVal));\n        res+=dfs(root.right,Math.max(root.val,maxVal));\n\n        return res;\n    }\n\n    public int goodNodes(TreeNode root) {\n        return dfs(root,Integer.MIN_VALUE);\n    }\n}\n</code></pre> <p><code>bfs</code> approach</p> <pre><code>class Solution {\n    /*\n        approach : bfs\n        1. init q and maxValq to maintain the nodes\n        2. for each level compare with maxVal and res++\n        3. return res\n    */\n\n    public int goodNodes(TreeNode root) {\n        if (root == null) {\n            return 0;\n        }\n\n        int res = 0;\n        Deque&lt;TreeNode&gt; nodeQueue = new LinkedList&lt;&gt;();\n        Deque&lt;Integer&gt; maxValQueue = new LinkedList&lt;&gt;();\n\n        nodeQueue.offer(root);\n        maxValQueue.offer(root.val);\n\n        while (!nodeQueue.isEmpty()) {\n            TreeNode node = nodeQueue.poll();\n            int maxVal = maxValQueue.poll();\n\n            if (node.val &gt;= maxVal) {\n                res++;\n            }\n\n            int newMaxVal = Math.max(maxVal, node.val);\n\n            if (node.left != null) {\n                nodeQueue.offer(node.left);\n                maxValQueue.offer(newMaxVal);\n            }\n\n            if (node.right != null) {\n                nodeQueue.offer(node.right);\n                maxValQueue.offer(newMaxVal);\n            }\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#linked-list","title":"Linked list","text":""},{"location":"LeetCode/#2-add-two-numbers","title":"2. Add Two Numbers","text":"<pre><code>/**\n * Definition for singly-linked list.\n * public class ListNode {\n *     int val;\n *     ListNode next;\n *     ListNode() {}\n *     ListNode(int val) { this.val = val; }\n *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }\n * }\n */\nclass Solution {\n    /*\n        T.C - o(n)\n        s.c - o(1)\n\n        approach;;\n        1. check if carry exists or l1 or l2\n        2. add value to carry , make a new node with carry%10\n        3. return\n    */\n\n\n    public ListNode addTwoNumbers(ListNode l1, ListNode l2) {\n        ListNode dum = new ListNode();\n        ListNode curr = dum;\n        int carry = 0;\n\n        while(carry&gt;0 || l1!=null || l2!=null){\n            if(l1!=null){\n                carry+=l1.val;\n                l1 = l1.next;\n            }\n            if(l2!=null){\n                carry+=l2.val;\n                l2 = l2.next;\n            }\n            curr.next = new ListNode(carry%10);\n            carry /=10;\n            curr = curr.next;\n        }\n\n        return dum.next;\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#19-remove-nth-node-from-end-of-list","title":"19. Remove Nth Node From End of List","text":"<pre><code>/**\n * Definition for singly-linked list.\n * public class ListNode {\n *     int val;\n *     ListNode next;\n *     ListNode() {}\n *     ListNode(int val) { this.val = val; }\n *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }\n * }\n */\nclass Solution {\n    /*\n        t.c o(n)\n        s.c o(1)\n        approach:\n            1.create a dummy node ,dummy.next = head\n            2. assign l,r pointers to find the nth element from last\n            3. l = dummy , r= moved by n times from head\n            4. delete the node\n            5. return\n    */\n\n\n    public ListNode removeNthFromEnd(ListNode head, int n) {\n        ListNode dummy = new ListNode(0,head);\n        ListNode l_ptr = dummy;\n        ListNode r_ptr = head;\n\n        while(n&gt;0){\n            r_ptr = r_ptr.next;\n            n--;\n        }\n\n        while(r_ptr!=null){ //reaches the node n\n            l_ptr = l_ptr.next;\n            r_ptr = r_ptr.next;\n        }\n\n        l_ptr.next = l_ptr.next.next; //delete the node\n\n        return dummy.next;\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#21-merge-two-sorted-lists","title":"21. Merge Two Sorted Lists","text":"<pre><code>/**\n * Definition for singly-linked list.\n * public class ListNode {\n *     int val;\n *     ListNode next;\n *     ListNode() {}\n *     ListNode(int val) { this.val = val; }\n *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }\n * }\n */\nclass Solution {\n    /*\n        t.c o(n)\n        s.c o(1)\n        approach:\n        1.create a dummy node to track\n        2.while both l1 and l2 exists , check which is less and add to dum\n        3.at end if any list is not all add to dum\n        4.return dummy.next\n    */\n\n\n    public ListNode mergeTwoLists(ListNode list1, ListNode list2) {\n        final ListNode dum = new ListNode();\n        ListNode dum_ptr = dum;\n        while(list1!=null &amp;&amp; list2!=null){\n            if(list1.val&lt;list2.val){\n                dum_ptr.next = list1;\n                list1 = list1.next;\n            }\n            else{\n                dum_ptr.next = list2;\n                list2 = list2.next;\n            }\n            dum_ptr = dum_ptr.next;\n        }\n        //check for remaining portion\n        dum_ptr.next = list1!=null?list1:list2;\n        return dum.next;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#23-merge-k-sorted-lists","title":"23. Merge k Sorted Lists","text":"<pre><code>/**\n * Definition for singly-linked list.\n * public class ListNode {\n *     int val;\n *     ListNode next;\n *     ListNode() {}\n *     ListNode(int val) { this.val = val; }\n *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }\n * }\n */\nclass Solution {\n    /*\n        t.c o(nlogk)\n        s.c o(1)\n\n        approach:\n        1. merge 2 lists at a time (helper function to merge)\n        2. append to the main list after every merge\n        3. return\n    */\n    private ListNode mergeTwoLists(ListNode list1, ListNode list2) {\n        final ListNode dum = new ListNode();\n        ListNode dum_ptr = dum;\n        while(list1!=null &amp;&amp; list2!=null){\n            if(list1.val&lt;list2.val){\n                dum_ptr.next = list1;\n                list1 = list1.next;\n            }\n            else{\n                dum_ptr.next = list2;\n                list2 = list2.next;\n            }\n            dum_ptr = dum_ptr.next;\n        }\n        //check for remaining portion\n        dum_ptr.next = list1!=null?list1:list2;\n        return dum.next;\n    }\n\n\n    public ListNode mergeKLists(ListNode[] lists) {\n        int n = lists.length;\n        int window =1;\n        while(window&lt;n){\n            for(int z=0;z&lt;n-window;z+=2*window){\n                lists[z] = mergeTwoLists(lists[z],lists[z+window]);\n            }\n            window*=2;\n        }\n        return n&gt;0?lists[0]:null;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#25-reverse-nodes-in-k-group","title":"25. Reverse Nodes in k-Group","text":"<pre><code>class Solution {\nclass Solution {\n    /*\n        t.c - o(n)\n        s.c - o(1)\n\n        approach:\n        1. find the total length , to split it into k parts\n        2. for each part reverse the section and maintatin the curr as first elem of next section\n        3. return dummy\n\n    */\n\n\n  public ListNode reverseKGroup(ListNode head, int k) {\n    if (head == null || k == 1)\n      return head;\n\n    final int length = getLength(head);\n    ListNode dummy = new ListNode(0, head);\n    ListNode prev = dummy;\n    ListNode curr = head;\n\n    for (int i = 0; i &lt; length / k; ++i) {\n      for (int j = 0; j &lt; k - 1; ++j) {\n        // 1 - &gt; 2 , 3-&gt;4\n        // 2-&gt;1 -&gt; curr (3) ,4-&gt; 3-&gt;curr(5)\n        ListNode tmp = curr.next; // 2\n        curr.next = tmp.next; // 3\n        tmp.next = prev.next; //1\n        prev.next = tmp; // 2\n      }\n      prev = curr; //5\n      curr = curr.next;\n    }\n\n    return dummy.next;\n  }\n\n  private int getLength(ListNode head) {\n    int length = 0;\n    for (ListNode curr = head; curr != null; curr = curr.next)\n      ++length;\n    return length;\n  }\n}\n</code></pre>"},{"location":"LeetCode/#138-copy-list-with-random-pointer","title":"138. Copy List with Random Pointer","text":"<pre><code>/*\n// Definition for a Node.\nclass Node {\n    int val;\n    Node next;\n    Node random;\n\n    public Node(int val) {\n        this.val = val;\n        this.next = null;\n        this.random = null;\n    }\n}\n*/\n\nclass Solution {\n    public Node copyRandomList(Node head) {\n\n        /*\n            t.c = 0(n)\n            s.c = o(n) - hash map\n            approach:\n                1. two passes to make the deepy copy\n                2. first pass , store the (curr,val) in the hashmap\n                3. second pass , build the node by fetching values from the hashmap\n        */\n        Node curr = head;\n        Map&lt;Node,Node&gt; hm = new HashMap&lt;&gt;();\n\n        //first pass\n        while(curr!=null){\n            hm.put(curr,new Node(curr.val)); //create a new node\n            curr = curr.next;\n        }\n        curr = head; //bring back curr for next iter\n        while(curr!=null){\n            hm.get(curr).next = hm.get(curr.next); //check for the curr.val in the map for curr\n            hm.get(curr).random = hm.get(curr.random);\n            curr = curr.next;\n        }\n        //return head from map\n        return hm.get(head);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#143-reorder-list","title":"143. Reorder List","text":"<pre><code>/**\n * Definition for singly-linked list.\n * public class ListNode {\n *     int val;\n *     ListNode next;\n *     ListNode() {}\n *     ListNode(int val) { this.val = val; }\n *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }\n * }\n */\nclass Solution {\n    /*\n        t.c o(n)\n        s.c o(1)\n        approach:\n            1. find the mid point of the llist\n            2. reverse the portion from mid to end\n            3. merge first and second portion\n\n    */\n\n    private ListNode findMid(ListNode head){\n        ListNode slow = head;\n        ListNode fast = head;\n        ListNode prev = null;\n\n        while(fast!=null &amp;&amp; fast.next!=null){\n            prev = slow;\n            slow = slow.next;\n            fast = fast.next.next;\n        }\n        //attach prev to null\n        prev.next = null;\n        return slow;\n    }\n\n    private ListNode reverse(ListNode head){\n        ListNode prev = null;\n        ListNode curr = head;\n        while(curr!=null){\n            ListNode tmp = curr.next;\n            curr.next = prev;\n            prev = curr;\n            curr = tmp;\n        }\n        return prev;\n    }\n\n    private void merge(ListNode l1,ListNode l2){\n        //1 2 --&gt; l1\n        //4 3 --&gt; l2\n        //1-&gt;4-&gt;2-&gt;3\n        while(l2!=null){\n            ListNode tmp = l1.next; //2\n            l1.next = l2; // 1-&gt;4\n            l1 = l2;// moves l1 to 4\n            l2 = tmp;//1-4-&gt;2\n        }\n    }\n\n\n    public void reorderList(ListNode head) {\n        if (head == null || head.next == null){\n            return;\n        }\n        ListNode mid = findMid(head);\n        ListNode reverseOrder = reverse(mid);\n        merge(head,reverseOrder);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#146-lru-cache","title":"146. LRU Cache","text":"<pre><code>class LRUCache {\n    /*\n        t.c - o(1)\n        s.c - 0(capacity)\n        approach:\n            1. create a doubly linked list to store the elems (lru_ptr ---- elemenets --- mru_ptr)\n            2. keep a track of the most freq and least freq in the list\n            3. after inserting , check the capacity and if exceed remove the lru element\n    */\n    private class Node{\n        Node prev;\n        Node next;\n\n        private int key;\n        private int value;\n\n        public Node(int key,int value){\n            this.key = key;\n            this.value = value;\n        }\n    }\n\n    //helper functions\n\n    public void remove(Node elem){\n        Node prev = elem.prev;\n        Node nxt = elem.next;\n\n        // 1 -&gt; &lt;- 2 -&gt; &lt;- 3\n\n        prev.next = nxt;\n        nxt.prev = prev;\n\n    }\n\n    public void insert(Node elem){\n        //insert the end of the list (at the mru position)\n        Node prev = this.mru.prev;\n        Node nxt = this.mru;\n\n        // prev -- x -- next\n        prev.next = elem;\n        elem.prev = prev;\n\n        elem.next = nxt;\n        nxt.prev = elem;\n\n    }\n\n\n    //define the hashmap and lru and mru pointers\n\n    private Map&lt;Integer,Node&gt; hm;\n    Node lru;\n    Node mru;\n    private int cap;\n    public LRUCache(int capacity) {\n        //init\n        this.cap = capacity;\n        hm = new HashMap&lt;&gt;();\n        this.lru = new Node(0,0);\n        this.mru = new Node(0,0);\n\n        //keep all the values in between lru and mru\n\n        this.lru.next = this.mru;\n        this.mru.prev = this.lru;\n    }\n\n    public int get(int key) {\n        //to get the key check if the key exists return\n        if(hm.containsKey(key)){\n            //add the element as mru\n            remove(hm.get(key));\n            insert(hm.get(key));\n            return hm.get(key).value;\n        }\n        else{\n            return -1;\n        }\n    }\n\n    public void put(int key, int value) {\n        //insert into the right end before mru\n        if(hm.containsKey(key)){\n            remove(hm.get(key));\n        }\n\n        hm.put(key,new Node(key,value));\n        insert(hm.get(key));\n\n        if(hm.size()&gt;cap){\n            Node lru_ptr = this.lru.next;\n            remove(lru_ptr);\n            hm.remove(lru_ptr.key);\n        }\n    }\n}\n\n/**\n * Your LRUCache object will be instantiated and called as such:\n * LRUCache obj = new LRUCache(capacity);\n * int param_1 = obj.get(key);\n * obj.put(key,value);\n */\n</code></pre>"},{"location":"LeetCode/#sliding-window","title":"Sliding Window","text":""},{"location":"LeetCode/#3-longest-substring-without-repeating-characters","title":"3. Longest Substring Without Repeating Characters","text":"<pre><code>class Solution {\n    /*\n        t.c o(n) s.c o(n) - set\n        approach:\n        1. use a set to check for duplicates\n        2. start the left at 0 and increase the sliding window until no duplicates are found\n        3. return the max res\n    */\n\n    public int lengthOfLongestSubstring(String s) {\n        Set&lt;Character&gt; cs = new HashSet&lt;&gt;();\n        char[] ns = s.toCharArray();\n        int res = 0;\n        int l = 0;\n        int n = s.length();\n\n        for(int r=0;r&lt;n;r++){\n            while(cs.contains(ns[r])){\n                //remove elements update the pointer\n                cs.remove(ns[l]);\n                l++;\n            }\n            cs.add(ns[r]);\n            res = Math.max(res, r-l+1);\n        }\n        return res;\n    }\n}\n</code></pre> <p><code>second approach</code> - <code>t.c O(n), s.c O(128)</code></p> <pre><code>class Solution {\n    /*\n        t.c o(n)\n        s.c o(128)\n        approach:\n            1. use a array of 128 len to represent all characters\n            2. if any element in array has count&gt;1 , indicates duplicates are found\n            3. init l at 0 , r at 0 , increment the counter of the right elelment\n            4. if count &gt; 1 , move the left towards right (update the sliding window)\n            5.return res\n    */\n    public int lengthOfLongestSubstring(String s) {\n        int res = 0;\n        int[] cnt = new int[128];\n\n        for(int l=0,r=0;r&lt;s.length();++r){\n            ++cnt[s.charAt(r)];\n            while(cnt[s.charAt(r)]&gt;1){\n                --cnt[s.charAt(l++)];\n            }\n            res = Math.max(res,r-l+1);\n        }\n\n        return res;\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#76-minimum-window-substring","title":"76. Minimum Window Substring","text":"<pre><code>class Solution {\n    public String minWindow(String s, String t) {\n        /*\n        t.c o(m+n)\n        s.c o(m)\n        Approach:\n            1. have to maintain hash map to check the counts between two strings\n            2. init l,r as 0,0 where l stores the start of the subString to return , run until r reaches end\n            3. match --&gt; indicates total found matches\n                minLen --&gt; min substr found until now\n            4. when match is found at r , add to map and decrement by 1 , if count == 0 , correct match\n            5. run a while loop where matched == len(t) , keep on moving the left towards right to find the min len\n            6.return the substr\n        */\n\n        HashMap&lt;Character,Integer&gt; hm = new HashMap&lt;&gt;();\n        int l = 0;\n        int match = 0;\n        int subStrStart = 0;\n        int minLen = s.length()+1; // can be any number &gt; len of s\n\n        //make map for string t\n        for(char c:t.toCharArray()){\n            hm.put(c,hm.getOrDefault(c,0)+1);\n        }\n\n\n        for(int r=0;r&lt;s.length();r++){\n            //move until match is found\n            char right = s.charAt(r);\n            if(hm.containsKey(right)){\n                //decrement the count in map and check if it's 0\n                hm.put(right,hm.get(right)-1);\n                if(hm.get(right)==0){\n                    //correct match\n                    match++;\n                }\n            }\n\n            //loop to move left\n            while(match == hm.size()){\n                //update minLen and subStrStart\n                if(r-l+1 &lt; minLen){\n                    minLen = r-l+1;\n                    subStrStart = l;\n                }\n                //pop left and check the count and l++\n                char left = s.charAt(l++);\n                if(hm.containsKey(left)){\n                    if(hm.get(left)==0){\n                        match--;\n                    }\n                    hm.put(left,hm.get(left)+1);\n                }\n\n\n            }\n        }\n        return minLen &gt; s.length() ? \"\" : s.substring(subStrStart,subStrStart+minLen);\n    }\n}\n</code></pre> <p><code>second approach</code> using s.c O(128)</p> <pre><code> class Solution {\n    public String minWindow(String s, String t) {\n    int[] count = new int[128];\n    int required = t.length();\n    int bestLeft = -1;\n    int minLength = s.length() + 1;\n\n    for (final char c : t.toCharArray())\n      ++count[c];\n\n    for (int l = 0, r = 0; r &lt; s.length(); ++r) {\n      if (--count[s.charAt(r)] &gt;= 0)\n        --required;\n      while (required == 0) {\n        if (r - l + 1 &lt; minLength) {\n          bestLeft = l;\n          minLength = r - l + 1;\n        }\n        if (++count[s.charAt(l++)] &gt; 0)\n          ++required;\n      }\n    }\n\n    return bestLeft == -1 ? \"\" : s.substring(bestLeft, bestLeft + minLength);\n    }\n}\n</code></pre>"},{"location":"LeetCode/#121-best-time-to-buy-and-sell-stock","title":"121. Best Time to Buy and Sell Stock","text":"<pre><code>class Solution {\n    public int maxProfit(int[] prices) {\n        /*\n            t.c : o(n) s.c o(1)\n            approach:\n                1.init two pointer , l = 0 , r = 1\n                2. check until r &lt;= total_len\n                3. if prices[l] &lt; prices[r] // upward curve (calculate profit)\n                4. else update left to the right (shift the whole window)\n                5. return\n        */\n\n        int res = 0;\n        int l = 0;\n        int r = 1;\n\n        while(r&lt;prices.length){\n            if(prices[l]&lt;prices[r]){\n                int profit = prices[r] - prices[l];\n                res = Math.max(res,profit);\n            }\n            else{\n                l = r; // shifting the whole window\n            }\n            r+=1;\n        }\n\n        return res;\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#239-sliding-window-maximum","title":"239. Sliding Window Maximum","text":"<pre><code>class Solution {\n    public int[] maxSlidingWindow(int[] nums, int k) {\n        /*\n            brute force:\n            t.c - o(k.(n-k)) s.c o(1)\n            pass through each window and calculate the max\n\n\n            linear - montonic decreasing queue\n            t.c - o(n)\n            s.c - o(n) - queue\n            approach:\n            1. init l,r =0, for first case offer all element in the range to the dequeue\n            2. for the next iteration , check if the q is not empty and if r &gt; last elem of queue , pop everything to left\n            3. if windows size matches , add to the result array\n            4. return\n        */\n        int n = nums.length;\n        int[] res = new int[n-k+1];\n        Deque&lt;Integer&gt; q = new LinkedList&lt;&gt;();\n\n        int l = 0;\n        for(int r=0;r&lt;n;r++){\n            //check if q is empty and the left index is not out of bounds\n            if(!q.isEmpty() &amp;&amp; q.peekFirst() &lt; r-k+1){\n                 q.pollFirst();\n            }\n            while(!q.isEmpty() &amp;&amp; nums[r]&gt; nums[q.peekLast()]){\n                q.pollLast();\n            }\n            //add the element to queue\n            q.offer(r);\n            if(r&gt;=k-1){\n                res[l++] = nums[q.peekFirst()];\n            }\n        }\n\n        return res;\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#424-longest-repeating-character-replacement","title":"424. Longest Repeating Character Replacement","text":"<pre><code>class Solution {\n    public int characterReplacement(String s, int k) {\n        /*\n            t.c - o(26*n)\n            s.c - o(26) - hashmap\n            approach:\n            1. init arr to store the cnt of characters\n            2. start l,r = 0 until r reaches end - break point\n            3. increase the cnt of char at r by 1\n            4. check if window is valid (windowSize - max(hashMap) &lt;= k)\n            5. else decrese the count of char and increase the l\n            6. return res\n        */\n\n        int res = 0;\n        int[] hm = new int[26];\n        int max = 0;\n        for(int l=0,r=0;r&lt;s.length();r++){\n            hm[s.charAt(r)-'A']++;\n            max = Math.max(max,hm[s.charAt(r)-'A']);\n            //check if window is valid\n            if(r-l+1 - max &gt;k){\n                //invalid\n                hm[s.charAt(l)-'A']--;\n                l++;\n            }\n            res = Math.max(res,r-l+1);\n        }\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#567-permutation-in-string","title":"567. Permutation in String","text":"<pre><code>class Solution {\n    public boolean checkInclusion(String s1, String s2) {\n        /*\n            t.c O(26+n)\n            s.c O(26)\n            approach:\n            1. init count arr for s1 and s2 o(26)\n            2. init l as 0 and r in range until end\n            3. check for matches (when both arrays are equal) , for a premutation substr matches should be 26 (return true)\n            4. check for l and r and update matches accordingly\n            5.\n            5.return matches == 26\n\n        */\n        //base case\n        if (s1.length() &gt; s2.length()) {\n            return false;\n        }\n\n        int[] s1Count = new int[26];\n        int[] s2Count = new int[26];\n\n        for (int i = 0; i &lt; s1.length(); i++) {\n            s1Count[s1.charAt(i) - 'a']++;\n            s2Count[s2.charAt(i) - 'a']++;\n        }\n\n        int matches = 0;\n        for (int i = 0; i &lt; 26; i++) {\n            matches += (s1Count[i] == s2Count[i]) ? 1 : 0;\n        }\n\n        int l = 0;\n        for (int r = s1.length(); r &lt; s2.length(); r++) {\n            if (matches == 26) {\n                return true;\n            }\n\n            int index = s2.charAt(r) - 'a';\n            s2Count[index]++;\n            if (s1Count[index] == s2Count[index]) {\n                matches++;\n            } else if (s1Count[index] + 1 == s2Count[index]) { //check with 0\n                matches--;\n            }\n\n            index = s2.charAt(l) - 'a';\n            s2Count[index]--;\n            if (s1Count[index] == s2Count[index]) {\n                matches++;\n            } else if (s1Count[index] - 1 == s2Count[index]) { //check with 1\n                matches--;\n            }\n            l++;\n        }\n\n        return matches == 26;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#binary-search","title":"Binary Search","text":""},{"location":"LeetCode/#4-median-of-two-sorted-arrays","title":"4. Median of Two Sorted Arrays","text":"<pre><code>class Solution {\n    public double findMedianSortedArrays(int[] nums1, int[] nums2) {\n        /*\n            t.c o(log(min(m,n))) s.c o(1)\n\n            Approach;\n                1. No need to merge both the arrays the whole thing can be made into left and right portions\n                2. take the min_len array , make l , r as start and end\n                3. for the other array , set l as 0 and right as ((total/2) - end of first arr)\n                4. check if the partitions are correct by checking the boundaries\n                5. if even:\n                        max(first_array)+min(second_array) / 2\n                    odd:\n                        max(left_array)\n        */\n\n       int m = nums1.length;\n        int n = nums2.length;\n\n        if (m &gt; n) {\n            return findMedianSortedArrays(nums2, nums1);\n        }\n\n        int total = m + n;\n        int half = (total + 1) / 2;\n\n        int left = 0;\n        int right = m;\n\n        var result = 0.0;\n\n        while (left &lt;= right) {\n            int i = left + (right - left) / 2;\n            int j = half - i;\n\n            // get the four points around possible median\n            int left1 = (i &gt; 0) ? nums1[i - 1] : Integer.MIN_VALUE;\n            int right1 = (i &lt; m) ? nums1[i] : Integer.MAX_VALUE;\n            int left2 = (j &gt; 0) ? nums2[j - 1] : Integer.MIN_VALUE;\n            int right2 = (j &lt; n) ? nums2[j] : Integer.MAX_VALUE;\n\n            // partition is correct\n            if (left1 &lt;= right2 &amp;&amp; left2 &lt;= right1) {\n                // even\n                if (total % 2 == 0) {\n                    result =\n                        (Math.max(left1, left2) + Math.min(right1, right2)) /\n                        2.0;\n                    // odd\n                } else {\n                    result = Math.max(left1, left2);\n                }\n                break;\n            }\n            // partition is wrong (update left/right pointers)\n            else if (left1 &gt; right2) {\n                right = i - 1;\n            } else {\n                left = i + 1;\n            }\n        }\n\n        return result;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#33-search-in-rotated-sorted-array","title":"33. Search in Rotated Sorted Array","text":"<pre><code>class Solution {\n    public int search(int[] nums, int target) {\n        /*\n            T.C  o(logn) s.c o(1)\n\n            approach:\n                1.init l,r = 0,len(nums)-1\n                2. check if target is in left portionn or right portion (based on nums[l])\n                3. if left portion:\n                        check with nums[l] and mid:\n                            if target&lt;nums[l] or target&gt;mid: //element in right portion\n                                left = mid+1\n                            else:\n                                r = mid-1\n                    if right portion:\n                        check with nums[r] and mid:\n                            if target &lt; mid or target &gt; nums[r]: // element in left portion\n                                r = mid-1\n                            else:\n                                l = mid+1\n        */\n        int l = 0;\n        int r = nums.length - 1;\n\n        while(l&lt;=r){\n\n            int mid = (l+r)/2;\n\n            if(nums[mid] == target){\n                return mid;\n            }\n            //left sorted\n            if(nums[l]&lt;=nums[mid]){\n                if(target &gt; nums[mid] || target &lt; nums[l]){\n                    l = mid + 1;\n                }else{\n                    r = mid - 1;\n                }\n            }else{//right sorted\n                if(target &lt; nums[mid] || target &gt; nums [r]){\n                    r = mid - 1;\n                }else{\n                    l = mid + 1;\n                }\n            }\n\n        }\n        return -1;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#74-search-a-2d-matrix","title":"74. Search a 2D matrix","text":"<pre><code>class Solution {\n    public boolean searchMatrix(int[][] matrix, int target) {\n        /*\n            t.c - o(logm+logn) s.c - o(1)\n            Approach:\n                1.find the row which contains the element by b,s log(m)\n                2.peform a second b,s to find the element in that row log(n)\n                3.return el\n        */\n        //edge case\n        if(matrix.length==0){\n            return false;\n        }\n\n\n        int ROWS = matrix.length;\n        int COL = matrix[0].length;\n\n        int top = 0;\n        int btm = ROWS-1;\n\n        while (top&lt;=btm){\n            int row = (top + btm) / 2;\n            System.out.println(row);\n            System.out.println(COL-1);\n            if (target &gt; matrix[row][matrix[row].length-1]){ // after the mid\n                top = row+1;\n            }\n            else if(target &lt; matrix[row][0]){\n                btm = row-1;\n            }\n            else{\n                break;\n            }\n        }\n\n        //if no row is found with the elem , break\n        if(!(top&lt;=btm)){\n            return false;\n        }\n        //search in the row\n        int s_row = (top + btm) / 2;\n        int l = 0;Sea\n        int r = matrix[0].length;\n\n        while (l&lt;=r){\n            int mid = (l+r) / 2;\n            if(matrix[s_row][mid]==target){\n                return true;\n            }\n            if (matrix[s_row][mid]&gt;target){ //ans in left portion\n                r = mid-1;\n            }\n            else if(matrix[s_row][mid]&lt;target){\n                l = mid+1;\n            }\n        }\n        return false;\n    }\n}\n</code></pre> <p><code>second approach</code> - works for smaller matrix , less number of rows</p> <pre><code>class Solution {\n  public boolean searchMatrix(int[][] matrix, int target) {\n    /*\n        t.c o(log(m*n)) s.c o(1)\n        approach:\n        1. flatten the matrix , left = start , end = m*n\n        2.search for el\n        3.return\n\n\n    */\n    //edge case\n    if (matrix.length == 0)\n      return false;\n\n    final int m = matrix.length;\n    final int n = matrix[0].length;\n    int l = 0;\n    int r = m * n;\n\n    while (l &lt; r) {\n      final int mid = (l + r) / 2;\n      final int i = mid / n;\n      final int j = mid % n;\n      if (matrix[i][j] == target)\n        return true;\n      if (matrix[i][j] &lt; target)\n        l = mid + 1;\n      else\n        r = mid;\n    }\n\n    return false;\n  }\n}\n</code></pre>"},{"location":"LeetCode/#153-find-minimum-in-rotated-sorted-array","title":"153. Find Minimum in Rotated Sorted Array","text":"<pre><code>class Solution {\n    /*\n        t,c - o(logn) s,c o(1)\n\n        ALGO:\n        1. maintain a res to hold min\n        2. in a sorted rotated array , at any point mid can belong either to right sorted portion or left sorted portion\n        3. if nums[mid]&gt;= nums[left] --&gt; belongs to left portion , have to search in right portion for min value (set left = mid+1)\n        4.else belongs to right portion , have to search in left (set right = mid)\n        5.return left\n\n    */\n\n\n    public int findMin(int[] nums) {\n        // int m = Integer.MAX_VALUE;\n        // for(int c:nums)\n        //     m = Math.min(m,c);\n        // return m;\n\n        int res = 0;\n        int l = 0;\n        int r = nums.length-1;\n\n        while(l&lt;=r){\n            if (nums[l] &lt;= nums[r]) {\n                return nums[l]; //termination condition , minimum at left\n            }\n            int mid = (l+r)/2;\n            if(nums[mid]&gt;=nums[l]){\n                l = mid+1;\n            }\n            else if(nums[mid]&lt;=nums[l]){\n                r = mid;\n            }\n        }\n        return 0;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#704-binary-search","title":"704. Binary Search","text":"<pre><code>class Solution {\n    public int search(int[] nums, int target) {\n\n        /*\n            t.c - O(logn) s.c - O(1)\n            Approach:\n                s.w\n                1.init l,r at start and end\n                2.find mid and compare with target\n                3.update left and right\n                4.return mid when equal\n        */\n\n        int l = 0;\n        int r = nums.length-1;\n        while (l&lt;=r){\n            int mid = (l+r) / 2;\n            if(nums[mid]==target){\n                return mid;\n            }\n            if (nums[mid]&gt;target){ //ans in left portion\n                r = mid-1;\n            }\n            else if(nums[mid]&lt;target){\n                l = mid+1;\n            }\n        }\n        return -1;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#875-koko-eating-bananas","title":"875. Koko Eating Bananas","text":"<pre><code>class Solution {\n        /*\n            t.c - o(Nlog(max(n))) s.c o(1)\n            approach-\n            1. need to find the k which is optimal to finish in less than h hours\n            2. total possible for k -&gt;[1,max(piles)] , do a binary search on this range\n            3. calculate total hours for a specific k , if calculated_hours&lt; h , search in left portion , else right\n            4.return mid\n        */\n    public int calucateHours(int[] piles,int k){\n        //calcuate hours taken for a k\n        int res = 0;\n        for(int c:piles){\n            res+= Math.ceil((double) c / k);\n        }\n        return res;\n    }\n\n    public int minEatingSpeed(int[] piles, int h) {\n\n\n        int l = 1;\n        int r = 1;\n        for(int c:piles)\n            r = Math.max(r,c);\n\n        while (l&lt;r){\n            int mid = (l+r)/2;\n            int hrs = calucateHours(piles,mid);\n            if (hrs&lt;=h){\n                r = mid;\n            }\n            else if(hrs&gt;h){\n                l = mid+1;\n            }\n        }\n        return r;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#981-time-based-key-value-store","title":"981. Time Based Key-Value Store","text":"<pre><code>class TimeMap {\n    /*\n        t.c - o(logn) s.c O(1)\n        approach:\n        1. items in set operation are sorted (time is always increasing)\n        2. perform binary operation on the dict[key]\n        3. find the closest to the timestamp (&lt;=)\n        4. return\n    */\n    private HashMap&lt;String,List&lt;Pair&lt;String,Integer&gt;&gt;&gt; mp;\n\n    private String binaySearch(List&lt;Pair&lt;String,Integer&gt;&gt; val,int ts){\n        //peform binary\n        int l = 0;\n        int r = val.size()-1;\n        String res = \"\";\n        while (l&lt;=r){\n            int m = (l+r)/2;\n            //check if &lt;= timestamp\n            int el = val.get(m).getValue();\n            if(el &lt;= ts){\n                res = val.get(m).getKey();\n                l = m+1;\n            }\n            else{\n                r = m-1;\n            }\n        }\n        return res;\n    }\n\n    public TimeMap() {\n        mp = new HashMap();\n    }\n\n    public void set(String key, String value, int timestamp) {\n        //set to the key\n        if(!mp.containsKey(key)){\n            mp.put(key,new ArrayList&lt;&gt;());\n        }\n        mp.get(key).add(new Pair(value,timestamp));\n    }\n\n    public String get(String key, int timestamp) {\n        //check if key exists\n        if(!mp.containsKey(key))\n            return \"\";\n        List&lt;Pair&lt;String,Integer&gt;&gt; val = mp.get(key);\n        return binaySearch(val,timestamp);\n    }\n}\n\n/**\n * Your TimeMap object will be instantiated and called as such:\n * TimeMap obj = new TimeMap();\n * obj.set(key,value,timestamp);\n * String param_2 = obj.get(key,timestamp);\n */\n</code></pre>"},{"location":"LeetCode/#stack","title":"Stack","text":""},{"location":"LeetCode/#1190-reverse-substrings-between-each-pair-of-parentheses","title":"1190. Reverse Substrings Between Each Pair of Parentheses","text":"<pre><code>class Solution {\n\n    private void util(char[] arr, int left, int right){\n        //util to reverse the string\n        while(left&lt;right){\n            char tmp = arr[left];\n            arr[left] = arr[right];\n            arr[right] = tmp;\n            left++;\n            right--;\n        }\n    }\n\n    public String reverseParentheses(String s) {\n        /*\n            algo:\n                (ed(et(oc))el)\n                co --&gt; etco --&gt; octe --&gt; edocteel --&gt; leetcode\n                1.store the index of '(', at first occurence of ')', take the largest index and reverse the substring between the index in the string, remove the brackets\n                2. continue until the index array is empty\n                3. return the string\n\n                t.c --&gt; O(n): traversing the string\n                s.c --&gt; O(n): charArray and stack\n        */\n\n        Stack&lt;Integer&gt; st = new Stack&lt;&gt;();\n        char[] ca = s.toCharArray();\n\n        for(int ind=0;ind&lt;ca.length;ind++){\n            if(ca[ind]=='('){\n                st.push(ind);\n            }\n            else if(ca[ind]==')'){\n                int leftIndex = st.pop();\n                util(ca,leftIndex+1,ind-1);\n            }\n        }\n\n        StringBuilder sb = new StringBuilder();\n        for(char c:ca){\n            if(c!='(' &amp;&amp; c!=')'){\n                sb.append(c);\n            }\n        }\n\n        return sb.toString();\n    }\n}\n</code></pre>"},{"location":"LeetCode/#22generate-parentheses","title":"22.Generate Parentheses","text":"<pre><code>class Solution:\n    def generateParenthesis(self, n: int) -&gt; List[str]:\n        '''\n         t.c - O(2^n) s.c O(n) to hold stack and O(2^n) for res stack\n         Approach:\n            backtrack algo\n            start with (0,0)\n            maintain two integers open and close\n            if open &lt; n:\n                add('(')\n                backtrack(open+1)\n                pop()\n            if close &lt; o: (closed cant be greater than o)\n                add(')')\n                backtrack(close+1)\n                pop()\n        '''\n        res = []\n        st = []\n\n        def bt(o,c):\n            if o == c == n:\n                res.append(\"\".join(st))\n                return\n            if o &lt; n:\n                st.append(\"(\")\n                bt(o+1,c)\n                st.pop()\n            if c &lt; o:\n                st.append(\")\")\n                bt(o,c+1)\n                st.pop()\n        bt(0,0)\n        return res\n</code></pre>"},{"location":"LeetCode/#36valid-paranthesis","title":"36.Valid Paranthesis","text":"<pre><code>class Solution:\n  def isValid(self, s: str) -&gt; bool:\n    stack = []\n\n    for c in s:\n      if c == '(':\n        stack.append(')')\n      elif c == '{':\n        stack.append('}')\n      elif c == '[':\n        stack.append(']')\n      elif not stack or stack.pop() != c:\n        return False\n\n    return not stack\n</code></pre>"},{"location":"LeetCode/#84-largest-rectangle-in-histogram","title":"84. Largest Rectangle in Histogram","text":"<pre><code>class Solution {\n    public int largestRectangleArea(int[] heights) {\n        /*\n            largest area --&gt; max_width or max_height\n            area = (l*b)\n            t.c -&gt; O(n)\n            s.c -&gt; O(n)\n            Approach:\n                1. we can make an rectangle only when the next element is greater than the current\n                2. start at ind 0, add to stack with pair (ind,height)\n                3. when element height is less than stack peek , pop from stack and calcuate the area\n                4. at last if any elements are left in the stack , they can extend all the way until end\n                5. return the maxArea formed\n        */\n\n        int res = 0;\n        int n = heights.length;\n        int start;\n\n        Stack&lt;Pair&lt;Integer,Integer&gt;&gt; st = new Stack&lt;&gt;();\n        //start iteration\n        for(int z=0;z&lt;n;z++){\n            int el = heights[z];\n            start = z;\n            //start poping from stack and modify the start index\n            while(!st.empty() &amp;&amp; st.peek().getValue()&gt;el){\n                Pair&lt;Integer,Integer&gt; p = st.pop();\n                int index = p.getKey();\n                int val = p.getValue();\n                res = Math.max(res,val*(z-index)); //calculating all rectangles\n                start = index; //update start index\n            }\n            //add to stack\n            st.push(new Pair(z,el));\n        }\n\n        //check for the remaining element in the stack (can be extended until end)\n        while(!st.empty()){\n            Pair&lt;Integer,Integer&gt; s = st.pop();\n            int i = s.getKey();\n            int h = s.getValue();\n            res = Math.max(res,h*(n-i));\n        }\n\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#150evaluate-reverse-polish-notation","title":"150.Evaluate Reverse Polish Notation","text":"<pre><code>class Solution {\n    /*\n        t.c -&gt; O(n) , s.c O(n)\n        Approach:\n            whenever we approach a expression pop two elements from the stack and add the result back to the stack\n\n\n    */\n\n\n    public int evalRPN(String[] tokens) {\n        Stack&lt;Integer&gt; st = new Stack&lt;&gt;();\n\n        for(String c:tokens){\n            if(c.equals(\"+\")){\n                int a = st.pop();\n                int b = st.pop();\n                st.push(a+b);\n            }\n            else if(c.equals(\"-\")){\n                int a = st.pop();\n                int b = st.pop();\n                st.push(b-a);\n            }\n            else if(c.equals(\"*\")){\n                st.push(st.pop() * st.pop());\n            }\n            else if(c.equals(\"/\")){\n                int a = st.pop();\n                int b = st.pop();\n                st.push(b/a);\n            }\n            else{\n                st.add(Integer.parseInt(c));\n            }\n        }\n\n        return st.pop();\n    }\n}\n</code></pre>"},{"location":"LeetCode/#155min-stack","title":"155.Min Stack","text":"<pre><code>class MinStack {\n        /*t.c O(1) , s.c O(n)\n         Approach:\n         to find the minValue in constant time , maintain a minstack which stores the min until now\n\n        */\n    private Stack&lt;Integer&gt; st;\n    private Stack&lt;Integer&gt; minSt;\n\n    public MinStack(){\n        st = new Stack&lt;&gt;();\n        minSt = new Stack&lt;&gt;();\n    }\n\n    public void push(int val) {\n        st.push(val);\n\n        val = Math.min(val, minSt.isEmpty()?val:minSt.peek());\n        minSt.push(val);\n    }\n\n    public void pop() {\n        st.pop();\n        minSt.pop();\n    }\n\n    public int top() {\n        return st.peek();\n    }\n\n    public int getMin() {\n        return minSt.peek();\n    }\n}\n</code></pre>"},{"location":"LeetCode/#739daily-temperatures","title":"739.Daily Temperatures","text":"<pre><code>class Solution {\n    public int[] dailyTemperatures(int[] temperatures) {\n        /*\n            t.c - O(n) s.c O(n) extra stack\n\n            Approach:\n                keep a stack to store the elements\n                start from the back , check if the stack is empty , if empty then append 0\n                else:\n                    check if element is greater then pop (continue until stack exists)\n                    if element is less than the top of stack , append the difference between curr and top stack to res\n        */\n\n        int[] ans = new int[temperatures.length];\n        Stack&lt;Integer&gt; stack = new Stack&lt;&gt;();\n        for (int currDay = 0; currDay &lt; temperatures.length; currDay++) {\n            while (!stack.isEmpty() &amp;&amp; temperatures[currDay] &gt; temperatures[stack.peek()]) {\n                int prevDay = stack.pop();\n                ans[prevDay] = currDay - prevDay;\n            }\n            stack.add(currDay);\n        }\n        return ans;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#853car-fleet","title":"853.Car Fleet","text":"<pre><code>class Car{\n    public int position;\n    public double time;\n    public Car(int pos,double time){\n        this.position = pos;\n        this.time = time;\n    }\n}\n\nclass Solution {\n    public int carFleet(int target, int[] position, int[] speed) {\n        /*\n            Approach 1 : t.c - O(nlogn) s.c O(n) - stack\n            algo:\n                1.make pairs of cars [[pos,speed]]\n                2.start from right , add time taken by car to stack\n                3. if stack has more than 2 items , check if st[-1] &lt;= st[-2] , pop from stack\n                4.return total len of the stack\n            Approach 2: t.c - O(sort) , s.c O(n)\n            algo:\n                1.make car class objects car(pos,time)\n                2.sort the array,\n                3.for car in carArr , if car.time &gt; maxTime --&gt; res++\n                4.return res\n\n        */\n        double maxTime = 0;\n        int n = position.length;\n        int res = 0;\n        Car[] car = new Car[n];\n        for(int z = 0 ; z&lt;n; z++){\n            car[z] = new Car(position[z],(double)(target-position[z])/speed[z]);\n        }\n        Arrays.sort(car,(a,b)-&gt; b.position - a.position);\n\n        for(Car c:car){\n            if(c.time&gt;maxTime){\n                maxTime = c.time;\n                res++;\n            }\n        }\n        return res;\n\n    }\n}\n</code></pre>"},{"location":"LeetCode/#two-pointers","title":"Two Pointers","text":""},{"location":"LeetCode/#11container-with-most-water","title":"11.Container With Most Water","text":"<pre><code>class Solution {\n    public int maxArea(int[] height) {\n\n        int res = 0;\n        int l = 0;\n        int r = height.length - 1;\n        int area = Integer.MIN_VALUE;\n\n        while(l&lt;r){\n            area = (r-l) * Math.min(height[l],height[r]);\n            res = Math.max(res,area);\n\n            if(height[l]&lt;height[r]){\n                l++;\n            }\n            else{\n                r--;\n            }\n        }\n        return res;\n    }\n}\n</code></pre>"},{"location":"LeetCode/#153sum","title":"15.3Sum","text":"<pre><code>class Solution:\n  def threeSum(self, nums: List[int]) -&gt; List[List[int]]:\n    if len(nums) &lt; 3:\n      return []\n\n    ans = []\n\n    nums.sort()\n\n    for i in range(len(nums) - 2):\n      if i &gt; 0 and nums[i] == nums[i - 1]:\n        continue\n      l = i + 1\n      r = len(nums) - 1\n      while l &lt; r:\n        summ = nums[i] + nums[l] + nums[r]\n        if summ == 0:\n          ans.append((nums[i], nums[l], nums[r]))\n          l += 1\n          r -= 1\n          while nums[l] == nums[l - 1] and l &lt; r:\n            l += 1\n          while nums[r] == nums[r + 1] and l &lt; r:\n            r -= 1\n        elif summ &lt; 0:\n          l += 1\n        else:\n          r -= 1\n\n    return ans\n</code></pre>"},{"location":"LeetCode/#42trapping-rain-water","title":"42.Trapping rain water","text":"<pre><code>class Solution:\n    def trap(self, height: List[int]) -&gt; int:\n        #edge case\n        if not height:\n            return 0\n\n        res = 0\n        l = 0\n        r = len(height)-1\n        maxL = height[l]\n        maxR = height[r]\n\n        while(l&lt;r):\n            if(maxL&lt;maxR):\n                res+= maxL - height[l]\n                l+=1\n                maxL = max(maxL,height[l])\n            else:\n                res+=maxR - height[r]\n                r-=1\n                maxR = max(maxR,height[r])\n        return res\n</code></pre>"},{"location":"LeetCode/#matrix","title":"Matrix","text":""},{"location":"LeetCode/#36valid-sudoku","title":"36.Valid Sudoku","text":"<pre><code>class Solution {\n    public boolean isValidSudoku(char[][] board) {\n        Set&lt;String&gt; seen = new HashSet&lt;&gt;();\n\n        for(int i = 0 ; i&lt;9;i++){\n            for(int j = 0 ; j&lt;9;j++){\n                if(board[i][j]=='.'){\n                    continue;\n                }\n                final char c = board[i][j];\n                if (!seen.add(c + \"@row\" + i) || //\n                    !seen.add(c + \"@col\" + j) || //\n                    !seen.add(c + \"@box\" + i / 3 + j / 3))\n                return false;\n            }\n        }\n        return true;\n    }\n}\n</code></pre>"},{"location":"lld/","title":"Low Level Design Notes","text":"<p><code>Credits</code> - Concept &amp;&amp; Coding</p>"},{"location":"lld/#table-of-contents","title":"Table of contents","text":"LLD Pattern Popular LLD Question Strategy Pattern S.O.L.I.D principles"},{"location":"lld/#strategy-patterns","title":"Strategy Patterns","text":""},{"location":"spring/","title":"Java Spring FrameWork","text":"<p>Course Link - Chad Darby</p>"},{"location":"spring/#spring-core","title":"Spring Core","text":""},{"location":"spring/#inversion-of-control-ioc","title":"Inversion of Control (IoC)","text":"<ul> <li>In general approach whenever a components needs to use another component, it creates an instance of the compoments or requests for the component from a service provider, this creates a \"tight coupling\" between the components i.e whenever one component changes the other would be affected by the change</li> <li>To solve this Inversion of control reverses the traditional approach, in this approach whenever a component requires an object, it is passed as a prop rather than instatiating the object in the class.</li> <li> <p>Different Types of IoC</p> </li> <li> <p>Dependency Injection: receive the dependencies through constructor, settor or an interface</p> </li> <li>service locator: receive the dependencies by making a request to a central repository.</li> <li> <p>Factory Pattern: Have a interface class deliver the required dependencies</p> </li> <li> <p>Spring framework uses spring container, to handle the Ioc functionalities</p> </li> </ul>"},{"location":"spring/#annotations","title":"Annotations","text":"<ul> <li>In spring application, the Application context contains the bean factory, by default spring does not create any class objects but by using the @component annotation, we can notify the bean factory.</li> <li>If we have multiple class dependencies, the spring framework is notified to fetch required beans using the @AutoWired annotation.</li> <li>scopes for objects, singleton and prototype (creates multiple objects each type getBean() is called)</li> </ul>"},{"location":"spring/#configuration","title":"@Configuration","text":"<ul> <li>Annotation used to define class, which would be used to create the bean factory</li> </ul>"},{"location":"spring/#bean","title":"@Bean","text":"<ul> <li>This tag is used to declare beans inside the config file, all beans would be declared and made available during the init process</li> </ul>"},{"location":"spring/#value","title":"@Value","text":"<ul> <li>sets the value in a bean, when its created</li> </ul>"},{"location":"spring/#layers","title":"Layers","text":""},{"location":"spring/#controller","title":"Controller","text":"<ul> <li>responsible for handling all the incoming connections, use @RestController annotation, swagger can be integrated into the controller layer</li> </ul>"},{"location":"spring/#service","title":"Service","text":"<ul> <li>responsible for handling all the bussiness logic, use @Service annotation</li> </ul>"},{"location":"spring/#respository","title":"Respository","text":"<ul> <li>responsible for connecting to the database, use @Repository annotation</li> </ul>"},{"location":"spring/#jpa","title":"JPA","text":"<ul> <li>Java Persistence API, its a form of contract used to connect and talk with different databases</li> <li>ORM (object relation mapper) is the tool which translates java objects into data base schemas and data rows</li> </ul>"},{"location":"spring/#spring-aop","title":"Spring AOP","text":"<p>This is usefull for performance metrics, input validation and security and providing rbac, rollback transactions on exceptions, custom exception handling, caching, auditing, API rate limiting</p> Use Case Description Example Annotation Logging &amp; Monitoring Logs method execution time and method calls. <code>@Around</code> Security &amp; Authorization Restricts access based on user roles. <code>@Before</code> Transaction Management Ensures rollback on failures. <code>@Transactional</code> Exception Handling Centralized error handling across services. <code>@AfterThrowing</code> Caching Stores frequently used data to improve performance. <code>@Cacheable</code> Auditing Tracks user activity for compliance. <code>@Before</code> API Rate Limiting Prevents abuse by limiting API calls. <code>@Before</code> Feature Toggles Enables/disables features dynamically. <code>@Before</code> <p>Aspect Oriented Programming Concepts in a Nutshell</p> <ol> <li>Join Point (When): Think of it as a scene in the movie of your program's execution.    It's where the action happens!</li> <li>Advice (What): This is the action! It's what happens at a particular scene (Join Point). It's like a plot twist in your program's execution.</li> <li>Aspect (Where-Conceptual): It's the script of your movie. It defines what plot twists (Advice) happen and where (Pointcut).</li> <li>Pointcut (Where-Operational): It's the specific scenes (Join Points) where the plot twists (Advice) occur. It's like a bookmark in your script (Aspect).</li> <li>Target Object (Whom): This is the main character. It's the object that experiences the plot twists (Advice).</li> <li>Weaving (How): This is the director's job. It's how the script (Aspect) is turned into a movie. In Spring AOP, this happens at runtime.</li> <li>Proxy (The Double): This is the stunt double in your movie. In Spring AOP, it's the object that is created after applying advice to the target object. It's the one that takes the hits, performs the stunts, and makes the main character (Target Object) look good.</li> </ol>"},{"location":"spring/#reactive-programming","title":"Reactive Programming","text":"<p>process - a singular unit with a set of resources attached to it and used at the runtime thread - a singular unit in a process, which would share the resources and perform its actions scheduler - a part of the OS, which determines the duration for which a thread can execute</p> <p>different types of IO calls</p> <p>sync + blocking - thread sends a request, sits idle until response is available async - a thread, creates a new thread and delegates its task to fetch the results non-blocking - a thread perfroms the fetch request from the source and gets a call back when the response is ready non-blocking + async - a thread, creates a new thread to deleagate, the new thread reaches out to source and gets notified when response is delivered</p> <ul> <li> <p>communication patterns</p> </li> <li> <p>request --&gt; response : classic type of communication, for each request a response is delivered</p> </li> <li>request --&gt; streaming response: A single request is made and stream of response are delivered    (booked a cab (req), server sends stream responses , (driver details, time to arrival))</li> <li>streaming request --&gt; response : A single request is initiated to the server, and multiple requests are made    (Galaxy watch sending sensor data to the server)</li> <li>bi directional : multiple requests and multiple responses (singular connections, but stream of req's and responses)</li> </ul> <p>At the heart and core, reactive programming depends on the observer pattern</p> <ul> <li>in this pattern, a set of chained reactive calls are made, when any change is observed   (input height in number --&gt; conversion in diff units)</li> <li>pub/sub communication model</li> </ul> <p>( workflow --&gt; whenever a subscriber wants to connect to a publisher a subscription is generated which implements all the methods )</p> <p></p> <ul> <li>processors - the intermit units between the publishers and subscribers who can acts as the both</li> <li>Reactor is the implementation of the pub/sub commnication model</li> <li>Mono: in this model, the publisher always emits 0 or 1 item</li> <li>Flux: in this model, publisher can emit 0 .. N items at once</li> <li>backpressure --&gt; occurs when producers sends more data than a consumer can handle</li> <li>Mono.just(<code>&lt;T&gt;</code> value) --&gt; creates a publisher with a single value, subscribers can subscribe to fetch the values</li> <li>Mono.fromSupplier(()-&gt; ()) --&gt; used to delay the emit, the value is computed and emitted only when subscription is made.</li> </ul>"},{"location":"spring/#hot-cold-publisher","title":"Hot/ Cold publisher","text":"<ul> <li>in case of cold publisher , each subscriber would get its own flux stream , in case of netflix , its acts as a cold pub</li> <li>in case of hot publisher , each subscriber would get the parent flux stream , in case of football match streaming</li> </ul>"},{"location":"spring/#scheduler","title":"scheduler","text":"<ul> <li>In general scenarion the creation of the flux object and the subscription and data stream is handled by the main thread</li> <li>If we want to avoid this and let only the main thread handle the creation process, we can use schedulers</li> </ul> <p>to get this functionalities, reactor provides schedulers, reactor.core.scheduler</p> <ul> <li> <p>different modes</p> </li> <li> <p>boundedElastic --&gt; useful for network bound calls</p> </li> <li>parallel --&gt; useful for computive intense</li> </ul>"},{"location":"spring/#subscribe-on","title":"subscribe on","text":"<ul> <li>this method is used to attach the reactor core schedule for upstream, example</li> </ul> <pre><code>flux.create(\n   //logic for emit and complete\n)\n.subscribeOn(Scheduler.boundedElatic())\n.subscribe(default_sub)\n</code></pre> <ul> <li>in this case, the main thread handles the creation of the flux (pub), and the other parts are handled by the thread pool   (when ever a sub arrives, a new thread fetchs the information from the pub, not the main thread)</li> </ul>"},{"location":"spring/#publish-on","title":"publish on","text":"<ul> <li>this method is used to attach the reactor core scheduler for downstream, whenever a publisher starts emitting data and sees a publisher on will assign the task to thread pool</li> </ul> <pre><code>flux.create(\n   //logic for emit and complete\n)\n.publishOn(Scheduler.boundedElatic())\n.subscribe(default_sub)\n</code></pre> <p>the handling with the schedulers is handled by the scheduler</p>"},{"location":"spring/#backpressure","title":"BackPressure","text":"<ul> <li> <p>Occurs when subscriber is taking slowly than at the rate pub is producing (sub taking 100 items but pub producing 10000 items)</p> </li> <li> <p>to handle this by default reactor.core uses a queue to maintain the buffer stream and has a default max value of 256</p> </li> <li> <p>If the sub is taking at a slow rate, pub would produce till the max and wait until</p> </li> </ul> <p>methods to handle the back pressure manually (in case of flux.create())</p> <ol> <li>Add an additonal buffer (this would store the items and pass on to subscriber) (onBackPressureBuffer)</li> <li>thrown an error, in this case, whenever upstream produces more than the buffer size (an error will be thrown)</li> <li>Drop strategy --&gt; in this case, a operator drops the extra items from the upstream, lets say sub takes 2 items and pub produces 20 items, 18 items would be dropped</li> </ol>"}]}